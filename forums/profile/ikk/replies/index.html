<!DOCTYPE html>
<html lang="en-US">
<head>

<meta charset="UTF-8">

<title>iKK&#039;s Replies | Politepix</title>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<link href="https://www.politepix.com/wp-content/uploads/omgf/omgf-stylesheet-56/omgf-stylesheet-56.css?ver=1668781124" rel="stylesheet" type="text/css">

<link rel="stylesheet" type="text/css" href="https://www.politepix.com/wp-content/themes/politepix-pixelpress-child-theme/style.css" media="screen">

<link rel="pingback" href="/xmlrpc.php">
<meta name="robots" content="max-image-preview:large">
<script>window._wca = window._wca || [];</script>

<link rel="alternate" type="application/rss+xml" title="Politepix &raquo; Feed" href="http://feeds.feedburner.com/politepixblog">
<link rel="alternate" type="application/rss+xml" title="Politepix &raquo; Comments Feed" href="/comments/feed/">
<script type="text/javascript">
/* <![CDATA[ */
window._wpemojiSettings = {"baseUrl":"https:\/\/s.w.org\/images\/core\/emoji\/15.0.3\/72x72\/","ext":".png","svgUrl":"https:\/\/s.w.org\/images\/core\/emoji\/15.0.3\/svg\/","svgExt":".svg","source":{"concatemoji":"\/wp-includes\/js\/wp-emoji-release.min.js?ver=6.5.2"}};
/*! This file is auto-generated */
!function(i,n){var o,s,e;function c(e){try{var t={supportTests:e,timestamp:(new Date).valueOf()};sessionStorage.setItem(o,JSON.stringify(t))}catch(e){}}function p(e,t,n){e.clearRect(0,0,e.canvas.width,e.canvas.height),e.fillText(t,0,0);var t=new Uint32Array(e.getImageData(0,0,e.canvas.width,e.canvas.height).data),r=(e.clearRect(0,0,e.canvas.width,e.canvas.height),e.fillText(n,0,0),new Uint32Array(e.getImageData(0,0,e.canvas.width,e.canvas.height).data));return t.every(function(e,t){return e===r[t]})}function u(e,t,n){switch(t){case"flag":return n(e,"🏳️‍⚧️","🏳️​⚧️")?!1:!n(e,"🇺🇳","🇺​🇳")&&!n(e,"🏴󠁧󠁢󠁥󠁮󠁧󠁿","🏴​󠁧​󠁢​󠁥​󠁮​󠁧​󠁿");case"emoji":return!n(e,"🐦‍⬛","🐦​⬛")}return!1}function f(e,t,n){var r="undefined"!=typeof WorkerGlobalScope&&self instanceof WorkerGlobalScope?new OffscreenCanvas(300,150):i.createElement("canvas"),a=r.getContext("2d",{willReadFrequently:!0}),o=(a.textBaseline="top",a.font="600 32px Arial",{});return e.forEach(function(e){o[e]=t(a,e,n)}),o}function t(e){var t=i.createElement("script");t.src=e,t.defer=!0,i.head.appendChild(t)}"undefined"!=typeof Promise&&(o="wpEmojiSettingsSupports",s=["flag","emoji"],n.supports={everything:!0,everythingExceptFlag:!0},e=new Promise(function(e){i.addEventListener("DOMContentLoaded",e,{once:!0})}),new Promise(function(t){var n=function(){try{var e=JSON.parse(sessionStorage.getItem(o));if("object"==typeof e&&"number"==typeof e.timestamp&&(new Date).valueOf()<e.timestamp+604800&&"object"==typeof e.supportTests)return e.supportTests}catch(e){}return null}();if(!n){if("undefined"!=typeof Worker&&"undefined"!=typeof OffscreenCanvas&&"undefined"!=typeof URL&&URL.createObjectURL&&"undefined"!=typeof Blob)try{var e="postMessage("+f.toString()+"("+[JSON.stringify(s),u.toString(),p.toString()].join(",")+"));",r=new Blob([e],{type:"text/javascript"}),a=new Worker(URL.createObjectURL(r),{name:"wpTestEmojiSupports"});return void(a.onmessage=function(e){c(n=e.data),a.terminate(),t(n)})}catch(e){}c(n=f(s,u,p))}t(n)}).then(function(e){for(var t in e)n.supports[t]=e[t],n.supports.everything=n.supports.everything&&n.supports[t],"flag"!==t&&(n.supports.everythingExceptFlag=n.supports.everythingExceptFlag&&n.supports[t]);n.supports.everythingExceptFlag=n.supports.everythingExceptFlag&&!n.supports.flag,n.DOMReady=!1,n.readyCallback=function(){n.DOMReady=!0}}).then(function(){return e}).then(function(){var e;n.supports.everything||(n.readyCallback(),(e=n.source||{}).concatemoji?t(e.concatemoji):e.wpemoji&&e.twemoji&&(t(e.twemoji),t(e.wpemoji)))}))}((window,document),window._wpemojiSettings);
/* ]]> */
</script>
<link rel="stylesheet" id="woo-layout-css" href="https://www.politepix.com/wp-content/themes/pixelpress/css/layout.css?ver=6.5.2" type="text/css" media="all">
<link rel="stylesheet" id="woocommerce-css" href="https://www.politepix.com/wp-content/themes/pixelpress/css/woocommerce.css?ver=6.5.2" type="text/css" media="all">
<style id="wp-emoji-styles-inline-css" type="text/css">img.wp-smiley, img.emoji {
		display: inline !important;
		border: none !important;
		box-shadow: none !important;
		height: 1em !important;
		width: 1em !important;
		margin: 0 0.07em !important;
		vertical-align: -0.1em !important;
		background: none !important;
		padding: 0 !important;
	}</style>
<link rel="stylesheet" id="wp-block-library-css" href="https://c0.wp.com/c/6.5.2/wp-includes/css/dist/block-library/style.min.css" type="text/css" media="all">
<style id="wp-block-library-inline-css" type="text/css">.has-text-align-justify{text-align:justify;}</style>
<link rel="stylesheet" id="mediaelement-css" href="https://c0.wp.com/c/6.5.2/wp-includes/js/mediaelement/mediaelementplayer-legacy.min.css" type="text/css" media="all">
<link rel="stylesheet" id="wp-mediaelement-css" href="https://c0.wp.com/c/6.5.2/wp-includes/js/mediaelement/wp-mediaelement.min.css" type="text/css" media="all">
<style id="jetpack-sharing-buttons-style-inline-css" type="text/css">.jetpack-sharing-buttons__services-list{display:flex;flex-direction:row;flex-wrap:wrap;gap:0;list-style-type:none;margin:5px;padding:0}.jetpack-sharing-buttons__services-list.has-small-icon-size{font-size:12px}.jetpack-sharing-buttons__services-list.has-normal-icon-size{font-size:16px}.jetpack-sharing-buttons__services-list.has-large-icon-size{font-size:24px}.jetpack-sharing-buttons__services-list.has-huge-icon-size{font-size:36px}@media print{.jetpack-sharing-buttons__services-list{display:none!important}}.editor-styles-wrapper .wp-block-jetpack-sharing-buttons{gap:0;padding-inline-start:0}ul.jetpack-sharing-buttons__services-list.has-background{padding:1.25em 2.375em}</style>
<style id="classic-theme-styles-inline-css" type="text/css">/*! This file is auto-generated */
.wp-block-button__link{color:#fff;background-color:#32373c;border-radius:9999px;box-shadow:none;text-decoration:none;padding:calc(.667em + 2px) calc(1.333em + 2px);font-size:1.125em}.wp-block-file__button{background:#32373c;color:#fff;text-decoration:none}</style>
<style id="global-styles-inline-css" type="text/css">body{--wp--preset--color--black: #000000;--wp--preset--color--cyan-bluish-gray: #abb8c3;--wp--preset--color--white: #ffffff;--wp--preset--color--pale-pink: #f78da7;--wp--preset--color--vivid-red: #cf2e2e;--wp--preset--color--luminous-vivid-orange: #ff6900;--wp--preset--color--luminous-vivid-amber: #fcb900;--wp--preset--color--light-green-cyan: #7bdcb5;--wp--preset--color--vivid-green-cyan: #00d084;--wp--preset--color--pale-cyan-blue: #8ed1fc;--wp--preset--color--vivid-cyan-blue: #0693e3;--wp--preset--color--vivid-purple: #9b51e0;--wp--preset--gradient--vivid-cyan-blue-to-vivid-purple: linear-gradient(135deg,rgba(6,147,227,1) 0%,rgb(155,81,224) 100%);--wp--preset--gradient--light-green-cyan-to-vivid-green-cyan: linear-gradient(135deg,rgb(122,220,180) 0%,rgb(0,208,130) 100%);--wp--preset--gradient--luminous-vivid-amber-to-luminous-vivid-orange: linear-gradient(135deg,rgba(252,185,0,1) 0%,rgba(255,105,0,1) 100%);--wp--preset--gradient--luminous-vivid-orange-to-vivid-red: linear-gradient(135deg,rgba(255,105,0,1) 0%,rgb(207,46,46) 100%);--wp--preset--gradient--very-light-gray-to-cyan-bluish-gray: linear-gradient(135deg,rgb(238,238,238) 0%,rgb(169,184,195) 100%);--wp--preset--gradient--cool-to-warm-spectrum: linear-gradient(135deg,rgb(74,234,220) 0%,rgb(151,120,209) 20%,rgb(207,42,186) 40%,rgb(238,44,130) 60%,rgb(251,105,98) 80%,rgb(254,248,76) 100%);--wp--preset--gradient--blush-light-purple: linear-gradient(135deg,rgb(255,206,236) 0%,rgb(152,150,240) 100%);--wp--preset--gradient--blush-bordeaux: linear-gradient(135deg,rgb(254,205,165) 0%,rgb(254,45,45) 50%,rgb(107,0,62) 100%);--wp--preset--gradient--luminous-dusk: linear-gradient(135deg,rgb(255,203,112) 0%,rgb(199,81,192) 50%,rgb(65,88,208) 100%);--wp--preset--gradient--pale-ocean: linear-gradient(135deg,rgb(255,245,203) 0%,rgb(182,227,212) 50%,rgb(51,167,181) 100%);--wp--preset--gradient--electric-grass: linear-gradient(135deg,rgb(202,248,128) 0%,rgb(113,206,126) 100%);--wp--preset--gradient--midnight: linear-gradient(135deg,rgb(2,3,129) 0%,rgb(40,116,252) 100%);--wp--preset--font-size--small: 13px;--wp--preset--font-size--medium: 20px;--wp--preset--font-size--large: 36px;--wp--preset--font-size--x-large: 42px;--wp--preset--spacing--20: 0.44rem;--wp--preset--spacing--30: 0.67rem;--wp--preset--spacing--40: 1rem;--wp--preset--spacing--50: 1.5rem;--wp--preset--spacing--60: 2.25rem;--wp--preset--spacing--70: 3.38rem;--wp--preset--spacing--80: 5.06rem;--wp--preset--shadow--natural: 6px 6px 9px rgba(0, 0, 0, 0.2);--wp--preset--shadow--deep: 12px 12px 50px rgba(0, 0, 0, 0.4);--wp--preset--shadow--sharp: 6px 6px 0px rgba(0, 0, 0, 0.2);--wp--preset--shadow--outlined: 6px 6px 0px -3px rgba(255, 255, 255, 1), 6px 6px rgba(0, 0, 0, 1);--wp--preset--shadow--crisp: 6px 6px 0px rgba(0, 0, 0, 1);}:where(.is-layout-flex){gap: 0.5em;}:where(.is-layout-grid){gap: 0.5em;}body .is-layout-flow > .alignleft{float: left;margin-inline-start: 0;margin-inline-end: 2em;}body .is-layout-flow > .alignright{float: right;margin-inline-start: 2em;margin-inline-end: 0;}body .is-layout-flow > .aligncenter{margin-left: auto !important;margin-right: auto !important;}body .is-layout-constrained > .alignleft{float: left;margin-inline-start: 0;margin-inline-end: 2em;}body .is-layout-constrained > .alignright{float: right;margin-inline-start: 2em;margin-inline-end: 0;}body .is-layout-constrained > .aligncenter{margin-left: auto !important;margin-right: auto !important;}body .is-layout-constrained > :where(:not(.alignleft):not(.alignright):not(.alignfull)){max-width: var(--wp--style--global--content-size);margin-left: auto !important;margin-right: auto !important;}body .is-layout-constrained > .alignwide{max-width: var(--wp--style--global--wide-size);}body .is-layout-flex{display: flex;}body .is-layout-flex{flex-wrap: wrap;align-items: center;}body .is-layout-flex > *{margin: 0;}body .is-layout-grid{display: grid;}body .is-layout-grid > *{margin: 0;}:where(.wp-block-columns.is-layout-flex){gap: 2em;}:where(.wp-block-columns.is-layout-grid){gap: 2em;}:where(.wp-block-post-template.is-layout-flex){gap: 1.25em;}:where(.wp-block-post-template.is-layout-grid){gap: 1.25em;}.has-black-color{color: var(--wp--preset--color--black) !important;}.has-cyan-bluish-gray-color{color: var(--wp--preset--color--cyan-bluish-gray) !important;}.has-white-color{color: var(--wp--preset--color--white) !important;}.has-pale-pink-color{color: var(--wp--preset--color--pale-pink) !important;}.has-vivid-red-color{color: var(--wp--preset--color--vivid-red) !important;}.has-luminous-vivid-orange-color{color: var(--wp--preset--color--luminous-vivid-orange) !important;}.has-luminous-vivid-amber-color{color: var(--wp--preset--color--luminous-vivid-amber) !important;}.has-light-green-cyan-color{color: var(--wp--preset--color--light-green-cyan) !important;}.has-vivid-green-cyan-color{color: var(--wp--preset--color--vivid-green-cyan) !important;}.has-pale-cyan-blue-color{color: var(--wp--preset--color--pale-cyan-blue) !important;}.has-vivid-cyan-blue-color{color: var(--wp--preset--color--vivid-cyan-blue) !important;}.has-vivid-purple-color{color: var(--wp--preset--color--vivid-purple) !important;}.has-black-background-color{background-color: var(--wp--preset--color--black) !important;}.has-cyan-bluish-gray-background-color{background-color: var(--wp--preset--color--cyan-bluish-gray) !important;}.has-white-background-color{background-color: var(--wp--preset--color--white) !important;}.has-pale-pink-background-color{background-color: var(--wp--preset--color--pale-pink) !important;}.has-vivid-red-background-color{background-color: var(--wp--preset--color--vivid-red) !important;}.has-luminous-vivid-orange-background-color{background-color: var(--wp--preset--color--luminous-vivid-orange) !important;}.has-luminous-vivid-amber-background-color{background-color: var(--wp--preset--color--luminous-vivid-amber) !important;}.has-light-green-cyan-background-color{background-color: var(--wp--preset--color--light-green-cyan) !important;}.has-vivid-green-cyan-background-color{background-color: var(--wp--preset--color--vivid-green-cyan) !important;}.has-pale-cyan-blue-background-color{background-color: var(--wp--preset--color--pale-cyan-blue) !important;}.has-vivid-cyan-blue-background-color{background-color: var(--wp--preset--color--vivid-cyan-blue) !important;}.has-vivid-purple-background-color{background-color: var(--wp--preset--color--vivid-purple) !important;}.has-black-border-color{border-color: var(--wp--preset--color--black) !important;}.has-cyan-bluish-gray-border-color{border-color: var(--wp--preset--color--cyan-bluish-gray) !important;}.has-white-border-color{border-color: var(--wp--preset--color--white) !important;}.has-pale-pink-border-color{border-color: var(--wp--preset--color--pale-pink) !important;}.has-vivid-red-border-color{border-color: var(--wp--preset--color--vivid-red) !important;}.has-luminous-vivid-orange-border-color{border-color: var(--wp--preset--color--luminous-vivid-orange) !important;}.has-luminous-vivid-amber-border-color{border-color: var(--wp--preset--color--luminous-vivid-amber) !important;}.has-light-green-cyan-border-color{border-color: var(--wp--preset--color--light-green-cyan) !important;}.has-vivid-green-cyan-border-color{border-color: var(--wp--preset--color--vivid-green-cyan) !important;}.has-pale-cyan-blue-border-color{border-color: var(--wp--preset--color--pale-cyan-blue) !important;}.has-vivid-cyan-blue-border-color{border-color: var(--wp--preset--color--vivid-cyan-blue) !important;}.has-vivid-purple-border-color{border-color: var(--wp--preset--color--vivid-purple) !important;}.has-vivid-cyan-blue-to-vivid-purple-gradient-background{background: var(--wp--preset--gradient--vivid-cyan-blue-to-vivid-purple) !important;}.has-light-green-cyan-to-vivid-green-cyan-gradient-background{background: var(--wp--preset--gradient--light-green-cyan-to-vivid-green-cyan) !important;}.has-luminous-vivid-amber-to-luminous-vivid-orange-gradient-background{background: var(--wp--preset--gradient--luminous-vivid-amber-to-luminous-vivid-orange) !important;}.has-luminous-vivid-orange-to-vivid-red-gradient-background{background: var(--wp--preset--gradient--luminous-vivid-orange-to-vivid-red) !important;}.has-very-light-gray-to-cyan-bluish-gray-gradient-background{background: var(--wp--preset--gradient--very-light-gray-to-cyan-bluish-gray) !important;}.has-cool-to-warm-spectrum-gradient-background{background: var(--wp--preset--gradient--cool-to-warm-spectrum) !important;}.has-blush-light-purple-gradient-background{background: var(--wp--preset--gradient--blush-light-purple) !important;}.has-blush-bordeaux-gradient-background{background: var(--wp--preset--gradient--blush-bordeaux) !important;}.has-luminous-dusk-gradient-background{background: var(--wp--preset--gradient--luminous-dusk) !important;}.has-pale-ocean-gradient-background{background: var(--wp--preset--gradient--pale-ocean) !important;}.has-electric-grass-gradient-background{background: var(--wp--preset--gradient--electric-grass) !important;}.has-midnight-gradient-background{background: var(--wp--preset--gradient--midnight) !important;}.has-small-font-size{font-size: var(--wp--preset--font-size--small) !important;}.has-medium-font-size{font-size: var(--wp--preset--font-size--medium) !important;}.has-large-font-size{font-size: var(--wp--preset--font-size--large) !important;}.has-x-large-font-size{font-size: var(--wp--preset--font-size--x-large) !important;}
.wp-block-navigation a:where(:not(.wp-element-button)){color: inherit;}
:where(.wp-block-post-template.is-layout-flex){gap: 1.25em;}:where(.wp-block-post-template.is-layout-grid){gap: 1.25em;}
:where(.wp-block-columns.is-layout-flex){gap: 2em;}:where(.wp-block-columns.is-layout-grid){gap: 2em;}
.wp-block-pullquote{font-size: 1.5em;line-height: 1.6;}</style>
<link rel="stylesheet" id="bbp-default-css" href="https://www.politepix.com/wp-content/plugins/bbpress/templates/default/css/bbpress.min.css?ver=2.6.9" type="text/css" media="all">
<link rel="stylesheet" id="currency_converter_styles-css" href="https://www.politepix.com/wp-content/plugins/woocommerce-currency-converter-widget/assets/css/converter.css?ver=2.2.2" type="text/css" media="all">
<style id="woocommerce-inline-inline-css" type="text/css">.woocommerce form .form-row .required { visibility: visible; }</style>
<link rel="stylesheet" id="cmplz-general-css" href="https://www.politepix.com/wp-content/plugins/complianz-gdpr/assets/css/cookieblocker.min.css?ver=1710283454" type="text/css" media="all">
<link rel="stylesheet" id="jetpack_css-css" href="https://c0.wp.com/p/jetpack/13.3.1/css/jetpack.css" type="text/css" media="all">
<link rel="stylesheet" id="prettyPhoto-css" href="https://www.politepix.com/wp-content/themes/pixelpress/includes/css/prettyPhoto.css?ver=6.5.2" type="text/css" media="all">
<script type="text/template" id="tmpl-variation-template">
	<div class="woocommerce-variation-description">{{{ data.variation.variation_description }}}<\/div>
	<div class="woocommerce-variation-price">{{{ data.variation.price_html }}}<\/div>
	<div class="woocommerce-variation-availability">{{{ data.variation.availability_html }}}<\/div>
</script>
<script type="text/template" id="tmpl-unavailable-variation-template">
	<p>Sorry, this product is unavailable. Please choose a different combination.<\/p>
</script>
<script type="text/javascript" src="https://c0.wp.com/c/6.5.2/wp-includes/js/dist/vendor/wp-polyfill-inert.min.js" id="wp-polyfill-inert-js"></script>
<script type="text/javascript" src="https://c0.wp.com/c/6.5.2/wp-includes/js/dist/vendor/regenerator-runtime.min.js" id="regenerator-runtime-js"></script>
<script type="text/javascript" src="https://c0.wp.com/c/6.5.2/wp-includes/js/dist/vendor/wp-polyfill.min.js" id="wp-polyfill-js"></script>
<script type="text/javascript" src="https://c0.wp.com/c/6.5.2/wp-includes/js/dist/hooks.min.js" id="wp-hooks-js"></script>
<script data-service="jetpack-statistics" data-category="statistics" type="text/plain" data-cmplz-src="https://stats.wp.com/w.js?ver=202417" id="woo-tracks-js"></script>
<script type="text/javascript" src="https://c0.wp.com/c/6.5.2/wp-includes/js/jquery/jquery.min.js" id="jquery-core-js"></script>
<script type="text/javascript" src="https://c0.wp.com/c/6.5.2/wp-includes/js/jquery/jquery-migrate.min.js" id="jquery-migrate-js"></script>
<script type="text/javascript" src="https://c0.wp.com/c/6.5.2/wp-includes/js/underscore.min.js" id="underscore-js"></script>
<script type="text/javascript" id="wp-util-js-extra">
/* <![CDATA[ */
var _wpUtilSettings = {"ajax":{"url":"\/wp-admin\/admin-ajax.php"}};
/* ]]> */
</script>
<script type="text/javascript" src="https://c0.wp.com/c/6.5.2/wp-includes/js/wp-util.min.js" id="wp-util-js"></script>
<script type="text/javascript" src="https://c0.wp.com/p/woocommerce/8.8.2/assets/js/jquery-blockui/jquery.blockUI.min.js" id="jquery-blockui-js" defer data-wp-strategy="defer"></script>
<script type="text/javascript" id="wc-add-to-cart-variation-js-extra">
/* <![CDATA[ */
var wc_add_to_cart_variation_params = {"wc_ajax_url":"\/?wc-ajax=%%endpoint%%","i18n_no_matching_variations_text":"Sorry, no products matched your selection. Please choose a different combination.","i18n_make_a_selection_text":"Please select some product options before adding this product to your cart.","i18n_unavailable_text":"Sorry, this product is unavailable. Please choose a different combination."};
/* ]]> */
</script>
<script type="text/javascript" src="https://c0.wp.com/p/woocommerce/8.8.2/assets/js/frontend/add-to-cart-variation.min.js" id="wc-add-to-cart-variation-js" defer data-wp-strategy="defer"></script>
<script type="text/javascript" src="https://c0.wp.com/p/woocommerce/8.8.2/assets/js/jquery-cookie/jquery.cookie.min.js" id="jquery-cookie-js" defer data-wp-strategy="defer"></script>
<script data-service="jetpack-statistics" data-category="statistics" type="text/plain" data-cmplz-src="https://stats.wp.com/s-202417.js" id="woocommerce-analytics-js" defer data-wp-strategy="defer"></script>
<script type="text/javascript" src="https://www.politepix.com/wp-content/themes/pixelpress/includes/js/third-party.js?ver=6.5.2" id="third party-js"></script>
<script type="text/javascript" src="https://c0.wp.com/p/woocommerce/8.8.2/assets/js/prettyPhoto/jquery.prettyPhoto.min.js" id="prettyPhoto-js" data-wp-strategy="defer"></script>
<script type="text/javascript" src="https://www.politepix.com/wp-content/themes/pixelpress/includes/js/general.js?ver=6.5.2" id="general-js"></script>
<script type="text/javascript" src="https://www.politepix.com/wp-content/themes/pixelpress/includes/js/uniform.js?ver=6.5.2" id="uniform-js"></script>
<link rel="https://api.w.org/" href="/wp-json/">
<link rel="EditURI" type="application/rsd+xml" title="RSD" href="/xmlrpc.php?rsd">
<meta name="generator" content="WordPress 6.5.2">
<meta name="generator" content="WooCommerce 8.8.2">
	<style>img#wpstats{display:none}</style>
					<style>.cmplz-hidden {
					display: none !important;
				}</style>		<script>( function() {
				window.onpageshow = function( event ) {
					// Defined window.wpforms means that a form exists on a page.
					// If so and back/forward button has been clicked,
					// force reload a page to prevent the submit button state stuck.
					if ( typeof window.wpforms !== 'undefined' && event.persisted ) {
						window.location.reload();
					}
				};
			}() );</script>
		
<!-- Theme version -->
<meta name="generator" content="PixelPress Politepix 1.0">
<meta name="generator" content="PixelPress 1.5.4">
<meta name="generator" content="WooFramework 6.2.9">

<!-- Always force latest IE rendering engine (even in intranet) & Chrome Frame -->
<meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">

<!--  Mobile viewport scale | Disable user zooming as the layout is optimised -->
<meta content="initial-scale=1.0; maximum-scale=1.0; user-scalable=no" name="viewport">
		<!--[if lt IE 9]>
			<script src="https://html5shim.googlecode.com/svn/trunk/html5.js"></script>
		<![endif]-->
			<noscript><style>.woocommerce-product-gallery{ opacity: 1 !important; }</style></noscript>
	
<!-- Google Webfonts -->
<link href="https://www.politepix.com/wp-content/uploads/omgf/omgf-stylesheet-165/omgf-stylesheet-165.css?ver=1668781124" rel="stylesheet" type="text/css">

<!-- Alt Stylesheet -->
<link href="https://www.politepix.com/wp-content/themes/pixelpress/styles/default.css" rel="stylesheet" type="text/css">

<!-- Custom Favicon -->
<link rel="shortcut icon" href="https://www.politepix.com/wp-content/uploads/favicon.png">

<!-- Woo Shortcodes CSS -->
<link href="https://www.politepix.com/wp-content/themes/pixelpress/functions/css/shortcodes.css" rel="stylesheet" type="text/css">

<!-- Custom Stylesheet -->
<link href="https://www.politepix.com/wp-content/themes/pixelpress/custom.css" rel="stylesheet" type="text/css">

<!-- Custom Stylesheet In Child Theme -->
<link href="https://www.politepix.com/wp-content/themes/politepix-pixelpress-child-theme/custom.css" rel="stylesheet" type="text/css">

</head>

<body data-cmplz="1" class="bbp-user-page single singular bbpress no-js theme-pixelpress woocommerce-no-js unknown alt-style-default has-lightbox layout-left-content">

<div id="wrapper">

	    
        
    <div id="header-wrap">

		<header id="header" class="col-full">
		
			<div id="logo" class="fl">
												    <a id="logo" href="/" title="iOS Frameworks for speech recognition, text to speech and more">
				    	<img src="https://www.politepix.com/wp-content/uploads/logo1.png" alt="Politepix">
				    </a>
			    			    
			    <hgroup>
			        
					<h1 class="site-title"><a href="/">Politepix</a></h1>
					<h2 class="site-description">iOS Frameworks for speech recognition, text to speech and more</h2>
					<h3 class="nav-toggle"><a href="#navigation">Navigation</a></h3>
				      	
				</hgroup>
			</div>
<!-- /#logo -->		
	        
	        	
	        <div id="header-right" class="fr">

				<nav id="navigation" role="navigation">
					
					<ul id="main-nav" class="nav fl">
<li id="menu-item-1175" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-has-children menu-item-1175">
<a href="/openears/">OpenEars</a>
<ul class="sub-menu">
	<li id="menu-item-11108" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-11108"><a href="/openears/tutorial/">OpenEars Tutorials</a></li>
	<li id="menu-item-1171" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-1171"><a href="/openears/support/">OpenEars FAQ/Support</a></li>
	<li id="menu-item-1189" class="menu-item menu-item-type-custom menu-item-object-custom menu-item-1189"><a href="/forums/forum/openearsforum/">OpenEars Support Forum</a></li>
	<li id="menu-item-14947" class="menu-item menu-item-type-custom menu-item-object-custom menu-item-14947"><a href="/openearsplatform/">About the OpenEars Platform</a></li>
</ul>
</li>
<li id="menu-item-11706" class="menu-item menu-item-type-custom menu-item-object-custom menu-item-has-children menu-item-11706">
<a href="/neatspeech">NeatSpeech</a>
<ul class="sub-menu">
	<li id="menu-item-11707" class="menu-item menu-item-type-custom menu-item-object-custom menu-item-11707"><a href="/forums/forum/openears-plugins/">NeatSpeech support forum</a></li>
</ul>
</li>
<li id="menu-item-9871" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-has-children menu-item-9871">
<a href="/rapidears/">RapidEars</a>
<ul class="sub-menu">
	<li id="menu-item-10389" class="menu-item menu-item-type-custom menu-item-object-custom menu-item-10389"><a href="/forums/forum/openears-plugins">RapidEars Support Forum</a></li>
</ul>
</li>
<li id="menu-item-11030" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-has-children menu-item-11030">
<a href="/rejecto/">Rejecto</a>
<ul class="sub-menu">
	<li id="menu-item-11031" class="menu-item menu-item-type-custom menu-item-object-custom menu-item-11031"><a href="/forums/forum/openears-plugins/">Rejecto Support Forum</a></li>
</ul>
</li>
<li id="menu-item-13071" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-13071"><a href="/savethatwave/">SaveThatWave</a></li>
<li id="menu-item-1021000" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-has-children menu-item-1021000">
<a href="/ruleorama/">RuleORama</a>
<ul class="sub-menu">
	<li id="menu-item-9002" class="menu-item menu-item-type-custom menu-item-object-custom menu-item-9002"><a href="/forums/forum/openears-plugins/">RuleORama Free Support Forum</a></li>
</ul>
</li>
<li id="menu-item-1178" class="menu-item menu-item-type-post_type menu-item-object-page current_page_parent menu-item-1178"><a title="Blog" href="/blog/">Blog</a></li>
<li id="menu-item-1015870" class="menu-item menu-item-type-custom menu-item-object-custom menu-item-has-children menu-item-1015870">
<a href="/shop">Shop</a>
<ul class="sub-menu">
	<li id="menu-item-8499" class="menu-item menu-item-type-custom menu-item-object-custom menu-item-8499"><a href="/shop">View all products</a></li>
	<li id="menu-item-8486" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-8486"><a href="/cart/">Cart</a></li>
	<li id="menu-item-8498" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-8498"><a href="/order-tracking/">Track your order</a></li>
	<li id="menu-item-8539" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-8539"><a href="/termsandconditions/">AGB/Terms and Conditions</a></li>
</ul>
</li>
</ul>			        
			        			        <ul class="mini-cart">
						<li>
							<a href="/cart/" title="View your shopping cart" class="cart-parent">
								<span> 
							<span class="woocommerce-Price-amount amount"><bdi><span class="woocommerce-Price-currencySymbol">&euro;</span>0.00</bdi></span><mark>0</mark>							</span>
							</a>
							<ul class="cart_list"><li class="empty">No products in the cart.</li></ul>						</li>
					</ul>
			      				      	
				</nav><!-- /#navigation -->

				
<div id="header-social" class="social fr">
				<a href="http://feeds.feedburner.com/politepixblog" class="subscribe" title="RSS"></a>

				<a href="http://www.twitter.com/politepix" class="twitter" title="Follow me on Twitter"></a>

		</div>
<!-- /.social -->
				

			</div>
<!-- /#header-right -->
			
					
		</header><!-- /#header -->
	
	</div>
<!-- /#header-wrap -->
	
	
	       
    <div id="content" class="page col-full">
    
    	    	
		<section id="main" class="col-left"> 			

                                                                   
            <article class="post-0  type- status-publish hentry">
				
				<header>
			    	<h1>iKK</h1>
				</header>
				
                <section class="entry">
                	
<div id="bbpress-forums" class="bbpress-wrapper">

	
	
	<div id="bbp-user-wrapper">

		
<div id="bbp-single-user-details">
	<div id="bbp-user-avatar">
		<span class="vcard">
			<a class="url fn n" href="/forums/profile/ikk/" title="iKK" rel="me">
							</a>
		</span>
	</div>

	
	<div id="bbp-user-navigation">
		<ul>
			<li class="">
				<span class="vcard bbp-user-profile-link">
					<a class="url fn n" href="/forums/profile/ikk/" title="iKK&#039;s Profile" rel="me">Profile</a>
				</span>
			</li>

			<li class="">
				<span class="bbp-user-topics-created-link">
					<a href="/forums/profile/ikk/topics/" title="iKK&#039;s Topics Started">Topics Started</a>
				</span>
			</li>

			<li class="current">
				<span class="bbp-user-replies-created-link">
					<a href="/forums/profile/ikk/replies/" title="iKK&#039;s Replies Created">Replies Created</a>
				</span>
			</li>

							<li class="">
					<span class="bbp-user-engagements-created-link">
						<a href="/forums/profile/ikk/engagements/" title="iKK&#039;s Engagements">Engagements</a>
					</span>
				</li>
			
							<li class="">
					<span class="bbp-user-favorites-link">
						<a href="/forums/profile/ikk/favorites/" title="iKK&#039;s Favorites">Favorites</a>
					</span>
				</li>
			
			
		</ul>

		
	</div>
</div>


		<div id="bbp-user-body">
															
<div id="bbp-user-replies-created" class="bbp-user-replies-created">

	
	<div class="bbp-search-form">
		<form role="search" method="get" id="bbp-reply-search-form">
			<div>
				<label class="screen-reader-text hidden" for="rs">Search replies:</label>
				<input type="text" value="" name="rs" id="rs">
				<input class="button" type="submit" id="bbp_search_submit" value="Search">
			</div>
		</form>
	</div>


	<h2 class="entry-title">Forum Replies Created</h2>
	<div class="bbp-user-section">

		
			
<div class="bbp-pagination">
	<div class="bbp-pagination-count">Viewing 50 posts - 1 through 50 (of 50 total)</div>
	<div class="bbp-pagination-links"></div>
</div>


			<div class="burma">Advertisement: <a href="/neatspeech">&ldquo;NeatSpeech is great-sounding offline speech synthesis, compatible with iOS6.1, and you can even edit pronunciations!&rdquo;</a>
</div>
<p>
</p>
<ul id="topic-0-replies" class="forums bbp-replies">

	<li class="bbp-header">
		<div class="bbp-reply-author">Author</div>
<!-- .bbp-reply-author -->
		<div class="bbp-reply-content">Posts</div>
<!-- .bbp-reply-content -->
	</li>
<!-- .bbp-header -->

	<li class="bbp-body">

		
			
				
<div id="post-1032421" class="bbp-reply-header">
	<div class="bbp-meta">
		<span class="bbp-reply-post-date">April 26, 2018 at 5:32 pm</span>

		
			<span class="bbp-header">
				in reply to: 				<a class="bbp-topic-permalink" href="/forums/topic/recognize-short-command-in-nonenglish/">Recognize short Command in nonEnglish</a>
			</span>

		
		<a href="/forums/topic/recognize-short-command-in-nonenglish/#post-1032421" class="bbp-reply-permalink">#1032421</a>

		
		<span class="bbp-admin-links"></span>
		
	</div>
<!-- .bbp-meta -->
</div>
<!-- #post-1032421 -->

<div class="loop-item-0 user-id-2480 bbp-parent-forum-3654 bbp-parent-topic-1032298 bbp-reply-position-85 odd topic-author  post-1032421 reply type-reply status-publish hentry">
	<div class="bbp-reply-author">

		
		<a href="/forums/profile/ikk/" title="View iKK&#039;s profile" class="bbp-author-link"><span class="bbp-author-avatar"></span><span class="bbp-author-name">iKK</span></a><div class="bbp-author-role">Participant</div>
		
		
	</div>
<!-- .bbp-reply-author -->

	<div class="bbp-reply-content">

		
		<p>Accoustic Model Creation Code for non-plugin OpenEars grammar solution:</p>
<pre><code>import UIKit

class ViewController: UIViewController, OEEventsObserverDelegate {
    
    var openEarsEventsObserver = OEEventsObserver()

    override func viewDidLoad() {
        super.viewDidLoad()
        // Do any additional setup after loading the view, typically from a nib.
        
        // ************* Necessary for logging **************************
        OELogging.startOpenEarsLogging() //Uncomment to receive full OpenEars logging in case of any unexpected results.
        OEPocketsphinxController.sharedInstance().verbosePocketSphinx = true
        // ************* Necessary for logging **************************
        
        self.openEarsEventsObserver.delegate = self
        
        let lmGenerator = OELanguageModelGenerator()
        let accusticModelName = &quot;AcousticModelGerman&quot;
        let fileName = &quot;GermanModel&quot;
        
        let words = [&quot;esch do no frey&quot;]
        
        let grammar = [
            ThisWillBeSaidOnce : [
                [ OneOfTheseWillBeSaidOnce : words]
            ]
        ]
        
        // let err: Error! = lmGenerator.generateLanguageModel(from: words, withFilesNamed: name, forAcousticModelAtPath: OEAcousticModel.path(toModel: accusticModelName))
        
        let err: Error! = lmGenerator.generateGrammar(from: grammar, withFilesNamed: fileName, forAcousticModelAtPath: OEAcousticModel.path(toModel: accusticModelName))
        
        var lmPath = &quot;&quot;
        var dictPath = &quot;&quot;
        
        if(err != nil) {
            print(&quot;Error while creating initial language model: \(err)&quot;)
        } else {
            lmPath = lmGenerator.pathToSuccessfullyGeneratedGrammar(withRequestedName: fileName)
            dictPath = lmGenerator.pathToSuccessfullyGeneratedDictionary(withRequestedName: fileName)
        }
        
        do {
            try OEPocketsphinxController.sharedInstance().setActive(true) // Setting the shared OEPocketsphinxController active is necessary before any of its properties are accessed.
        } catch {
            print(&quot;Error: it wasn&#039;t possible to set the shared instance to active: \&quot;\(error)\&quot;&quot;)
        }
        
        OEPocketsphinxController.sharedInstance().vadThreshold = 3.2;
    OEPocketsphinxController.sharedInstance().startListeningWithLanguageModel(atPath: lmPath, dictionaryAtPath: dictPath, acousticModelAtPath: OEAcousticModel.path(toModel: accusticModelName), languageModelIsJSGF: true)
    }

    override func didReceiveMemoryWarning() {
        super.didReceiveMemoryWarning()
        // Dispose of any resources that can be recreated.
    }
    
    func pocketsphinxDidReceiveHypothesis(_ hypothesis: String!, recognitionScore: String!, utteranceID: String!) { // Something was heard
        print(&quot;Local callback: The received hypothesis is \(hypothesis!) with a score of \(recognitionScore!) and an ID of \(utteranceID!)&quot;)
    }
    
    // An optional delegate method of OEEventsObserver which informs that the Pocketsphinx recognition loop has entered its actual loop.
    // This might be useful in debugging a conflict between another sound class and Pocketsphinx.
    func pocketsphinxRecognitionLoopDidStart() {
        print(&quot;Local callback: Pocketsphinx started.&quot;) // Log it.
    }
    
    // An optional delegate method of OEEventsObserver which informs that Pocketsphinx is now listening for speech.
    func pocketsphinxDidStartListening() {
        print(&quot;Local callback: Pocketsphinx is now listening.&quot;) // Log it.
    }
    
    // An optional delegate method of OEEventsObserver which informs that Pocketsphinx detected speech and is starting to process it.
    func pocketsphinxDidDetectSpeech() {
        print(&quot;Local callback: Pocketsphinx has detected speech.&quot;) // Log it.
    }
    
    // An optional delegate method of OEEventsObserver which informs that Pocketsphinx detected a second of silence, indicating the end of an utterance.
    func pocketsphinxDidDetectFinishedSpeech() {
        print(&quot;Local callback: Pocketsphinx has detected a second of silence, concluding an utterance.&quot;) // Log it.
    }
    
    // An optional delegate method of OEEventsObserver which informs that Pocketsphinx has exited its recognition loop, most
    // likely in response to the OEPocketsphinxController being told to stop listening via the stopListening method.
    func pocketsphinxDidStopListening() {
        print(&quot;Local callback: Pocketsphinx has stopped listening.&quot;) // Log it.
    }
    
    // An optional delegate method of OEEventsObserver which informs that Pocketsphinx is still in its listening loop but it is not
    // Going to react to speech until listening is resumed.  This can happen as a result of Flite speech being
    // in progress on an audio route that doesn&#039;t support simultaneous Flite speech and Pocketsphinx recognition,
    // or as a result of the OEPocketsphinxController being told to suspend recognition via the suspendRecognition method.
    func pocketsphinxDidSuspendRecognition() {
        print(&quot;Local callback: Pocketsphinx has suspended recognition.&quot;) // Log it.
    }
    
    // An optional delegate method of OEEventsObserver which informs that Pocketsphinx is still in its listening loop and after recognition
    // having been suspended it is now resuming.  This can happen as a result of Flite speech completing
    // on an audio route that doesn&#039;t support simultaneous Flite speech and Pocketsphinx recognition,
    // or as a result of the OEPocketsphinxController being told to resume recognition via the resumeRecognition method.
    func pocketsphinxDidResumeRecognition() {
        print(&quot;Local callback: Pocketsphinx has resumed recognition.&quot;) // Log it.
    }
    
    // An optional delegate method which informs that Pocketsphinx switched over to a new language model at the given URL in the course of
    // recognition. This does not imply that it is a valid file or that recognition will be successful using the file.
    func pocketsphinxDidChangeLanguageModel(toFile newLanguageModelPathAsString: String!, andDictionary newDictionaryPathAsString: String!) {
        
        print(&quot;Local callback: Pocketsphinx is now using the following language model: \n\(newLanguageModelPathAsString!) and the following dictionary: \(newDictionaryPathAsString!)&quot;)
    }
    
    // An optional delegate method of OEEventsObserver which informs that Flite is speaking, most likely to be useful if debugging a
    // complex interaction between sound classes. You don&#039;t have to do anything yourself in order to prevent Pocketsphinx from listening to Flite talk and trying to recognize the speech.
    func fliteDidStartSpeaking() {
        print(&quot;Local callback: Flite has started speaking&quot;) // Log it.
    }
    
    // An optional delegate method of OEEventsObserver which informs that Flite is finished speaking, most likely to be useful if debugging a
    // complex interaction between sound classes.
    func fliteDidFinishSpeaking() {
        print(&quot;Local callback: Flite has finished speaking&quot;) // Log it.
    }
    
    func pocketSphinxContinuousSetupDidFail(withReason reasonForFailure: String!) { // This can let you know that something went wrong with the recognition loop startup. Turn on [OELogging startOpenEarsLogging] to learn why.
        print(&quot;Local callback: Setting up the continuous recognition loop has failed for the reason \(reasonForFailure), please turn on OELogging.startOpenEarsLogging() to learn more.&quot;) // Log it.
    }
    
    func pocketSphinxContinuousTeardownDidFail(withReason reasonForFailure: String!) { // This can let you know that something went wrong with the recognition loop startup. Turn on OELogging.startOpenEarsLogging() to learn why.
        print(&quot;Local callback: Tearing down the continuous recognition loop has failed for the reason \(reasonForFailure)&quot;) // Log it.
    }
    
    /** Pocketsphinx couldn&#039;t start because it has no mic permissions (will only be returned on iOS7 or later).*/
    func pocketsphinxFailedNoMicPermissions() {
        print(&quot;Local callback: The user has never set mic permissions or denied permission to this app&#039;s mic, so listening will not start.&quot;)
    }
    
    /** The user prompt to get mic permissions, or a check of the mic permissions, has completed with a true or a false result  (will only be returned on iOS7 or later).*/
    
    func micPermissionCheckCompleted(withResult: Bool) {
        print(&quot;Local callback: mic check completed.&quot;)
    }
}</code></pre>

		
	</div>
<!-- .bbp-reply-content -->
</div>
<!-- .reply -->

			
				
<div id="post-1032420" class="bbp-reply-header">
	<div class="bbp-meta">
		<span class="bbp-reply-post-date">April 26, 2018 at 5:31 pm</span>

		
			<span class="bbp-header">
				in reply to: 				<a class="bbp-topic-permalink" href="/forums/topic/recognize-short-command-in-nonenglish/">Recognize short Command in nonEnglish</a>
			</span>

		
		<a href="/forums/topic/recognize-short-command-in-nonenglish/#post-1032420" class="bbp-reply-permalink">#1032420</a>

		
		<span class="bbp-admin-links"></span>
		
	</div>
<!-- .bbp-meta -->
</div>
<!-- #post-1032420 -->

<div class="loop-item-1 user-id-2480 bbp-parent-forum-3654 bbp-parent-topic-1032298 bbp-reply-position-84 even topic-author  post-1032420 reply type-reply status-publish hentry">
	<div class="bbp-reply-author">

		
		<a href="/forums/profile/ikk/" title="View iKK&#039;s profile" class="bbp-author-link"><span class="bbp-author-avatar"></span><span class="bbp-author-name">iKK</span></a><div class="bbp-author-role">Participant</div>
		
		
	</div>
<!-- .bbp-reply-author -->

	<div class="bbp-reply-content">

		
		<p>With OpenEars-only (original grammar without any plugin):</p>
<p>I have false-positives and I have false negatives. I feel that it does a tiny bit better as for the false-negatives than Rejecto. But I would have to test much more thorougly.</p>
<p>I suggest that I place more logs for each of the solutions. (since again, for me this logs are very cryptic).</p>
<p>But let me first place the Accoustic Model Creation Code of the non-plugin OpenEars-only solution to have everything mentioned here.</p>

		
	</div>
<!-- .bbp-reply-content -->
</div>
<!-- .reply -->

			
				
<div id="post-1032418" class="bbp-reply-header">
	<div class="bbp-meta">
		<span class="bbp-reply-post-date">April 26, 2018 at 5:24 pm</span>

		
			<span class="bbp-header">
				in reply to: 				<a class="bbp-topic-permalink" href="/forums/topic/recognize-short-command-in-nonenglish/">Recognize short Command in nonEnglish</a>
			</span>

		
		<a href="/forums/topic/recognize-short-command-in-nonenglish/#post-1032418" class="bbp-reply-permalink">#1032418</a>

		
		<span class="bbp-admin-links"></span>
		
	</div>
<!-- .bbp-meta -->
</div>
<!-- #post-1032418 -->

<div class="loop-item-2 user-id-2480 bbp-parent-forum-3654 bbp-parent-topic-1032298 bbp-reply-position-82 odd topic-author  post-1032418 reply type-reply status-publish hentry">
	<div class="bbp-reply-author">

		
		<a href="/forums/profile/ikk/" title="View iKK&#039;s profile" class="bbp-author-link"><span class="bbp-author-avatar"></span><span class="bbp-author-name">iKK</span></a><div class="bbp-author-role">Participant</div>
		
		
	</div>
<!-- .bbp-reply-author -->

	<div class="bbp-reply-content">

		
		<p>With Rejecto: What I don&#8217;t understand why the ending of my &#8220;sentence at question&#8221; does not seem to matter at all. i.e. if I speak &#8220;eschdonofrey&#8221; or if I speak &#8220;eschdonoAnything&#8221; makes no difference, the sentence is still recognized (which leads to so many false-negatives !</p>
<p>Do you have any idea on how to improve the ending-problem of my sentence at question ?</p>

		
	</div>
<!-- .bbp-reply-content -->
</div>
<!-- .reply -->

			
				
<div id="post-1032415" class="bbp-reply-header">
	<div class="bbp-meta">
		<span class="bbp-reply-post-date">April 26, 2018 at 5:21 pm</span>

		
			<span class="bbp-header">
				in reply to: 				<a class="bbp-topic-permalink" href="/forums/topic/recognize-short-command-in-nonenglish/">Recognize short Command in nonEnglish</a>
			</span>

		
		<a href="/forums/topic/recognize-short-command-in-nonenglish/#post-1032415" class="bbp-reply-permalink">#1032415</a>

		
		<span class="bbp-admin-links"></span>
		
	</div>
<!-- .bbp-meta -->
</div>
<!-- #post-1032415 -->

<div class="loop-item-3 user-id-2480 bbp-parent-forum-3654 bbp-parent-topic-1032298 bbp-reply-position-79 even topic-author  post-1032415 reply type-reply status-publish hentry">
	<div class="bbp-reply-author">

		
		<a href="/forums/profile/ikk/" title="View iKK&#039;s profile" class="bbp-author-link"><span class="bbp-author-avatar"></span><span class="bbp-author-name">iKK</span></a><div class="bbp-author-role">Participant</div>
		
		
	</div>
<!-- .bbp-reply-author -->

	<div class="bbp-reply-content">

		
		<p>OK &#8211; let&#8217;s continue with Rejecto !</p>

		
	</div>
<!-- .bbp-reply-content -->
</div>
<!-- .reply -->

			
				
<div id="post-1032413" class="bbp-reply-header">
	<div class="bbp-meta">
		<span class="bbp-reply-post-date">April 26, 2018 at 5:19 pm</span>

		
			<span class="bbp-header">
				in reply to: 				<a class="bbp-topic-permalink" href="/forums/topic/recognize-short-command-in-nonenglish/">Recognize short Command in nonEnglish</a>
			</span>

		
		<a href="/forums/topic/recognize-short-command-in-nonenglish/#post-1032413" class="bbp-reply-permalink">#1032413</a>

		
		<span class="bbp-admin-links"></span>
		
	</div>
<!-- .bbp-meta -->
</div>
<!-- #post-1032413 -->

<div class="loop-item-4 user-id-2480 bbp-parent-forum-3654 bbp-parent-topic-1032298 bbp-reply-position-77 odd topic-author  post-1032413 reply type-reply status-publish hentry">
	<div class="bbp-reply-author">

		
		<a href="/forums/profile/ikk/" title="View iKK&#039;s profile" class="bbp-author-link"><span class="bbp-author-avatar"></span><span class="bbp-author-name">iKK</span></a><div class="bbp-author-role">Participant</div>
		
		
	</div>
<!-- .bbp-reply-author -->

	<div class="bbp-reply-content">

		
		<p>For both solutions (Rejecto or RuleORama) my question to you: Are you able to interpret the logs in order to tune one or the other solution even more ? I am completely lost in what to tune here since the logs look very cryptic to me.</p>
<p>If yes, what examples should I place ? (positive, false-positive or false negative ones?</p>

		
	</div>
<!-- .bbp-reply-content -->
</div>
<!-- .reply -->

			
				
<div id="post-1032412" class="bbp-reply-header">
	<div class="bbp-meta">
		<span class="bbp-reply-post-date">April 26, 2018 at 5:14 pm</span>

		
			<span class="bbp-header">
				in reply to: 				<a class="bbp-topic-permalink" href="/forums/topic/recognize-short-command-in-nonenglish/">Recognize short Command in nonEnglish</a>
			</span>

		
		<a href="/forums/topic/recognize-short-command-in-nonenglish/#post-1032412" class="bbp-reply-permalink">#1032412</a>

		
		<span class="bbp-admin-links"></span>
		
	</div>
<!-- .bbp-meta -->
</div>
<!-- #post-1032412 -->

<div class="loop-item-5 user-id-2480 bbp-parent-forum-3654 bbp-parent-topic-1032298 bbp-reply-position-76 even topic-author  post-1032412 reply type-reply status-publish hentry">
	<div class="bbp-reply-author">

		
		<a href="/forums/profile/ikk/" title="View iKK&#039;s profile" class="bbp-author-link"><span class="bbp-author-avatar"></span><span class="bbp-author-name">iKK</span></a><div class="bbp-author-role">Participant</div>
		
		
	</div>
<!-- .bbp-reply-author -->

	<div class="bbp-reply-content">

		
		<p>Thank you &#8211; also the RuleORama is now performing !</p>
<p>Unfortunately, it still has many false negatives. </p>
<p>Also, one thing I don&#8217;t understand is that it often times responds with having recognized the &#8220;sentence at question&#8221; several times. As can be seen in this log-excert:</p>
<pre><code>2018-04-26 17:12:25.815209+0200 TestOpenEars[1012:281905] Pocketsphinx heard &quot;esch do no frey esch do no frey esch do no frey esch do no frey esch do no frey&quot; with a score of (-130134) and an utterance ID of 19.
Local callback: The received hypothesis is esch do no frey esch do no frey esch do no frey esch do no frey esch do no frey with a score of -130134 and an ID of 19</code></pre>
<p>What could this be ?  i.e. Why does the hypothesis contain our &#8220;sentence at question&#8221; this many times ??</p>

		
	</div>
<!-- .bbp-reply-content -->
</div>
<!-- .reply -->

			
				
<div id="post-1032411" class="bbp-reply-header">
	<div class="bbp-meta">
		<span class="bbp-reply-post-date">April 26, 2018 at 5:09 pm</span>

		
			<span class="bbp-header">
				in reply to: 				<a class="bbp-topic-permalink" href="/forums/topic/recognize-short-command-in-nonenglish/">Recognize short Command in nonEnglish</a>
			</span>

		
		<a href="/forums/topic/recognize-short-command-in-nonenglish/#post-1032411" class="bbp-reply-permalink">#1032411</a>

		
		<span class="bbp-admin-links"></span>
		
	</div>
<!-- .bbp-meta -->
</div>
<!-- #post-1032411 -->

<div class="loop-item-6 user-id-2480 bbp-parent-forum-3654 bbp-parent-topic-1032298 bbp-reply-position-75 odd topic-author  post-1032411 reply type-reply status-publish hentry">
	<div class="bbp-reply-author">

		
		<a href="/forums/profile/ikk/" title="View iKK&#039;s profile" class="bbp-author-link"><span class="bbp-author-avatar"></span><span class="bbp-author-name">iKK</span></a><div class="bbp-author-role">Participant</div>
		
		
	</div>
<!-- .bbp-reply-author -->

	<div class="bbp-reply-content">

		
		<p>Thank you for the explanation &#8211; I will investigate in the &#8220;0.1 &lt; withWeight &lt; 1.9&#8221; parameter as well as play with the two LookupList.text suggestions (maybe even play with that one also a little bit to understand its effects&#8230;)&#8230;.</p>

		
	</div>
<!-- .bbp-reply-content -->
</div>
<!-- .reply -->

			
				
<div id="post-1032407" class="bbp-reply-header">
	<div class="bbp-meta">
		<span class="bbp-reply-post-date">April 26, 2018 at 5:02 pm</span>

		
			<span class="bbp-header">
				in reply to: 				<a class="bbp-topic-permalink" href="/forums/topic/recognize-short-command-in-nonenglish/">Recognize short Command in nonEnglish</a>
			</span>

		
		<a href="/forums/topic/recognize-short-command-in-nonenglish/#post-1032407" class="bbp-reply-permalink">#1032407</a>

		
		<span class="bbp-admin-links"></span>
		
	</div>
<!-- .bbp-meta -->
</div>
<!-- #post-1032407 -->

<div class="loop-item-7 user-id-2480 bbp-parent-forum-3654 bbp-parent-topic-1032298 bbp-reply-position-72 even topic-author  post-1032407 reply type-reply status-publish hentry">
	<div class="bbp-reply-author">

		
		<a href="/forums/profile/ikk/" title="View iKK&#039;s profile" class="bbp-author-link"><span class="bbp-author-avatar"></span><span class="bbp-author-name">iKK</span></a><div class="bbp-author-role">Participant</div>
		
		
	</div>
<!-- .bbp-reply-author -->

	<div class="bbp-reply-content">

		
		<p>RuleORama Error log :</p>
<pre><code>2018-04-26 17:02:12.467180+0200 TestOpenEars[1005:277279] Starting OpenEars logging for OpenEars version 2.506 on 64-bit device (or build): iPhone running iOS version: 11.300000
2018-04-26 17:02:12.468228+0200 TestOpenEars[1005:277279] Creating shared instance of OEPocketsphinxController
2018-04-26 17:02:12.484721+0200 TestOpenEars[1005:277279] RuleORama version 2.502000
2018-04-26 17:02:12.498086+0200 TestOpenEars[1005:277279] Since there is no cached version, loading the language model lookup list for the acoustic model called AcousticModelGerman
2018-04-26 17:02:12.502769+0200 TestOpenEars[1005:277279] Since there is no cached version, loading the g2p model for the acoustic model called AcousticModelGerman
2018-04-26 17:02:12.535249+0200 TestOpenEars[1005:277279] The word do was not found in the dictionary of the acoustic model /var/containers/Bundle/Application/19DFCFC8-F32E-4454-87D3-F5960BF22F97/TestOpenEars.app/AcousticModelGerman.bundle. Now using the fallback method to look it up. If this is happening more frequently than you would expect, likely causes can be that you are entering words in another language from the one you are recognizing, or that there are symbols (including numbers) that need to be spelled out or cleaned up, or you are using your own acoustic model and there is an issue with either its phonetic dictionary or it lacks a g2p file. Please get in touch at the forums for assistance with the last two possible issues.
2018-04-26 17:02:12.535454+0200 TestOpenEars[1005:277279] the graphemes &quot;d oo&quot; were created for the word do using the fallback method.
2018-04-26 17:02:12.538121+0200 TestOpenEars[1005:277279] The word esch was not found in the dictionary of the acoustic model /var/containers/Bundle/Application/19DFCFC8-F32E-4454-87D3-F5960BF22F97/TestOpenEars.app/AcousticModelGerman.bundle. Now using the fallback method to look it up. If this is happening more frequently than you would expect, likely causes can be that you are entering words in another language from the one you are recognizing, or that there are symbols (including numbers) that need to be spelled out or cleaned up, or you are using your own acoustic model and there is an issue with either its phonetic dictionary or it lacks a g2p file. Please get in touch at the forums for assistance with the last two possible issues.
2018-04-26 17:02:12.538570+0200 TestOpenEars[1005:277279] the graphemes &quot;@ ss&quot; were created for the word esch using the fallback method.
2018-04-26 17:02:12.541126+0200 TestOpenEars[1005:277279] The word frey was not found in the dictionary of the acoustic model /var/containers/Bundle/Application/19DFCFC8-F32E-4454-87D3-F5960BF22F97/TestOpenEars.app/AcousticModelGerman.bundle. Now using the fallback method to look it up. If this is happening more frequently than you would expect, likely causes can be that you are entering words in another language from the one you are recognizing, or that there are symbols (including numbers) that need to be spelled out or cleaned up, or you are using your own acoustic model and there is an issue with either its phonetic dictionary or it lacks a g2p file. Please get in touch at the forums for assistance with the last two possible issues.
2018-04-26 17:02:12.541368+0200 TestOpenEars[1005:277279] the graphemes &quot;f r @ ii&quot; were created for the word frey using the fallback method.
2018-04-26 17:02:12.543943+0200 TestOpenEars[1005:277279] The word no was not found in the dictionary of the acoustic model /var/containers/Bundle/Application/19DFCFC8-F32E-4454-87D3-F5960BF22F97/TestOpenEars.app/AcousticModelGerman.bundle. Now using the fallback method to look it up. If this is happening more frequently than you would expect, likely causes can be that you are entering words in another language from the one you are recognizing, or that there are symbols (including numbers) that need to be spelled out or cleaned up, or you are using your own acoustic model and there is an issue with either its phonetic dictionary or it lacks a g2p file. Please get in touch at the forums for assistance with the last two possible issues.
2018-04-26 17:02:12.544061+0200 TestOpenEars[1005:277279] the graphemes &quot;n oo&quot; were created for the word no using the fallback method.
2018-04-26 17:02:12.544117+0200 TestOpenEars[1005:277279] I&#039;m done running performDictionaryLookup and it took 0.041384 seconds
2018-04-26 17:02:12.564690+0200 TestOpenEars[1005:277279] Starting dynamic language model generation

INFO: ngram_model_arpa_legacy.c(504): ngrams 1=3, 2=0, 3=0
INFO: ngram_model_arpa_legacy.c(136): Reading unigrams
INFO: ngram_model_arpa_legacy.c(543):        3 = #unigrams created
INFO: ngram_model_dmp_legacy.c(521): Building DMP model...
INFO: ngram_model_dmp_legacy.c(551):        3 = #unigrams created
2018-04-26 17:02:12.589480+0200 TestOpenEars[1005:277279] Done creating language model with CMUCLMTK in 0.024742 seconds.
2018-04-26 17:02:12.592952+0200 TestOpenEars[1005:277279] Generating fast grammar took 0.095226 seconds
INFO: ngram_model_trie.c(424): Trying to read LM in bin format
INFO: ngram_model_trie.c(457): Header doesn&#039;t match
INFO: ngram_model_trie.c(180): Trying to read LM in arpa format
INFO: ngram_model_trie.c(218): LM of order 1
INFO: ngram_model_trie.c(220): #1-grams: 3
2018-04-26 17:02:12.596542+0200 TestOpenEars[1005:277279] Attempting to start listening session from startListeningWithLanguageModelAtPath:
2018-04-26 17:02:12.596608+0200 TestOpenEars[1005:277279] Error: you have invoked the method:

startListeningWithLanguageModelAtPath:(NSString *)languageModelPath dictionaryAtPath:(NSString *)dictionaryPath acousticModelAtPath:(NSString *)acousticModelPath languageModelIsJSGF:(BOOL)languageModelIsJSGF

with a languageModelPath which is nil. If your call to OELanguageModelGenerator did not return an error when you generated this grammar, that means the correct path to your grammar that you should pass to this method&#039;s languageModelPath argument is as follows:

NSString *correctPathToMyLanguageModelFile = [myLanguageModelGenerator pathToSuccessfullyGeneratedGrammarWithRequestedName:@&quot;TheNameIChoseForMyVocabulary&quot;];

Feel free to copy and paste this code for your path to your grammar, but remember to replace the part that says &quot;TheNameIChoseForMyVocabulary&quot; with the name you actually chose for your grammar or you will get this error again (and replace myLanguageModelGenerator with the name of your OELanguageModelGenerator instance). Since this file is required, expect an exception or undocumented behavior shortly.</code></pre>

		
	</div>
<!-- .bbp-reply-content -->
</div>
<!-- .reply -->

			
				
<div id="post-1032406" class="bbp-reply-header">
	<div class="bbp-meta">
		<span class="bbp-reply-post-date">April 26, 2018 at 5:01 pm</span>

		
			<span class="bbp-header">
				in reply to: 				<a class="bbp-topic-permalink" href="/forums/topic/recognize-short-command-in-nonenglish/">Recognize short Command in nonEnglish</a>
			</span>

		
		<a href="/forums/topic/recognize-short-command-in-nonenglish/#post-1032406" class="bbp-reply-permalink">#1032406</a>

		
		<span class="bbp-admin-links"></span>
		
	</div>
<!-- .bbp-meta -->
</div>
<!-- #post-1032406 -->

<div class="loop-item-8 user-id-2480 bbp-parent-forum-3654 bbp-parent-topic-1032298 bbp-reply-position-71 odd topic-author  post-1032406 reply type-reply status-publish hentry">
	<div class="bbp-reply-author">

		
		<a href="/forums/profile/ikk/" title="View iKK&#039;s profile" class="bbp-author-link"><span class="bbp-author-avatar"></span><span class="bbp-author-name">iKK</span></a><div class="bbp-author-role">Participant</div>
		
		
	</div>
<!-- .bbp-reply-author -->

	<div class="bbp-reply-content">

		
		<p>RuleORama Accoustic Model creation Code :</p>
<pre><code>import UIKit

class ViewController: UIViewController, OEEventsObserverDelegate {
    
    var openEarsEventsObserver = OEEventsObserver()

    override func viewDidLoad() {
        super.viewDidLoad()
        // Do any additional setup after loading the view, typically from a nib.
        
        // ************* Necessary for logging **************************
        OELogging.startOpenEarsLogging() //Uncomment to receive full OpenEars logging in case of any unexpected results.
        OEPocketsphinxController.sharedInstance().verbosePocketSphinx = true
        // ************* Necessary for logging **************************
        
        
        self.openEarsEventsObserver.delegate = self
        
        let lmGenerator = OELanguageModelGenerator()
        let accusticModelName = &quot;AcousticModelGerman&quot;
        let fileName = &quot;GermanModel&quot;
        
        let words = [&quot;esch do no frey&quot;]
        
        let grammar = [
            ThisWillBeSaidOnce : [
                [ OneOfTheseWillBeSaidOnce : words]
            ]
        ]
        
        // let err: Error! = lmGenerator.generateLanguageModel(from: words, withFilesNamed: name, forAcousticModelAtPath: OEAcousticModel.path(toModel: accusticModelName))
        
        // let err: Error! = lmGenerator.generateGrammar(from: grammar, withFilesNamed: fileName, forAcousticModelAtPath: OEAcousticModel.path(toModel: accusticModelName))
        
        let err: Error! = lmGenerator.generateFastGrammar(from: grammar, withFilesNamed: fileName, forAcousticModelAtPath: OEAcousticModel.path(toModel: accusticModelName))
        
        var lmPath = &quot;&quot;
        var dictPath = &quot;&quot;
        
        if(err != nil) {
            print(&quot;Error while creating initial language model: \(err)&quot;)
        } else {
            // lmPath = lmGenerator.pathToSuccessfullyGeneratedLanguageModel(withRequestedName: fileName)
            lmPath = lmGenerator.pathToSuccessfullyGeneratedRuleORamaRuleset(withRequestedName: fileName)
            dictPath = lmGenerator.pathToSuccessfullyGeneratedDictionary(withRequestedName: fileName)
        }
        
        do {
            try OEPocketsphinxController.sharedInstance().setActive(true) // Setting the shared OEPocketsphinxController active is necessary before any of its properties are accessed.
        } catch {
            print(&quot;Error: it wasn&#039;t possible to set the shared instance to active: \&quot;\(error)\&quot;&quot;)
        }
        
        OEPocketsphinxController.sharedInstance().vadThreshold = 3.2;
    OEPocketsphinxController.sharedInstance().startListeningWithLanguageModel(atPath: lmPath, dictionaryAtPath: dictPath, acousticModelAtPath: OEAcousticModel.path(toModel: accusticModelName), languageModelIsJSGF: true)
    }

    override func didReceiveMemoryWarning() {
        super.didReceiveMemoryWarning()
        // Dispose of any resources that can be recreated.
    }
    
    func pocketsphinxDidReceiveHypothesis(_ hypothesis: String!, recognitionScore: String!, utteranceID: String!) { // Something was heard
        print(&quot;Local callback: The received hypothesis is \(hypothesis!) with a score of \(recognitionScore!) and an ID of \(utteranceID!)&quot;)
    }
    
    // An optional delegate method of OEEventsObserver which informs that the Pocketsphinx recognition loop has entered its actual loop.
    // This might be useful in debugging a conflict between another sound class and Pocketsphinx.
    func pocketsphinxRecognitionLoopDidStart() {
        print(&quot;Local callback: Pocketsphinx started.&quot;) // Log it.
    }
    
    // An optional delegate method of OEEventsObserver which informs that Pocketsphinx is now listening for speech.
    func pocketsphinxDidStartListening() {
        print(&quot;Local callback: Pocketsphinx is now listening.&quot;) // Log it.
    }
    
    // An optional delegate method of OEEventsObserver which informs that Pocketsphinx detected speech and is starting to process it.
    func pocketsphinxDidDetectSpeech() {
        print(&quot;Local callback: Pocketsphinx has detected speech.&quot;) // Log it.
    }
    
    // An optional delegate method of OEEventsObserver which informs that Pocketsphinx detected a second of silence, indicating the end of an utterance.
    func pocketsphinxDidDetectFinishedSpeech() {
        print(&quot;Local callback: Pocketsphinx has detected a second of silence, concluding an utterance.&quot;) // Log it.
    }
    
    // An optional delegate method of OEEventsObserver which informs that Pocketsphinx has exited its recognition loop, most
    // likely in response to the OEPocketsphinxController being told to stop listening via the stopListening method.
    func pocketsphinxDidStopListening() {
        print(&quot;Local callback: Pocketsphinx has stopped listening.&quot;) // Log it.
    }
    
    // An optional delegate method of OEEventsObserver which informs that Pocketsphinx is still in its listening loop but it is not
    // Going to react to speech until listening is resumed.  This can happen as a result of Flite speech being
    // in progress on an audio route that doesn&#039;t support simultaneous Flite speech and Pocketsphinx recognition,
    // or as a result of the OEPocketsphinxController being told to suspend recognition via the suspendRecognition method.
    func pocketsphinxDidSuspendRecognition() {
        print(&quot;Local callback: Pocketsphinx has suspended recognition.&quot;) // Log it.
    }
    
    // An optional delegate method of OEEventsObserver which informs that Pocketsphinx is still in its listening loop and after recognition
    // having been suspended it is now resuming.  This can happen as a result of Flite speech completing
    // on an audio route that doesn&#039;t support simultaneous Flite speech and Pocketsphinx recognition,
    // or as a result of the OEPocketsphinxController being told to resume recognition via the resumeRecognition method.
    func pocketsphinxDidResumeRecognition() {
        print(&quot;Local callback: Pocketsphinx has resumed recognition.&quot;) // Log it.
    }
    
    // An optional delegate method which informs that Pocketsphinx switched over to a new language model at the given URL in the course of
    // recognition. This does not imply that it is a valid file or that recognition will be successful using the file.
    func pocketsphinxDidChangeLanguageModel(toFile newLanguageModelPathAsString: String!, andDictionary newDictionaryPathAsString: String!) {
        
        print(&quot;Local callback: Pocketsphinx is now using the following language model: \n\(newLanguageModelPathAsString!) and the following dictionary: \(newDictionaryPathAsString!)&quot;)
    }
    
    // An optional delegate method of OEEventsObserver which informs that Flite is speaking, most likely to be useful if debugging a
    // complex interaction between sound classes. You don&#039;t have to do anything yourself in order to prevent Pocketsphinx from listening to Flite talk and trying to recognize the speech.
    func fliteDidStartSpeaking() {
        print(&quot;Local callback: Flite has started speaking&quot;) // Log it.
    }
    
    // An optional delegate method of OEEventsObserver which informs that Flite is finished speaking, most likely to be useful if debugging a
    // complex interaction between sound classes.
    func fliteDidFinishSpeaking() {
        print(&quot;Local callback: Flite has finished speaking&quot;) // Log it.
    }
    
    func pocketSphinxContinuousSetupDidFail(withReason reasonForFailure: String!) { // This can let you know that something went wrong with the recognition loop startup. Turn on [OELogging startOpenEarsLogging] to learn why.
        print(&quot;Local callback: Setting up the continuous recognition loop has failed for the reason \(reasonForFailure), please turn on OELogging.startOpenEarsLogging() to learn more.&quot;) // Log it.
    }
    
    func pocketSphinxContinuousTeardownDidFail(withReason reasonForFailure: String!) { // This can let you know that something went wrong with the recognition loop startup. Turn on OELogging.startOpenEarsLogging() to learn why.
        print(&quot;Local callback: Tearing down the continuous recognition loop has failed for the reason \(reasonForFailure)&quot;) // Log it.
    }
    
    /** Pocketsphinx couldn&#039;t start because it has no mic permissions (will only be returned on iOS7 or later).*/
    func pocketsphinxFailedNoMicPermissions() {
        print(&quot;Local callback: The user has never set mic permissions or denied permission to this app&#039;s mic, so listening will not start.&quot;)
    }
    
    /** The user prompt to get mic permissions, or a check of the mic permissions, has completed with a true or a false result  (will only be returned on iOS7 or later).*/
    
    func micPermissionCheckCompleted(withResult: Bool) {
        print(&quot;Local callback: mic check completed.&quot;)
    }
}</code></pre>

		
	</div>
<!-- .bbp-reply-content -->
</div>
<!-- .reply -->

			
				
<div id="post-1032405" class="bbp-reply-header">
	<div class="bbp-meta">
		<span class="bbp-reply-post-date">April 26, 2018 at 5:00 pm</span>

		
			<span class="bbp-header">
				in reply to: 				<a class="bbp-topic-permalink" href="/forums/topic/recognize-short-command-in-nonenglish/">Recognize short Command in nonEnglish</a>
			</span>

		
		<a href="/forums/topic/recognize-short-command-in-nonenglish/#post-1032405" class="bbp-reply-permalink">#1032405</a>

		
		<span class="bbp-admin-links"></span>
		
	</div>
<!-- .bbp-meta -->
</div>
<!-- #post-1032405 -->

<div class="loop-item-9 user-id-2480 bbp-parent-forum-3654 bbp-parent-topic-1032298 bbp-reply-position-70 even topic-author  post-1032405 reply type-reply status-publish hentry">
	<div class="bbp-reply-author">

		
		<a href="/forums/profile/ikk/" title="View iKK&#039;s profile" class="bbp-author-link"><span class="bbp-author-avatar"></span><span class="bbp-author-name">iKK</span></a><div class="bbp-author-role">Participant</div>
		
		
	</div>
<!-- .bbp-reply-author -->

	<div class="bbp-reply-content">

		
		<p>Can we now approach the RuleORama error ?</p>
<p>I feel that having both up&#8217;n&#8217;running (Rejecto and RuleORama) would help to compare the solutions to find the best approach.</p>
<p>Here is the Language-model creation of RuleORama (see next forum-entry) and its Error-log (see after-next forum-entry).</p>

		
	</div>
<!-- .bbp-reply-content -->
</div>
<!-- .reply -->

			
				
<div id="post-1032404" class="bbp-reply-header">
	<div class="bbp-meta">
		<span class="bbp-reply-post-date">April 26, 2018 at 4:56 pm</span>

		
			<span class="bbp-header">
				in reply to: 				<a class="bbp-topic-permalink" href="/forums/topic/recognize-short-command-in-nonenglish/">Recognize short Command in nonEnglish</a>
			</span>

		
		<a href="/forums/topic/recognize-short-command-in-nonenglish/#post-1032404" class="bbp-reply-permalink">#1032404</a>

		
		<span class="bbp-admin-links"></span>
		
	</div>
<!-- .bbp-meta -->
</div>
<!-- #post-1032404 -->

<div class="loop-item-10 user-id-2480 bbp-parent-forum-3654 bbp-parent-topic-1032298 bbp-reply-position-69 odd topic-author  post-1032404 reply type-reply status-publish hentry">
	<div class="bbp-reply-author">

		
		<a href="/forums/profile/ikk/" title="View iKK&#039;s profile" class="bbp-author-link"><span class="bbp-author-avatar"></span><span class="bbp-author-name">iKK</span></a><div class="bbp-author-role">Participant</div>
		
		
	</div>
<!-- .bbp-reply-author -->

	<div class="bbp-reply-content">

		
		<p>This helped !</p>
<p>This is the first time Rejecto seems to peform :) Thank you very much !</p>
<p>Now, I tested both A) and B) and it indeed makes a slight difference.</p>
<p>A)</p>
<pre><code>es	ee s
eschdonofrey	@ ss d oo n oo f r @ ii
esf	ee s f</code></pre>
<p>B)</p>
<pre><code>es  ee s
eschdonofrey    ee ss d oo n oo f r ee ii
esf ee s f</code></pre>
<p>As for A, this seems to perform slightly better than B.</p>
<p>However, even for A there are many false-positives ! And also 1 out of 10 is a false-negative (which I never had in any of the previous tests).</p>
<p>At least, this is something to play now&#8230;.</p>
<p>One question:<br>
What does the symbol &#8220;@&#8221; represent in the LookupList.text ? (the double-ee&#8217;s and double-ii&#8217;s I can somehow intereprete but what does &#8220;@&#8221; really mean ?)</p>

		
	</div>
<!-- .bbp-reply-content -->
</div>
<!-- .reply -->

			
				
<div id="post-1032402" class="bbp-reply-header">
	<div class="bbp-meta">
		<span class="bbp-reply-post-date">April 26, 2018 at 4:34 pm</span>

		
			<span class="bbp-header">
				in reply to: 				<a class="bbp-topic-permalink" href="/forums/topic/recognize-short-command-in-nonenglish/">Recognize short Command in nonEnglish</a>
			</span>

		
		<a href="/forums/topic/recognize-short-command-in-nonenglish/#post-1032402" class="bbp-reply-permalink">#1032402</a>

		
		<span class="bbp-admin-links"></span>
		
	</div>
<!-- .bbp-meta -->
</div>
<!-- #post-1032402 -->

<div class="loop-item-11 user-id-2480 bbp-parent-forum-3654 bbp-parent-topic-1032298 bbp-reply-position-67 even topic-author  post-1032402 reply type-reply status-publish hentry">
	<div class="bbp-reply-author">

		
		<a href="/forums/profile/ikk/" title="View iKK&#039;s profile" class="bbp-author-link"><span class="bbp-author-avatar"></span><span class="bbp-author-name">iKK</span></a><div class="bbp-author-role">Participant</div>
		
		
	</div>
<!-- .bbp-reply-author -->

	<div class="bbp-reply-content">

		
		<p>Rejecto Language Model creation as it looks right now &#8211; still giving an error on startup&#8230;</p>
<pre><code>import UIKit

class ViewController: UIViewController, OEEventsObserverDelegate {
    
    var openEarsEventsObserver = OEEventsObserver()

    override func viewDidLoad() {
        super.viewDidLoad()
        // Do any additional setup after loading the view, typically from a nib.
        
        // ************* Necessary for logging **************************
        OELogging.startOpenEarsLogging() //Uncomment to receive full OpenEars logging in case of any unexpected results.
        OEPocketsphinxController.sharedInstance().verbosePocketSphinx = true
        // ************* Necessary for logging **************************
        
        self.openEarsEventsObserver.delegate = self
        
        let lmGenerator = OELanguageModelGenerator()
        let accusticModelName = &quot;AcousticModelGerman&quot;
        
        let fileName = &quot;GermanModel&quot;
        
        // let words = [&quot;esch do no frey&quot;]
        let words = [&quot;eschdonofrey&quot;]
        
        // let err: Error! = lmGenerator.generateLanguageModel(from: words, withFilesNamed: name, forAcousticModelAtPath: OEAcousticModel.path(toModel: accusticModelName))
        
        let err: Error! = lmGenerator.generateRejectingLanguageModel(from: words, withFilesNamed: fileName, withOptionalExclusions: nil, usingVowelsOnly: false, withWeight: 1.0, forAcousticModelAtPath: OEAcousticModel.path(toModel: accusticModelName))
        
        var lmPath = &quot;&quot;
        var dictPath = &quot;&quot;
        
        if(err != nil) {
            print(&quot;Error while creating initial language model: \(err)&quot;)
        } else {
            // lmPath = lmGenerator.pathToSuccessfullyGeneratedLanguageModel(withRequestedName: fileName)
            lmPath = lmGenerator.pathToSuccessfullyGeneratedGrammar(withRequestedName: fileName)
            dictPath = lmGenerator.pathToSuccessfullyGeneratedDictionary(withRequestedName: fileName)
        }
        
        do {
            try OEPocketsphinxController.sharedInstance().setActive(true) // Setting the shared OEPocketsphinxController active is necessary before any of its properties are accessed.
        } catch {
            print(&quot;Error: it wasn&#039;t possible to set the shared instance to active: \&quot;\(error)\&quot;&quot;)
        }
        
        OEPocketsphinxController.sharedInstance().vadThreshold = 3.2;
    OEPocketsphinxController.sharedInstance().startListeningWithLanguageModel(atPath: lmPath, dictionaryAtPath: dictPath, acousticModelAtPath: OEAcousticModel.path(toModel: accusticModelName), languageModelIsJSGF: false)
        
    }

    override func didReceiveMemoryWarning() {
        super.didReceiveMemoryWarning()
        // Dispose of any resources that can be recreated.
    }
    
    func pocketsphinxDidReceiveHypothesis(_ hypothesis: String!, recognitionScore: String!, utteranceID: String!) { // Something was heard
        print(&quot;Local callback: The received hypothesis is \(hypothesis!) with a score of \(recognitionScore!) and an ID of \(utteranceID!)&quot;)
    }
    
    // An optional delegate method of OEEventsObserver which informs that the Pocketsphinx recognition loop has entered its actual loop.
    // This might be useful in debugging a conflict between another sound class and Pocketsphinx.
    func pocketsphinxRecognitionLoopDidStart() {
        print(&quot;Local callback: Pocketsphinx started.&quot;) // Log it.
    }
    
    // An optional delegate method of OEEventsObserver which informs that Pocketsphinx is now listening for speech.
    func pocketsphinxDidStartListening() {
        print(&quot;Local callback: Pocketsphinx is now listening.&quot;) // Log it.
    }
    
    // An optional delegate method of OEEventsObserver which informs that Pocketsphinx detected speech and is starting to process it.
    func pocketsphinxDidDetectSpeech() {
        print(&quot;Local callback: Pocketsphinx has detected speech.&quot;) // Log it.
    }
    
    // An optional delegate method of OEEventsObserver which informs that Pocketsphinx detected a second of silence, indicating the end of an utterance.
    func pocketsphinxDidDetectFinishedSpeech() {
        print(&quot;Local callback: Pocketsphinx has detected a second of silence, concluding an utterance.&quot;) // Log it.
    }
    
    // An optional delegate method of OEEventsObserver which informs that Pocketsphinx has exited its recognition loop, most
    // likely in response to the OEPocketsphinxController being told to stop listening via the stopListening method.
    func pocketsphinxDidStopListening() {
        print(&quot;Local callback: Pocketsphinx has stopped listening.&quot;) // Log it.
    }
    
    // An optional delegate method of OEEventsObserver which informs that Pocketsphinx is still in its listening loop but it is not
    // Going to react to speech until listening is resumed.  This can happen as a result of Flite speech being
    // in progress on an audio route that doesn&#039;t support simultaneous Flite speech and Pocketsphinx recognition,
    // or as a result of the OEPocketsphinxController being told to suspend recognition via the suspendRecognition method.
    func pocketsphinxDidSuspendRecognition() {
        print(&quot;Local callback: Pocketsphinx has suspended recognition.&quot;) // Log it.
    }
    
    // An optional delegate method of OEEventsObserver which informs that Pocketsphinx is still in its listening loop and after recognition
    // having been suspended it is now resuming.  This can happen as a result of Flite speech completing
    // on an audio route that doesn&#039;t support simultaneous Flite speech and Pocketsphinx recognition,
    // or as a result of the OEPocketsphinxController being told to resume recognition via the resumeRecognition method.
    func pocketsphinxDidResumeRecognition() {
        print(&quot;Local callback: Pocketsphinx has resumed recognition.&quot;) // Log it.
    }
    
    // An optional delegate method which informs that Pocketsphinx switched over to a new language model at the given URL in the course of
    // recognition. This does not imply that it is a valid file or that recognition will be successful using the file.
    func pocketsphinxDidChangeLanguageModel(toFile newLanguageModelPathAsString: String!, andDictionary newDictionaryPathAsString: String!) {
        
        print(&quot;Local callback: Pocketsphinx is now using the following language model: \n\(newLanguageModelPathAsString!) and the following dictionary: \(newDictionaryPathAsString!)&quot;)
    }
    
    // An optional delegate method of OEEventsObserver which informs that Flite is speaking, most likely to be useful if debugging a
    // complex interaction between sound classes. You don&#039;t have to do anything yourself in order to prevent Pocketsphinx from listening to Flite talk and trying to recognize the speech.
    func fliteDidStartSpeaking() {
        print(&quot;Local callback: Flite has started speaking&quot;) // Log it.
    }
    
    // An optional delegate method of OEEventsObserver which informs that Flite is finished speaking, most likely to be useful if debugging a
    // complex interaction between sound classes.
    func fliteDidFinishSpeaking() {
        print(&quot;Local callback: Flite has finished speaking&quot;) // Log it.
    }
    
    func pocketSphinxContinuousSetupDidFail(withReason reasonForFailure: String!) { // This can let you know that something went wrong with the recognition loop startup. Turn on [OELogging startOpenEarsLogging] to learn why.
        print(&quot;Local callback: Setting up the continuous recognition loop has failed for the reason \(reasonForFailure), please turn on OELogging.startOpenEarsLogging() to learn more.&quot;) // Log it.
    }
    
    func pocketSphinxContinuousTeardownDidFail(withReason reasonForFailure: String!) { // This can let you know that something went wrong with the recognition loop startup. Turn on OELogging.startOpenEarsLogging() to learn why.
        print(&quot;Local callback: Tearing down the continuous recognition loop has failed for the reason \(reasonForFailure)&quot;) // Log it.
    }
    
    /** Pocketsphinx couldn&#039;t start because it has no mic permissions (will only be returned on iOS7 or later).*/
    func pocketsphinxFailedNoMicPermissions() {
        print(&quot;Local callback: The user has never set mic permissions or denied permission to this app&#039;s mic, so listening will not start.&quot;)
    }
    
    /** The user prompt to get mic permissions, or a check of the mic permissions, has completed with a true or a false result  (will only be returned on iOS7 or later).*/
    
    func micPermissionCheckCompleted(withResult: Bool) {
        print(&quot;Local callback: mic check completed.&quot;)
    }
}</code></pre>

		
	</div>
<!-- .bbp-reply-content -->
</div>
<!-- .reply -->

			
				
<div id="post-1032401" class="bbp-reply-header">
	<div class="bbp-meta">
		<span class="bbp-reply-post-date">April 26, 2018 at 4:34 pm</span>

		
			<span class="bbp-header">
				in reply to: 				<a class="bbp-topic-permalink" href="/forums/topic/recognize-short-command-in-nonenglish/">Recognize short Command in nonEnglish</a>
			</span>

		
		<a href="/forums/topic/recognize-short-command-in-nonenglish/#post-1032401" class="bbp-reply-permalink">#1032401</a>

		
		<span class="bbp-admin-links"></span>
		
	</div>
<!-- .bbp-meta -->
</div>
<!-- #post-1032401 -->

<div class="loop-item-12 user-id-2480 bbp-parent-forum-3654 bbp-parent-topic-1032298 bbp-reply-position-66 odd topic-author  post-1032401 reply type-reply status-publish hentry">
	<div class="bbp-reply-author">

		
		<a href="/forums/profile/ikk/" title="View iKK&#039;s profile" class="bbp-author-link"><span class="bbp-author-avatar"></span><span class="bbp-author-name">iKK</span></a><div class="bbp-author-role">Participant</div>
		
		
	</div>
<!-- .bbp-reply-author -->

	<div class="bbp-reply-content">

		
		<p>Log from Rejecto trial :</p>
<pre><code>2018-04-26 16:31:28.384594+0200 TestOpenEars[972:261652] Starting OpenEars logging for OpenEars version 2.506 on 64-bit device (or build): iPhone running iOS version: 11.300000
2018-04-26 16:31:28.385406+0200 TestOpenEars[972:261652] Creating shared instance of OEPocketsphinxController
2018-04-26 16:31:28.397524+0200 TestOpenEars[972:261652] Rejecto version 2.500000
2018-04-26 16:31:28.398126+0200 TestOpenEars[972:261652] Since there is no cached version, loading the g2p model for the acoustic model called AcousticModelGerman
2018-04-26 16:31:28.454973+0200 TestOpenEars[972:261652] Since there is no cached version, loading the language model lookup list for the acoustic model called AcousticModelGerman
2018-04-26 16:31:28.459570+0200 TestOpenEars[972:261652] Returning a cached version of LanguageModelGeneratorLookupList.text
2018-04-26 16:31:28.459643+0200 TestOpenEars[972:261652] Returning a cached version of g2p
2018-04-26 16:31:28.460388+0200 TestOpenEars[972:261652] I&#039;m done running performDictionaryLookup and it took 0.000772 seconds
2018-04-26 16:31:28.460671+0200 TestOpenEars[972:261652] I&#039;m done running performDictionaryLookup and it took 0.001317 seconds
2018-04-26 16:31:28.463842+0200 TestOpenEars[972:261652] A value has been given for weight, but it is identical to the default so we are ignoring it.
2018-04-26 16:31:28.463878+0200 TestOpenEars[972:261652] Starting dynamic language model generation

INFO: ngram_model_arpa_legacy.c(504): ngrams 1=45, 2=86, 3=43
INFO: ngram_model_arpa_legacy.c(136): Reading unigrams
INFO: ngram_model_arpa_legacy.c(543):       45 = #unigrams created
INFO: ngram_model_arpa_legacy.c(196): Reading bigrams
INFO: ngram_model_arpa_legacy.c(561):       86 = #bigrams created
INFO: ngram_model_arpa_legacy.c(562):        3 = #prob2 entries
INFO: ngram_model_arpa_legacy.c(570):        3 = #bo_wt2 entries
INFO: ngram_model_arpa_legacy.c(293): Reading trigrams
INFO: ngram_model_arpa_legacy.c(583):       43 = #trigrams created
INFO: ngram_model_arpa_legacy.c(584):        2 = #prob3 entries
INFO: ngram_model_dmp_legacy.c(521): Building DMP model...
INFO: ngram_model_dmp_legacy.c(551):       45 = #unigrams created
INFO: ngram_model_dmp_legacy.c(652):       86 = #bigrams created
INFO: ngram_model_dmp_legacy.c(653):        3 = #prob2 entries
INFO: ngram_model_dmp_legacy.c(660):        3 = #bo_wt2 entries
INFO: ngram_model_dmp_legacy.c(664):       43 = #trigrams created
INFO: ngram_model_dmp_legacy.c(665):        2 = #prob3 entries
2018-04-26 16:31:28.485473+0200 TestOpenEars[972:261652] Done creating language model with CMUCLMTK in 0.021533 seconds.
INFO: ngram_model_arpa_legacy.c(504): ngrams 1=45, 2=86, 3=43
INFO: ngram_model_arpa_legacy.c(136): Reading unigrams
INFO: ngram_model_arpa_legacy.c(543):       45 = #unigrams created
INFO: ngram_model_arpa_legacy.c(196): Reading bigrams
INFO: ngram_model_arpa_legacy.c(561):       86 = #bigrams created
INFO: ngram_model_arpa_legacy.c(562):        3 = #prob2 entries
INFO: ngram_model_arpa_legacy.c(570):        3 = #bo_wt2 entries
INFO: ngram_model_arpa_legacy.c(293): Reading trigrams
INFO: ngram_model_arpa_legacy.c(583):       43 = #trigrams created
INFO: ngram_model_arpa_legacy.c(584):        2 = #prob3 entries
INFO: ngram_model_dmp_legacy.c(521): Building DMP model...
INFO: ngram_model_dmp_legacy.c(551):       45 = #unigrams created
INFO: ngram_model_dmp_legacy.c(652):       86 = #bigrams created
INFO: ngram_model_dmp_legacy.c(653):        3 = #prob2 entries
INFO: ngram_model_dmp_legacy.c(660):        3 = #bo_wt2 entries
INFO: ngram_model_dmp_legacy.c(664):       43 = #trigrams created
INFO: ngram_model_dmp_legacy.c(665):        2 = #prob3 entries
2018-04-26 16:31:28.489123+0200 TestOpenEars[972:261652] I&#039;m done running dynamic language model generation and it took 0.091080 seconds
2018-04-26 16:31:28.489559+0200 TestOpenEars[972:261652] Attempting to start listening session from startListeningWithLanguageModelAtPath:
2018-04-26 16:31:28.492174+0200 TestOpenEars[972:261652] User gave mic permission for this app.
2018-04-26 16:31:28.492310+0200 TestOpenEars[972:261652] setSecondsOfSilence wasn&#039;t set, using default of 0.700000.
2018-04-26 16:31:28.492653+0200 TestOpenEars[972:261771] Starting listening.
2018-04-26 16:31:28.492840+0200 TestOpenEars[972:261771] About to set up audio session
2018-04-26 16:31:28.576329+0200 TestOpenEars[972:261771] Creating audio session with default settings.
2018-04-26 16:31:28.576380+0200 TestOpenEars[972:261771] Done setting audio session category.
2018-04-26 16:31:28.582877+0200 TestOpenEars[972:261771] Done setting preferred sample rate to 16000.000000 – now the real sample rate is 48000.000000
2018-04-26 16:31:28.583434+0200 TestOpenEars[972:261771] number of channels is already the preferred number of 1 so not setting it.
2018-04-26 16:31:28.586772+0200 TestOpenEars[972:261771] Done setting session&#039;s preferred I/O buffer duration to 0.128000 – now the actual buffer duration is 0.085333
2018-04-26 16:31:28.586817+0200 TestOpenEars[972:261771] Done setting up audio session
2018-04-26 16:31:28.588052+0200 TestOpenEars[972:261785] Audio route has changed for the following reason:
2018-04-26 16:31:28.590354+0200 TestOpenEars[972:261771] About to set up audio IO unit in a session with a sample rate of 48000.000000, a channel number of 1 and a buffer duration of 0.085333.
2018-04-26 16:31:28.624144+0200 TestOpenEars[972:261785] There was a category change. The new category is AVAudioSessionCategoryPlayAndRecord
2018-04-26 16:31:28.674501+0200 TestOpenEars[972:261785] This is not a case in which OpenEars notifies of a route change. At the close of this method, the new audio route will be &lt;Input route or routes: &quot;MicrophoneBuiltIn&quot;. Output route or routes: &quot;Speaker&quot;&gt;. The previous route before changing to this route was &quot;&lt;AVAudioSessionRouteDescription: 0x1c0405c00, 
inputs = (null); 
outputs = (
    &quot;&lt;AVAudioSessionPortDescription: 0x1c0405750, type = Speaker; name = Speaker; UID = Speaker; selectedDataSource = (null)&gt;&quot;
)&gt;&quot;.
2018-04-26 16:31:28.676633+0200 TestOpenEars[972:261785] Audio route has changed for the following reason:
2018-04-26 16:31:28.678797+0200 TestOpenEars[972:261785] There was a category change. The new category is AVAudioSessionCategoryPlayAndRecord
2018-04-26 16:31:28.681564+0200 TestOpenEars[972:261771] Done setting up audio unit
2018-04-26 16:31:28.681601+0200 TestOpenEars[972:261771] About to start audio IO unit
2018-04-26 16:31:28.682725+0200 TestOpenEars[972:261785] This is not a case in which OpenEars notifies of a route change. At the close of this method, the new audio route will be &lt;Input route or routes: &quot;MicrophoneBuiltIn&quot;. Output route or routes: &quot;Speaker&quot;&gt;. The previous route before changing to this route was &quot;&lt;AVAudioSessionRouteDescription: 0x1c0405bf0, 
inputs = (
    &quot;&lt;AVAudioSessionPortDescription: 0x1c0405c80, type = MicrophoneBuiltIn; name = iPhone Microphone; UID = Built-In Microphone; selectedDataSource = Bottom&gt;&quot;
); 
outputs = (
    &quot;&lt;AVAudioSessionPortDescription: 0x1c421b890, type = Receiver; name = Receiver; UID = Built-In Receiver; selectedDataSource = (null)&gt;&quot;
)&gt;&quot;.
2018-04-26 16:31:28.888849+0200 TestOpenEars[972:261771] Done starting audio unit
2018-04-26 16:31:28.888907+0200 TestOpenEars[972:261771] The file you&#039;ve sent to the decoder appears to be a JSGF grammar based on its naming, but you have not set languageModelIsJSGF: to TRUE. If you are experiencing recognition issues, there is a good chance that this is the reason for it. This can also happen if you meant to use the method [OELanguageModelGenerator pathToSuccessfullyGeneratedLanguageModelWithRequestedName:] to obtain a language model path but unintentionally used the method [OELanguageModelGenerator pathToSuccessfullyGeneratedGrammarWithRequestedName:] instead.
INFO: pocketsphinx.c(145): Parsed model-specific feature parameters from /var/containers/Bundle/Application/B43039EB-3F1B-427A-9364-199FBEB79021/TestOpenEars.app/AcousticModelGerman.bundle/feat.params
Current configuration:
[NAME]			[DEFLT]		[VALUE]
-agc			none		none
-agcthresh		2.0		2.000000e+00
-allphone				
-allphone_ci		no		no
-alpha			0.97		9.700000e-01
-ascale			20.0		2.000000e+01
-aw			1		1
-backtrace		no		no
-beam			1e-48		1.000000e-48
-bestpath		yes		yes
-bestpathlw		9.5		9.500000e+00
-ceplen			13		13
-cmn			current		current
-cmninit		8.0		30
-compallsen		no		no
-debug					0
-dict					/var/mobile/Containers/Data/Application/4BEF6CDF-6561-47C4-AF08-F8C54C84EBEF/Library/Caches/GermanModel.dic
-dictcase		no		no
-dither			no		no
-doublebw		no		no
-ds			1		1
-fdict					/var/containers/Bundle/Application/B43039EB-3F1B-427A-9364-199FBEB79021/TestOpenEars.app/AcousticModelGerman.bundle/noisedict
-feat			1s_c_d_dd	1s_c_d_dd
-featparams				/var/containers/Bundle/Application/B43039EB-3F1B-427A-9364-199FBEB79021/TestOpenEars.app/AcousticModelGerman.bundle/feat.params
-fillprob		1e-8		1.000000e-08
-frate			100		100
-fsg					
-fsgusealtpron		yes		yes
-fsgusefiller		yes		yes
-fwdflat		yes		yes
-fwdflatbeam		1e-64		1.000000e-64
-fwdflatefwid		4		4
-fwdflatlw		8.5		8.500000e+00
-fwdflatsfwin		25		25
-fwdflatwbeam		7e-29		7.000000e-29
-fwdtree		yes		yes
-hmm					/var/containers/Bundle/Application/B43039EB-3F1B-427A-9364-199FBEB79021/TestOpenEars.app/AcousticModelGerman.bundle
-input_endian		little		little
-jsgf					
-keyphrase				
-kws					
-kws_delay		10		10
-kws_plp		1e-1		1.000000e-01
-kws_threshold		1		1.000000e+00
-latsize		5000		5000
-lda					
-ldadim			0		0
-lifter			0		22
-lm					/var/mobile/Containers/Data/Application/4BEF6CDF-6561-47C4-AF08-F8C54C84EBEF/Library/Caches/GermanModel.gram
-lmctl					
-lmname					
-logbase		1.0001		1.000100e+00
-logfn					
-logspec		no		no
-lowerf			133.33334	1.300000e+02
-lpbeam			1e-40		1.000000e-40
-lponlybeam		7e-29		7.000000e-29
-lw			6.5		6.500000e+00
-maxhmmpf		30000		30000
-maxwpf			-1		-1
-mdef					/var/containers/Bundle/Application/B43039EB-3F1B-427A-9364-199FBEB79021/TestOpenEars.app/AcousticModelGerman.bundle/mdef
-mean					/var/containers/Bundle/Application/B43039EB-3F1B-427A-9364-199FBEB79021/TestOpenEars.app/AcousticModelGerman.bundle/means
-mfclogdir				
-min_endfr		0		0
-mixw					/var/containers/Bundle/Application/B43039EB-3F1B-427A-9364-199FBEB79021/TestOpenEars.app/AcousticModelGerman.bundle/mixture_weights
-mixwfloor		0.0000001	1.000000e-07
-mllr					
-mmap			yes		yes
-ncep			13		13
-nfft			512		512
-nfilt			40		25
-nwpen			1.0		1.000000e+00
-pbeam			1e-48		1.000000e-48
-pip			1.0		1.000000e+00
-pl_beam		1e-10		1.000000e-10
-pl_pbeam		1e-10		1.000000e-10
-pl_pip			1.0		1.000000e+00
-pl_weight		3.0		3.000000e+00
-pl_window		5		5
-rawlogdir				
-remove_dc		no		no
-remove_noise		yes		yes
-remove_silence		yes		yes
-round_filters		yes		yes
-samprate		16000		1.600000e+04
-seed			-1		-1
-sendump				
-senlogdir				
-senmgau				
-silprob		0.005		5.000000e-03
-smoothspec		no		no
-svspec					
-tmat					/var/containers/Bundle/Application/B43039EB-3F1B-427A-9364-199FBEB79021/TestOpenEars.app/AcousticModelGerman.bundle/transition_matrices
-tmatfloor		0.0001		1.000000e-04
-topn			4		4
-topn_beam		0		0
-toprule				
-transform		legacy		dct
-unit_area		yes		yes
-upperf			6855.4976	6.800000e+03
-uw			1.0		1.000000e+00
-vad_postspeech		50		69
-vad_prespeech		20		10
-vad_startspeech	10		10
-vad_threshold		2.0		3.200000e+00
-var					/var/containers/Bundle/Application/B43039EB-3F1B-427A-9364-199FBEB79021/TestOpenEars.app/AcousticModelGerman.bundle/variances
-varfloor		0.0001		1.000000e-04
-varnorm		no		no
-verbose		no		no
-warp_params				
-warp_type		inverse_linear	inverse_linear
-wbeam			7e-29		7.000000e-29
-wip			0.65		6.500000e-01
-wlen			0.025625	2.562500e-02

INFO: feat.c(715): Initializing feature stream to type: &#039;1s_c_d_dd&#039;, ceplen=13, CMN=&#039;current&#039;, VARNORM=&#039;no&#039;, AGC=&#039;none&#039;
INFO: cmn.c(143): mean[0]= 12.00, mean[1..12]= 0.0
INFO: mdef.c(518): Reading model definition: /var/containers/Bundle/Application/B43039EB-3F1B-427A-9364-199FBEB79021/TestOpenEars.app/AcousticModelGerman.bundle/mdef
INFO: bin_mdef.c(181): Allocating 53834 * 8 bytes (420 KiB) for CD tree
INFO: tmat.c(206): Reading HMM transition probability matrices: /var/containers/Bundle/Application/B43039EB-3F1B-427A-9364-199FBEB79021/TestOpenEars.app/AcousticModelGerman.bundle/transition_matrices
INFO: acmod.c(117): Attempting to use PTM computation module
INFO: ms_gauden.c(198): Reading mixture gaussian parameter: /var/containers/Bundle/Application/B43039EB-3F1B-427A-9364-199FBEB79021/TestOpenEars.app/AcousticModelGerman.bundle/means
INFO: ms_gauden.c(292): 2129 codebook, 1 feature, size: 
INFO: ms_gauden.c(294):  32x39
INFO: ms_gauden.c(198): Reading mixture gaussian parameter: /var/containers/Bundle/Application/B43039EB-3F1B-427A-9364-199FBEB79021/TestOpenEars.app/AcousticModelGerman.bundle/variances
INFO: ms_gauden.c(292): 2129 codebook, 1 feature, size: 
INFO: ms_gauden.c(294):  32x39
INFO: ms_gauden.c(354): 7100 variance values floored
INFO: ptm_mgau.c(801): Number of codebooks exceeds 256: 2129
INFO: acmod.c(119): Attempting to use semi-continuous computation module
INFO: ms_gauden.c(198): Reading mixture gaussian parameter: /var/containers/Bundle/Application/B43039EB-3F1B-427A-9364-199FBEB79021/TestOpenEars.app/AcousticModelGerman.bundle/means
INFO: ms_gauden.c(292): 2129 codebook, 1 feature, size: 
INFO: ms_gauden.c(294):  32x39
INFO: ms_gauden.c(198): Reading mixture gaussian parameter: /var/containers/Bundle/Application/B43039EB-3F1B-427A-9364-199FBEB79021/TestOpenEars.app/AcousticModelGerman.bundle/variances
INFO: ms_gauden.c(292): 2129 codebook, 1 feature, size: 
INFO: ms_gauden.c(294):  32x39
INFO: ms_gauden.c(354): 7100 variance values floored
INFO: acmod.c(121): Falling back to general multi-stream GMM computation
INFO: ms_gauden.c(198): Reading mixture gaussian parameter: /var/containers/Bundle/Application/B43039EB-3F1B-427A-9364-199FBEB79021/TestOpenEars.app/AcousticModelGerman.bundle/means
INFO: ms_gauden.c(292): 2129 codebook, 1 feature, size: 
INFO: ms_gauden.c(294):  32x39
INFO: ms_gauden.c(198): Reading mixture gaussian parameter: /var/containers/Bundle/Application/B43039EB-3F1B-427A-9364-199FBEB79021/TestOpenEars.app/AcousticModelGerman.bundle/variances
INFO: ms_gauden.c(292): 2129 codebook, 1 feature, size: 
INFO: ms_gauden.c(294):  32x39
INFO: ms_gauden.c(354): 7100 variance values floored
INFO: ms_senone.c(149): Reading senone mixture weights: /var/containers/Bundle/Application/B43039EB-3F1B-427A-9364-199FBEB79021/TestOpenEars.app/AcousticModelGerman.bundle/mixture_weights
INFO: ms_senone.c(200): Truncating senone logs3(pdf) values by 10 bits
INFO: ms_senone.c(207): Not transposing mixture weights in memory
INFO: ms_senone.c(268): Read mixture weights for 2129 senones: 1 features x 32 codewords
INFO: ms_senone.c(320): Mapping senones to individual codebooks
INFO: ms_mgau.c(141): The value of topn: 4
INFO: phone_loop_search.c(114): State beam -225 Phone exit beam -225 Insertion penalty 0
INFO: dict.c(320): Allocating 4143 * 32 bytes (129 KiB) for word entries
INFO: dict.c(333): Reading main dictionary: /var/mobile/Containers/Data/Application/4BEF6CDF-6561-47C4-AF08-F8C54C84EBEF/Library/Caches/GermanModel.dic
INFO: dict.c(213): Allocated 0 KiB for strings, 0 KiB for phones
INFO: dict.c(336): 43 words read
INFO: dict.c(358): Reading filler dictionary: /var/containers/Bundle/Application/B43039EB-3F1B-427A-9364-199FBEB79021/TestOpenEars.app/AcousticModelGerman.bundle/noisedict
INFO: dict.c(213): Allocated 0 KiB for strings, 0 KiB for phones
INFO: dict.c(361): 4 words read
INFO: dict2pid.c(396): Building PID tables for dictionary
INFO: dict2pid.c(406): Allocating 43^3 * 2 bytes (155 KiB) for word-initial triphones
INFO: dict2pid.c(132): Allocated 44720 bytes (43 KiB) for word-final triphones
INFO: dict2pid.c(196): Allocated 44720 bytes (43 KiB) for single-phone word triphones
INFO: ngram_model_trie.c(424): Trying to read LM in bin format
ERROR: &quot;ngram_model_trie.c&quot;, line 447: bin file /var/mobile/Containers/Data/Application/4BEF6CDF-6561-47C4-AF08-F8C54C84EBEF/Library/Caches/GermanModel.gram not found
INFO: ngram_model_trie.c(180): Trying to read LM in arpa format
ERROR: &quot;ngram_model_trie.c&quot;, line 203: arpa file /var/mobile/Containers/Data/Application/4BEF6CDF-6561-47C4-AF08-F8C54C84EBEF/Library/Caches/GermanModel.gram not found
INFO: ngram_model_trie.c(537): Trying to read LM in DMP format
ERROR: &quot;ngram_model_trie.c&quot;, line 560: DMP file /var/mobile/Containers/Data/Application/4BEF6CDF-6561-47C4-AF08-F8C54C84EBEF/Library/Caches/GermanModel.gram not found
2018-04-26 16:31:29.361202+0200 TestOpenEars[972:261771] Error: it wasn&#039;t possible to initialize the pocketsphinx decoder.
2018-04-26 16:31:29.372364+0200 TestOpenEars[972:261652] Successfully started listening session from startListeningWithLanguageModelAtPath:
Local callback: Setting up the continuous recognition loop has failed for the reason Optional(&quot;Error: it wasn\&#039;t possible to initialize the pocketsphinx decoder. Please turn on OELogging in order to troubleshoot this. If you need support with this issue, please turn on both OELogging and verbosePocketsphinx in order to get assistance.&quot;), please turn on OELogging.startOpenEarsLogging() to learn more.</code></pre>

		
	</div>
<!-- .bbp-reply-content -->
</div>
<!-- .reply -->

			
				
<div id="post-1032400" class="bbp-reply-header">
	<div class="bbp-meta">
		<span class="bbp-reply-post-date">April 26, 2018 at 4:33 pm</span>

		
			<span class="bbp-header">
				in reply to: 				<a class="bbp-topic-permalink" href="/forums/topic/recognize-short-command-in-nonenglish/">Recognize short Command in nonEnglish</a>
			</span>

		
		<a href="/forums/topic/recognize-short-command-in-nonenglish/#post-1032400" class="bbp-reply-permalink">#1032400</a>

		
		<span class="bbp-admin-links"></span>
		
	</div>
<!-- .bbp-meta -->
</div>
<!-- #post-1032400 -->

<div class="loop-item-13 user-id-2480 bbp-parent-forum-3654 bbp-parent-topic-1032298 bbp-reply-position-65 even topic-author  post-1032400 reply type-reply status-publish hentry">
	<div class="bbp-reply-author">

		
		<a href="/forums/profile/ikk/" title="View iKK&#039;s profile" class="bbp-author-link"><span class="bbp-author-avatar"></span><span class="bbp-author-name">iKK</span></a><div class="bbp-author-role">Participant</div>
		
		
	</div>
<!-- .bbp-reply-author -->

	<div class="bbp-reply-content">

		
		<p>I did the two changes but same thing &#8211; still an error in Rejecto log !</p>
<p>(&#8211;&gt; see next forum entry for its log)<br>
(&#8211;&gt; see after next forum entry for the language model creation as it looks now)</p>
<p>What else is to change ??</p>

		
	</div>
<!-- .bbp-reply-content -->
</div>
<!-- .reply -->

			
				
<div id="post-1032395" class="bbp-reply-header">
	<div class="bbp-meta">
		<span class="bbp-reply-post-date">April 26, 2018 at 4:16 pm</span>

		
			<span class="bbp-header">
				in reply to: 				<a class="bbp-topic-permalink" href="/forums/topic/recognize-short-command-in-nonenglish/">Recognize short Command in nonEnglish</a>
			</span>

		
		<a href="/forums/topic/recognize-short-command-in-nonenglish/#post-1032395" class="bbp-reply-permalink">#1032395</a>

		
		<span class="bbp-admin-links"></span>
		
	</div>
<!-- .bbp-meta -->
</div>
<!-- #post-1032395 -->

<div class="loop-item-14 user-id-2480 bbp-parent-forum-3654 bbp-parent-topic-1032298 bbp-reply-position-62 odd topic-author  post-1032395 reply type-reply status-publish hentry">
	<div class="bbp-reply-author">

		
		<a href="/forums/profile/ikk/" title="View iKK&#039;s profile" class="bbp-author-link"><span class="bbp-author-avatar"></span><span class="bbp-author-name">iKK</span></a><div class="bbp-author-role">Participant</div>
		
		
	</div>
<!-- .bbp-reply-author -->

	<div class="bbp-reply-content">

		
		<p>And the Rejecto error-log when <code>let words = [&quot;eschdonofrey&quot;]</code></p>
<pre><code>2018-04-26 16:12:57.394517+0200 TestOpenEars[948:251080] Starting OpenEars logging for OpenEars version 2.506 on 64-bit device (or build): iPhone running iOS version: 11.300000
2018-04-26 16:12:57.394668+0200 TestOpenEars[948:251080] Creating shared instance of OEPocketsphinxController
2018-04-26 16:12:57.400109+0200 TestOpenEars[948:251080] Rejecto version 2.500000
2018-04-26 16:12:57.400656+0200 TestOpenEars[948:251080] Since there is no cached version, loading the g2p model for the acoustic model called AcousticModelGerman
2018-04-26 16:12:57.447645+0200 TestOpenEars[948:251080] Since there is no cached version, loading the language model lookup list for the acoustic model called AcousticModelGerman
2018-04-26 16:12:57.452509+0200 TestOpenEars[948:251080] Returning a cached version of LanguageModelGeneratorLookupList.text
2018-04-26 16:12:57.452586+0200 TestOpenEars[948:251080] Returning a cached version of g2p
2018-04-26 16:12:57.453390+0200 TestOpenEars[948:251080] I&#039;m done running performDictionaryLookup and it took 0.000826 seconds
2018-04-26 16:12:57.453572+0200 TestOpenEars[948:251080] I&#039;m done running performDictionaryLookup and it took 0.001270 seconds
2018-04-26 16:12:57.456686+0200 TestOpenEars[948:251080] A value has been given for weight, but it is identical to the default so we are ignoring it.
2018-04-26 16:12:57.456719+0200 TestOpenEars[948:251080] Starting dynamic language model generation

INFO: ngram_model_arpa_legacy.c(504): ngrams 1=23, 2=42, 3=21
INFO: ngram_model_arpa_legacy.c(136): Reading unigrams
INFO: ngram_model_arpa_legacy.c(543):       23 = #unigrams created
INFO: ngram_model_arpa_legacy.c(196): Reading bigrams
INFO: ngram_model_arpa_legacy.c(561):       42 = #bigrams created
INFO: ngram_model_arpa_legacy.c(562):        3 = #prob2 entries
INFO: ngram_model_arpa_legacy.c(570):        3 = #bo_wt2 entries
INFO: ngram_model_arpa_legacy.c(293): Reading trigrams
INFO: ngram_model_arpa_legacy.c(583):       21 = #trigrams created
INFO: ngram_model_arpa_legacy.c(584):        2 = #prob3 entries
INFO: ngram_model_dmp_legacy.c(521): Building DMP model...
INFO: ngram_model_dmp_legacy.c(551):       23 = #unigrams created
INFO: ngram_model_dmp_legacy.c(652):       42 = #bigrams created
INFO: ngram_model_dmp_legacy.c(653):        3 = #prob2 entries
INFO: ngram_model_dmp_legacy.c(660):        3 = #bo_wt2 entries
INFO: ngram_model_dmp_legacy.c(664):       21 = #trigrams created
INFO: ngram_model_dmp_legacy.c(665):        2 = #prob3 entries
2018-04-26 16:12:57.480557+0200 TestOpenEars[948:251080] Done creating language model with CMUCLMTK in 0.023809 seconds.
INFO: ngram_model_arpa_legacy.c(504): ngrams 1=23, 2=42, 3=21
INFO: ngram_model_arpa_legacy.c(136): Reading unigrams
INFO: ngram_model_arpa_legacy.c(543):       23 = #unigrams created
INFO: ngram_model_arpa_legacy.c(196): Reading bigrams
INFO: ngram_model_arpa_legacy.c(561):       42 = #bigrams created
INFO: ngram_model_arpa_legacy.c(562):        3 = #prob2 entries
INFO: ngram_model_arpa_legacy.c(570):        3 = #bo_wt2 entries
INFO: ngram_model_arpa_legacy.c(293): Reading trigrams
INFO: ngram_model_arpa_legacy.c(583):       21 = #trigrams created
INFO: ngram_model_arpa_legacy.c(584):        2 = #prob3 entries
INFO: ngram_model_dmp_legacy.c(521): Building DMP model...
INFO: ngram_model_dmp_legacy.c(551):       23 = #unigrams created
INFO: ngram_model_dmp_legacy.c(652):       42 = #bigrams created
INFO: ngram_model_dmp_legacy.c(653):        3 = #prob2 entries
INFO: ngram_model_dmp_legacy.c(660):        3 = #bo_wt2 entries
INFO: ngram_model_dmp_legacy.c(664):       21 = #trigrams created
INFO: ngram_model_dmp_legacy.c(665):        2 = #prob3 entries
2018-04-26 16:12:57.484133+0200 TestOpenEars[948:251080] I&#039;m done running dynamic language model generation and it took 0.083542 seconds
2018-04-26 16:12:57.484546+0200 TestOpenEars[948:251080] Attempting to start listening session from startListeningWithLanguageModelAtPath:
2018-04-26 16:12:57.486653+0200 TestOpenEars[948:251080] User gave mic permission for this app.
2018-04-26 16:12:57.486778+0200 TestOpenEars[948:251080] setSecondsOfSilence wasn&#039;t set, using default of 0.700000.
2018-04-26 16:12:57.487411+0200 TestOpenEars[948:251148] Starting listening.
2018-04-26 16:12:57.487511+0200 TestOpenEars[948:251148] About to set up audio session
2018-04-26 16:12:57.573019+0200 TestOpenEars[948:251148] Creating audio session with default settings.
2018-04-26 16:12:57.573063+0200 TestOpenEars[948:251148] Done setting audio session category.
2018-04-26 16:12:57.574976+0200 TestOpenEars[948:251148] Done setting preferred sample rate to 16000.000000 – now the real sample rate is 48000.000000
2018-04-26 16:12:57.576946+0200 TestOpenEars[948:251148] number of channels is already the preferred number of 1 so not setting it.
2018-04-26 16:12:57.580976+0200 TestOpenEars[948:251158] Audio route has changed for the following reason:
2018-04-26 16:12:57.581704+0200 TestOpenEars[948:251148] Done setting session&#039;s preferred I/O buffer duration to 0.128000 – now the actual buffer duration is 0.085333
2018-04-26 16:12:57.581730+0200 TestOpenEars[948:251148] Done setting up audio session
2018-04-26 16:12:57.581825+0200 TestOpenEars[948:251158] There was a category change. The new category is AVAudioSessionCategoryPlayAndRecord
2018-04-26 16:12:57.583983+022018-04-26 16:12:57.585493+0200 TestOpenEars[948:251148] About to set up audio IO unit in a session with a sample rate of 48000.000000, a channel number of 1 and a buffer duration of 0.085333.
00 TestOpenEars[948:251158] This is not a case in which OpenEars notifies of a route change. At the close of this method, the new audio route will be &lt;Input route or routes: &quot;MicrophoneBuiltIn&quot;. Output route or routes: &quot;Speaker&quot;&gt;. The previous route before changing to this route was &quot;&lt;AVAudioSessionRouteDescription: 0x1c060ba30, 
inputs = (null); 
outputs = (
    &quot;&lt;AVAudioSessionPortDescription: 0x1c060ba00, type = Speaker; name = Speaker; UID = Speaker; selectedDataSource = (null)&gt;&quot;
)&gt;&quot;.
2018-04-26 16:12:57.651365+0200 TestOpenEars[948:251158] Audio route has changed for the following reason:
2018-04-26 16:12:57.654591+0200 TestOpenEars[948:251158] There was a category change. The new category is AVAudioSessionCategoryPlayAndRecord
2018-04-26 16:12:57.657603+0200 TestOpenEars[948:251158] This is not a case in which OpenEars notifies of a route change. At the close of this method, the new audio route will be &lt;Input route or routes: &quot;MicrophoneBuiltIn&quot;. Output route or routes: &quot;Speaker&quot;&gt;. The previous route before changing to this route was &quot;&lt;AVAudioSessionRouteDescription: 0x1c060ba60, 
inputs = (
    &quot;&lt;AVAudioSessionPortDescription: 0x1c060b990, type = MicrophoneBuiltIn; name = iPhone Microphone; UID = Built-In Microphone; selectedDataSource = Bottom&gt;&quot;
); 
outputs = (
    &quot;&lt;AVAudioSessionPortDescription: 0x1c060b8e0, type = Receiver; name = Receiver; UID = Built-In Receiver; selectedDataSource = (null)&gt;&quot;
)&gt;&quot;.
2018-04-26 16:12:57.661195+0200 TestOpenEars[948:251148] Done setting up audio unit
2018-04-26 16:12:57.661236+0200 TestOpenEars[948:251148] About to start audio IO unit
2018-04-26 16:12:57.869438+0200 TestOpenEars[948:251148] Done starting audio unit
INFO: pocketsphinx.c(145): Parsed model-specific feature parameters from /var/containers/Bundle/Application/6CF2B633-750A-4DE1-8EC3-899218B63A02/TestOpenEars.app/AcousticModelGerman.bundle/feat.params
Current configuration:
[NAME]			[DEFLT]		[VALUE]
-agc			none		none
-agcthresh		2.0		2.000000e+00
-allphone				
-allphone_ci		no		no
-alpha			0.97		9.700000e-01
-ascale			20.0		2.000000e+01
-aw			1		1
-backtrace		no		no
-beam			1e-48		1.000000e-48
-bestpath		yes		yes
-bestpathlw		9.5		9.500000e+00
-ceplen			13		13
-cmn			current		current
-cmninit		8.0		30
-compallsen		no		no
-debug					0
-dict					/var/mobile/Containers/Data/Application/789AE295-AD6D-4F93-B321-792800594D7E/Library/Caches/GermanModel.dic
-dictcase		no		no
-dither			no		no
-doublebw		no		no
-ds			1		1
-fdict					/var/containers/Bundle/Application/6CF2B633-750A-4DE1-8EC3-899218B63A02/TestOpenEars.app/AcousticModelGerman.bundle/noisedict
-feat			1s_c_d_dd	1s_c_d_dd
-featparams				/var/containers/Bundle/Application/6CF2B633-750A-4DE1-8EC3-899218B63A02/TestOpenEars.app/AcousticModelGerman.bundle/feat.params
-fillprob		1e-8		1.000000e-08
-frate			100		100
-fsg					
-fsgusealtpron		yes		yes
-fsgusefiller		yes		yes
-fwdflat		yes		yes
-fwdflatbeam		1e-64		1.000000e-64
-fwdflatefwid		4		4
-fwdflatlw		8.5		8.500000e+00
-fwdflatsfwin		25		25
-fwdflatwbeam		7e-29		7.000000e-29
-fwdtree		yes		yes
-hmm					/var/containers/Bundle/Application/6CF2B633-750A-4DE1-8EC3-899218B63A02/TestOpenEars.app/AcousticModelGerman.bundle
-input_endian		little		little
-jsgf					/var/mobile/Containers/Data/Application/789AE295-AD6D-4F93-B321-792800594D7E/Library/Caches/GermanModel.gram
-keyphrase				
-kws					
-kws_delay		10		10
-kws_plp		1e-1		1.000000e-01
-kws_threshold		1		1.000000e+00
-latsize		5000		5000
-lda					
-ldadim			0		0
-lifter			0		22
-lm					
-lmctl					
-lmname					
-logbase		1.0001		1.000100e+00
-logfn					
-logspec		no		no
-lowerf			133.33334	1.300000e+02
-lpbeam			1e-40		1.000000e-40
-lponlybeam		7e-29		7.000000e-29
-lw			6.5		1.000000e+00
-maxhmmpf		30000		30000
-maxwpf			-1		-1
-mdef					/var/containers/Bundle/Application/6CF2B633-750A-4DE1-8EC3-899218B63A02/TestOpenEars.app/AcousticModelGerman.bundle/mdef
-mean					/var/containers/Bundle/Application/6CF2B633-750A-4DE1-8EC3-899218B63A02/TestOpenEars.app/AcousticModelGerman.bundle/means
-mfclogdir				
-min_endfr		0		0
-mixw					/var/containers/Bundle/Application/6CF2B633-750A-4DE1-8EC3-899218B63A02/TestOpenEars.app/AcousticModelGerman.bundle/mixture_weights
-mixwfloor		0.0000001	1.000000e-07
-mllr					
-mmap			yes		yes
-ncep			13		13
-nfft			512		512
-nfilt			40		25
-nwpen			1.0		1.000000e+00
-pbeam			1e-48		1.000000e-48
-pip			1.0		1.000000e+00
-pl_beam		1e-10		1.000000e-10
-pl_pbeam		1e-10		1.000000e-10
-pl_pip			1.0		1.000000e+00
-pl_weight		3.0		3.000000e+00
-pl_window		5		5
-rawlogdir				
-remove_dc		no		no
-remove_noise		yes		yes
-remove_silence		yes		yes
-round_filters		yes		yes
-samprate		16000		1.600000e+04
-seed			-1		-1
-sendump				
-senlogdir				
-senmgau				
-silprob		0.005		5.000000e-03
-smoothspec		no		no
-svspec					
-tmat					/var/containers/Bundle/Application/6CF2B633-750A-4DE1-8EC3-899218B63A02/TestOpenEars.app/AcousticModelGerman.bundle/transition_matrices
-tmatfloor		0.0001		1.000000e-04
-topn			4		4
-topn_beam		0		0
-toprule				
-transform		legacy		dct
-unit_area		yes		yes
-upperf			6855.4976	6.800000e+03
-uw			1.0		1.000000e+00
-vad_postspeech		50		69
-vad_prespeech		20		10
-vad_startspeech	10		10
-vad_threshold		2.0		3.200000e+00
-var					/var/containers/Bundle/Application/6CF2B633-750A-4DE1-8EC3-899218B63A02/TestOpenEars.app/AcousticModelGerman.bundle/variances
-varfloor		0.0001		1.000000e-04
-varnorm		no		no
-verbose		no		no
-warp_params				
-warp_type		inverse_linear	inverse_linear
-wbeam			7e-29		7.000000e-29
-wip			0.65		6.500000e-01
-wlen			0.025625	2.562500e-02

INFO: feat.c(715): Initializing feature stream to type: &#039;1s_c_d_dd&#039;, ceplen=13, CMN=&#039;current&#039;, VARNORM=&#039;no&#039;, AGC=&#039;none&#039;
INFO: cmn.c(143): mean[0]= 12.00, mean[1..12]= 0.0
INFO: mdef.c(518): Reading model definition: /var/containers/Bundle/Application/6CF2B633-750A-4DE1-8EC3-899218B63A02/TestOpenEars.app/AcousticModelGerman.bundle/mdef
INFO: bin_mdef.c(181): Allocating 53834 * 8 bytes (420 KiB) for CD tree
INFO: tmat.c(206): Reading HMM transition probability matrices: /var/containers/Bundle/Application/6CF2B633-750A-4DE1-8EC3-899218B63A02/TestOpenEars.app/AcousticModelGerman.bundle/transition_matrices
INFO: acmod.c(117): Attempting to use PTM computation module
INFO: ms_gauden.c(198): Reading mixture gaussian parameter: /var/containers/Bundle/Application/6CF2B633-750A-4DE1-8EC3-899218B63A02/TestOpenEars.app/AcousticModelGerman.bundle/means
INFO: ms_gauden.c(292): 2129 codebook, 1 feature, size: 
INFO: ms_gauden.c(294):  32x39
INFO: ms_gauden.c(198): Reading mixture gaussian parameter: /var/containers/Bundle/Application/6CF2B633-750A-4DE1-8EC3-899218B63A02/TestOpenEars.app/AcousticModelGerman.bundle/variances
INFO: ms_gauden.c(292): 2129 codebook, 1 feature, size: 
INFO: ms_gauden.c(294):  32x39
INFO: ms_gauden.c(354): 7100 variance values floored
INFO: ptm_mgau.c(801): Number of codebooks exceeds 256: 2129
INFO: acmod.c(119): Attempting to use semi-continuous computation module
INFO: ms_gauden.c(198): Reading mixture gaussian parameter: /var/containers/Bundle/Application/6CF2B633-750A-4DE1-8EC3-899218B63A02/TestOpenEars.app/AcousticModelGerman.bundle/means
INFO: ms_gauden.c(292): 2129 codebook, 1 feature, size: 
INFO: ms_gauden.c(294):  32x39
INFO: ms_gauden.c(198): Reading mixture gaussian parameter: /var/containers/Bundle/Application/6CF2B633-750A-4DE1-8EC3-899218B63A02/TestOpenEars.app/AcousticModelGerman.bundle/variances
INFO: ms_gauden.c(292): 2129 codebook, 1 feature, size: 
INFO: ms_gauden.c(294):  32x39
INFO: ms_gauden.c(354): 7100 variance values floored
INFO: acmod.c(121): Falling back to general multi-stream GMM computation
INFO: ms_gauden.c(198): Reading mixture gaussian parameter: /var/containers/Bundle/Application/6CF2B633-750A-4DE1-8EC3-899218B63A02/TestOpenEars.app/AcousticModelGerman.bundle/means
INFO: ms_gauden.c(292): 2129 codebook, 1 feature, size: 
INFO: ms_gauden.c(294):  32x39
INFO: ms_gauden.c(198): Reading mixture gaussian parameter: /var/containers/Bundle/Application/6CF2B633-750A-4DE1-8EC3-899218B63A02/TestOpenEars.app/AcousticModelGerman.bundle/variances
INFO: ms_gauden.c(292): 2129 codebook, 1 feature, size: 
INFO: ms_gauden.c(294):  32x39
INFO: ms_gauden.c(354): 7100 variance values floored
INFO: ms_senone.c(149): Reading senone mixture weights: /var/containers/Bundle/Application/6CF2B633-750A-4DE1-8EC3-899218B63A02/TestOpenEars.app/AcousticModelGerman.bundle/mixture_weights
INFO: ms_senone.c(200): Truncating senone logs3(pdf) values by 10 bits
INFO: ms_senone.c(207): Not transposing mixture weights in memory
INFO: ms_senone.c(268): Read mixture weights for 2129 senones: 1 features x 32 codewords
INFO: ms_senone.c(320): Mapping senones to individual codebooks
INFO: ms_mgau.c(141): The value of topn: 4
INFO: phone_loop_search.c(114): State beam -225 Phone exit beam -225 Insertion penalty 0
INFO: dict.c(320): Allocating 4121 * 32 bytes (128 KiB) for word entries
INFO: dict.c(333): Reading main dictionary: /var/mobile/Containers/Data/Application/789AE295-AD6D-4F93-B321-792800594D7E/Library/Caches/GermanModel.dic
INFO: dict.c(213): Allocated 0 KiB for strings, 0 KiB for phones
INFO: dict.c(336): 21 words read
INFO: dict.c(358): Reading filler dictionary: /var/containers/Bundle/Application/6CF2B633-750A-4DE1-8EC3-899218B63A02/TestOpenEars.app/AcousticModelGerman.bundle/noisedict
INFO: dict.c(213): Allocated 0 KiB for strings, 0 KiB for phones
INFO: dict.c(361): 4 words read
INFO: dict2pid.c(396): Building PID tables for dictionary
INFO: dict2pid.c(406): Allocating 43^3 * 2 bytes (155 KiB) for word-initial triphones
INFO: dict2pid.c(132): Allocated 44720 bytes (43 KiB) for word-final triphones
INFO: dict2pid.c(196): Allocated 44720 bytes (43 KiB) for single-phone word triphones
INFO: jsgf.c(691): Defined rule: &lt;GermanModel.g00000&gt;
INFO: jsgf.c(691): Defined rule: &lt;GermanModel.rule_0&gt;
INFO: jsgf.c(691): Defined rule: &lt;GermanModel.g00002&gt;
INFO: jsgf.c(691): Defined rule: PUBLIC &lt;GermanModel.rule_1&gt;
INFO: fsg_model.c(215): Computing transitive closure for null transitions
INFO: fsg_model.c(277): 0 null transitions added
INFO: fsg_search.c(227): FSG(beam: -1080, pbeam: -1080, wbeam: -634; wip: -5, pip: 0)
ERROR: &quot;fsg_search.c&quot;, line 141: The word &#039;esch&#039; is missing in the dictionary
2018-04-26 16:12:58.311567+0200 TestOpenEars[948:251148] Error: it wasn&#039;t possible to initialize the pocketsphinx decoder.
2018-04-26 16:12:58.311775+0200 TestOpenEars[948:251080] Successfully started listening session from startListeningWithLanguageModelAtPath:
Local callback: Setting up the continuous recognition loop has failed for the reason Optional(&quot;Error: it wasn\&#039;t possible to initialize the pocketsphinx decoder. Please turn on OELogging in order to troubleshoot this. If you need support with this issue, please turn on both OELogging and verbosePocketsphinx in order to get assistance.&quot;), please turn on OELogging.startOpenEarsLogging() to learn more.
2018-04-26 16:13:00.037620+0200 TestOpenEars[948:251080] Status bar could not find cached time string image. Rendering in-process.</code></pre>

		
	</div>
<!-- .bbp-reply-content -->
</div>
<!-- .reply -->

			
				
<div id="post-1032394" class="bbp-reply-header">
	<div class="bbp-meta">
		<span class="bbp-reply-post-date">April 26, 2018 at 4:15 pm</span>

		
			<span class="bbp-header">
				in reply to: 				<a class="bbp-topic-permalink" href="/forums/topic/recognize-short-command-in-nonenglish/">Recognize short Command in nonEnglish</a>
			</span>

		
		<a href="/forums/topic/recognize-short-command-in-nonenglish/#post-1032394" class="bbp-reply-permalink">#1032394</a>

		
		<span class="bbp-admin-links"></span>
		
	</div>
<!-- .bbp-meta -->
</div>
<!-- #post-1032394 -->

<div class="loop-item-15 user-id-2480 bbp-parent-forum-3654 bbp-parent-topic-1032298 bbp-reply-position-61 even topic-author  post-1032394 reply type-reply status-publish hentry">
	<div class="bbp-reply-author">

		
		<a href="/forums/profile/ikk/" title="View iKK&#039;s profile" class="bbp-author-link"><span class="bbp-author-avatar"></span><span class="bbp-author-name">iKK</span></a><div class="bbp-author-role">Participant</div>
		
		
	</div>
<!-- .bbp-reply-author -->

	<div class="bbp-reply-content">

		
		<p>ViewController code with the language-model creation :</p>
<pre><code>import UIKit

class ViewController: UIViewController, OEEventsObserverDelegate {
    
    var openEarsEventsObserver = OEEventsObserver()

    override func viewDidLoad() {
        super.viewDidLoad()
        // Do any additional setup after loading the view, typically from a nib.
        
        // ************* Necessary for logging **************************
        OELogging.startOpenEarsLogging() //Uncomment to receive full OpenEars logging in case of any unexpected results.
        OEPocketsphinxController.sharedInstance().verbosePocketSphinx = true
        // ************* Necessary for logging **************************
        
        self.openEarsEventsObserver.delegate = self
        
        let lmGenerator = OELanguageModelGenerator()
        let accusticModelName = &quot;AcousticModelGerman&quot;
        
        let fileName = &quot;GermanModel&quot;
        
        // let words = [&quot;esch do no frey&quot;]
        let words = [&quot;eschdonofrey&quot;]
        
        // let err: Error! = lmGenerator.generateLanguageModel(from: words, withFilesNamed: name, forAcousticModelAtPath: OEAcousticModel.path(toModel: accusticModelName))
        
        let err: Error! = lmGenerator.generateRejectingLanguageModel(from: words, withFilesNamed: fileName, withOptionalExclusions: nil, usingVowelsOnly: true, withWeight: 1.0, forAcousticModelAtPath: OEAcousticModel.path(toModel: accusticModelName))
        
        var lmPath = &quot;&quot;
        var dictPath = &quot;&quot;
        
        if(err != nil) {
            print(&quot;Error while creating initial language model: \(err)&quot;)
        } else {
            // lmPath = lmGenerator.pathToSuccessfullyGeneratedLanguageModel(withRequestedName: fileName)
            lmPath = lmGenerator.pathToSuccessfullyGeneratedGrammar(withRequestedName: fileName)
            dictPath = lmGenerator.pathToSuccessfullyGeneratedDictionary(withRequestedName: fileName)
        }
        
        do {
            try OEPocketsphinxController.sharedInstance().setActive(true) // Setting the shared OEPocketsphinxController active is necessary before any of its properties are accessed.
        } catch {
            print(&quot;Error: it wasn&#039;t possible to set the shared instance to active: \&quot;\(error)\&quot;&quot;)
        }
        
        OEPocketsphinxController.sharedInstance().vadThreshold = 3.2;
    OEPocketsphinxController.sharedInstance().startListeningWithLanguageModel(atPath: lmPath, dictionaryAtPath: dictPath, acousticModelAtPath: OEAcousticModel.path(toModel: accusticModelName), languageModelIsJSGF: true)
    }

    override func didReceiveMemoryWarning() {
        super.didReceiveMemoryWarning()
        // Dispose of any resources that can be recreated.
    }
    
    func pocketsphinxDidReceiveHypothesis(_ hypothesis: String!, recognitionScore: String!, utteranceID: String!) { // Something was heard
        print(&quot;Local callback: The received hypothesis is \(hypothesis!) with a score of \(recognitionScore!) and an ID of \(utteranceID!)&quot;)
    }
    
    // An optional delegate method of OEEventsObserver which informs that the Pocketsphinx recognition loop has entered its actual loop.
    // This might be useful in debugging a conflict between another sound class and Pocketsphinx.
    func pocketsphinxRecognitionLoopDidStart() {
        print(&quot;Local callback: Pocketsphinx started.&quot;) // Log it.
    }
    
    // An optional delegate method of OEEventsObserver which informs that Pocketsphinx is now listening for speech.
    func pocketsphinxDidStartListening() {
        print(&quot;Local callback: Pocketsphinx is now listening.&quot;) // Log it.
    }
    
    // An optional delegate method of OEEventsObserver which informs that Pocketsphinx detected speech and is starting to process it.
    func pocketsphinxDidDetectSpeech() {
        print(&quot;Local callback: Pocketsphinx has detected speech.&quot;) // Log it.
    }
    
    // An optional delegate method of OEEventsObserver which informs that Pocketsphinx detected a second of silence, indicating the end of an utterance.
    func pocketsphinxDidDetectFinishedSpeech() {
        print(&quot;Local callback: Pocketsphinx has detected a second of silence, concluding an utterance.&quot;) // Log it.
    }
    
    // An optional delegate method of OEEventsObserver which informs that Pocketsphinx has exited its recognition loop, most
    // likely in response to the OEPocketsphinxController being told to stop listening via the stopListening method.
    func pocketsphinxDidStopListening() {
        print(&quot;Local callback: Pocketsphinx has stopped listening.&quot;) // Log it.
    }
    
    // An optional delegate method of OEEventsObserver which informs that Pocketsphinx is still in its listening loop but it is not
    // Going to react to speech until listening is resumed.  This can happen as a result of Flite speech being
    // in progress on an audio route that doesn&#039;t support simultaneous Flite speech and Pocketsphinx recognition,
    // or as a result of the OEPocketsphinxController being told to suspend recognition via the suspendRecognition method.
    func pocketsphinxDidSuspendRecognition() {
        print(&quot;Local callback: Pocketsphinx has suspended recognition.&quot;) // Log it.
    }
    
    // An optional delegate method of OEEventsObserver which informs that Pocketsphinx is still in its listening loop and after recognition
    // having been suspended it is now resuming.  This can happen as a result of Flite speech completing
    // on an audio route that doesn&#039;t support simultaneous Flite speech and Pocketsphinx recognition,
    // or as a result of the OEPocketsphinxController being told to resume recognition via the resumeRecognition method.
    func pocketsphinxDidResumeRecognition() {
        print(&quot;Local callback: Pocketsphinx has resumed recognition.&quot;) // Log it.
    }
    
    // An optional delegate method which informs that Pocketsphinx switched over to a new language model at the given URL in the course of
    // recognition. This does not imply that it is a valid file or that recognition will be successful using the file.
    func pocketsphinxDidChangeLanguageModel(toFile newLanguageModelPathAsString: String!, andDictionary newDictionaryPathAsString: String!) {
        
        print(&quot;Local callback: Pocketsphinx is now using the following language model: \n\(newLanguageModelPathAsString!) and the following dictionary: \(newDictionaryPathAsString!)&quot;)
    }
    
    // An optional delegate method of OEEventsObserver which informs that Flite is speaking, most likely to be useful if debugging a
    // complex interaction between sound classes. You don&#039;t have to do anything yourself in order to prevent Pocketsphinx from listening to Flite talk and trying to recognize the speech.
    func fliteDidStartSpeaking() {
        print(&quot;Local callback: Flite has started speaking&quot;) // Log it.
    }
    
    // An optional delegate method of OEEventsObserver which informs that Flite is finished speaking, most likely to be useful if debugging a
    // complex interaction between sound classes.
    func fliteDidFinishSpeaking() {
        print(&quot;Local callback: Flite has finished speaking&quot;) // Log it.
    }
    
    func pocketSphinxContinuousSetupDidFail(withReason reasonForFailure: String!) { // This can let you know that something went wrong with the recognition loop startup. Turn on [OELogging startOpenEarsLogging] to learn why.
        print(&quot;Local callback: Setting up the continuous recognition loop has failed for the reason \(reasonForFailure), please turn on OELogging.startOpenEarsLogging() to learn more.&quot;) // Log it.
    }
    
    func pocketSphinxContinuousTeardownDidFail(withReason reasonForFailure: String!) { // This can let you know that something went wrong with the recognition loop startup. Turn on OELogging.startOpenEarsLogging() to learn why.
        print(&quot;Local callback: Tearing down the continuous recognition loop has failed for the reason \(reasonForFailure)&quot;) // Log it.
    }
    
    /** Pocketsphinx couldn&#039;t start because it has no mic permissions (will only be returned on iOS7 or later).*/
    func pocketsphinxFailedNoMicPermissions() {
        print(&quot;Local callback: The user has never set mic permissions or denied permission to this app&#039;s mic, so listening will not start.&quot;)
    }
    
    /** The user prompt to get mic permissions, or a check of the mic permissions, has completed with a true or a false result  (will only be returned on iOS7 or later).*/
    
    func micPermissionCheckCompleted(withResult: Bool) {
        print(&quot;Local callback: mic check completed.&quot;)
    }
}</code></pre>

		
	</div>
<!-- .bbp-reply-content -->
</div>
<!-- .reply -->

			
				
<div id="post-1032392" class="bbp-reply-header">
	<div class="bbp-meta">
		<span class="bbp-reply-post-date">April 26, 2018 at 4:15 pm</span>

		
			<span class="bbp-header">
				in reply to: 				<a class="bbp-topic-permalink" href="/forums/topic/recognize-short-command-in-nonenglish/">Recognize short Command in nonEnglish</a>
			</span>

		
		<a href="/forums/topic/recognize-short-command-in-nonenglish/#post-1032392" class="bbp-reply-permalink">#1032392</a>

		
		<span class="bbp-admin-links"></span>
		
	</div>
<!-- .bbp-meta -->
</div>
<!-- #post-1032392 -->

<div class="loop-item-16 user-id-2480 bbp-parent-forum-3654 bbp-parent-topic-1032298 bbp-reply-position-60 odd topic-author  post-1032392 reply type-reply status-publish hentry">
	<div class="bbp-reply-author">

		
		<a href="/forums/profile/ikk/" title="View iKK&#039;s profile" class="bbp-author-link"><span class="bbp-author-avatar"></span><span class="bbp-author-name">iKK</span></a><div class="bbp-author-role">Participant</div>
		
		
	</div>
<!-- .bbp-reply-author -->

	<div class="bbp-reply-content">

		
		<p>Ok &#8211; all in this forum:</p>
<p>Lets continue with Rejecto: </p>
<p>(I changed the AcousticModelGerman.bundle/LanguageModelGeneratorLookupList.text to what you suggested).</p>
<p>You wrote last: <code>so that it just creates a model for the single word “eschdonofrey”</code></p>
<p>This makes me do :</p>
<p><code>let words = [&quot;eschdonofrey&quot;]</code></p>
<p>&#8230;with its language-model creation as can be seen in the next Forum-entry (for clarity I place this in a new forum-entry)</p>
<p>But this leads to an error as can be seen in its log<br>
(&#8211;&gt; also this log is placed in its separate forum-entry to make things easier to read)</p>
<p>If I change the words-array back to <code>let words = [&quot;esch do no frey&quot;]</code> then there is no error &#8211; but I feel that I did not fully follow your instructions.</p>
<p>What is the correct words-array for Rejecto and our new LanguageModelGeneratorLookupList.text ???</p>
<p>If it is <code>let words = [&quot;eschdonofrey&quot;]</code> then what is the counter-measure to its error ??</p>

		
	</div>
<!-- .bbp-reply-content -->
</div>
<!-- .reply -->

			
				
<div id="post-1032389" class="bbp-reply-header">
	<div class="bbp-meta">
		<span class="bbp-reply-post-date">April 26, 2018 at 4:05 pm</span>

		
			<span class="bbp-header">
				in reply to: 				<a class="bbp-topic-permalink" href="/forums/topic/recognize-short-command-in-nonenglish/">Recognize short Command in nonEnglish</a>
			</span>

		
		<a href="/forums/topic/recognize-short-command-in-nonenglish/#post-1032389" class="bbp-reply-permalink">#1032389</a>

		
		<span class="bbp-admin-links"></span>
		
	</div>
<!-- .bbp-meta -->
</div>
<!-- #post-1032389 -->

<div class="loop-item-17 user-id-2480 bbp-parent-forum-3654 bbp-parent-topic-1032298 bbp-reply-position-57 even topic-author  post-1032389 reply type-reply status-publish hentry">
	<div class="bbp-reply-author">

		
		<a href="/forums/profile/ikk/" title="View iKK&#039;s profile" class="bbp-author-link"><span class="bbp-author-avatar"></span><span class="bbp-author-name">iKK</span></a><div class="bbp-author-role">Participant</div>
		
		
	</div>
<!-- .bbp-reply-author -->

	<div class="bbp-reply-content">

		
		<p>Ok &#8211; I just feel that the log and VC&#8217;s Code make the forum trememdous. And links would be nicer somehow. I can put it into a new github-reop if you prefer. Or I can paste the huge logs in this forum. What do you prefer ?</p>

		
	</div>
<!-- .bbp-reply-content -->
</div>
<!-- .reply -->

			
				
<div id="post-1032374" class="bbp-reply-header">
	<div class="bbp-meta">
		<span class="bbp-reply-post-date">April 26, 2018 at 3:26 pm</span>

		
			<span class="bbp-header">
				in reply to: 				<a class="bbp-topic-permalink" href="/forums/topic/recognize-short-command-in-nonenglish/">Recognize short Command in nonEnglish</a>
			</span>

		
		<a href="/forums/topic/recognize-short-command-in-nonenglish/#post-1032374" class="bbp-reply-permalink">#1032374</a>

		
		<span class="bbp-admin-links"></span>
		
	</div>
<!-- .bbp-meta -->
</div>
<!-- #post-1032374 -->

<div class="loop-item-18 user-id-2480 bbp-parent-forum-3654 bbp-parent-topic-1032298 bbp-reply-position-54 odd topic-author  post-1032374 reply type-reply status-publish hentry">
	<div class="bbp-reply-author">

		
		<a href="/forums/profile/ikk/" title="View iKK&#039;s profile" class="bbp-author-link"><span class="bbp-author-avatar"></span><span class="bbp-author-name">iKK</span></a><div class="bbp-author-role">Participant</div>
		
		
	</div>
<!-- .bbp-reply-author -->

	<div class="bbp-reply-content">

		
		<p>The forum entries I submit are no longer shown (in none of my browsers&#8230;). This is unfortunate. Can you still read them ??</p>

		
	</div>
<!-- .bbp-reply-content -->
</div>
<!-- .reply -->

			
				
<div id="post-1032363" class="bbp-reply-header">
	<div class="bbp-meta">
		<span class="bbp-reply-post-date">April 24, 2018 at 2:29 pm</span>

		
			<span class="bbp-header">
				in reply to: 				<a class="bbp-topic-permalink" href="/forums/topic/recognize-short-command-in-nonenglish/">Recognize short Command in nonEnglish</a>
			</span>

		
		<a href="/forums/topic/recognize-short-command-in-nonenglish/#post-1032363" class="bbp-reply-permalink">#1032363</a>

		
		<span class="bbp-admin-links"></span>
		
	</div>
<!-- .bbp-meta -->
</div>
<!-- #post-1032363 -->

<div class="loop-item-19 user-id-2480 bbp-parent-forum-3654 bbp-parent-topic-1032298 bbp-reply-position-52 even topic-author  post-1032363 reply type-reply status-publish hentry">
	<div class="bbp-reply-author">

		
		<a href="/forums/profile/ikk/" title="View iKK&#039;s profile" class="bbp-author-link"><span class="bbp-author-avatar"></span><span class="bbp-author-name">iKK</span></a><div class="bbp-author-role">Participant</div>
		
		
	</div>
<!-- .bbp-reply-author -->

	<div class="bbp-reply-content">

		
		<p>OpenEars only version with German acc-Model and Logging:<br>
&#8211;&gt; 3 times spoken sentence correctly and 3 times spoken incorrectly (but unfortunately still recognized by App):</p>
<pre><code>2018-04-24 15:26:59.451799+0300 TestOpenEars[5111:2385157] Starting OpenEars logging for OpenEars version 2.506 on 64-bit device (or build): iPhone running iOS version: 11.300000
2018-04-24 15:26:59.453199+0300 TestOpenEars[5111:2385157] Creating shared instance of OEPocketsphinxController
2018-04-24 15:26:59.492625+0300 TestOpenEars[5111:2385157] Since there is no cached version, loading the language model lookup list for the acoustic model called AcousticModelGerman
2018-04-24 15:26:59.500315+0300 TestOpenEars[5111:2385157] Since there is no cached version, loading the g2p model for the acoustic model called AcousticModelGerman
2018-04-24 15:26:59.560933+0300 TestOpenEars[5111:2385157] The word do was not found in the dictionary of the acoustic model /var/containers/Bundle/Application/EF8E1618-8403-456C-8666-01B9C11D392E/TestOpenEars.app/AcousticModelGerman.bundle. Now using the fallback method to look it up. If this is happening more frequently than you would expect, likely causes can be that you are entering words in another language from the one you are recognizing, or that there are symbols (including numbers) that need to be spelled out or cleaned up, or you are using your own acoustic model and there is an issue with either its phonetic dictionary or it lacks a g2p file. Please get in touch at the forums for assistance with the last two possible issues.
2018-04-24 15:26:59.561292+0300 TestOpenEars[5111:2385157] the graphemes &quot;d oo&quot; were created for the word do using the fallback method.
2018-04-24 15:26:59.566736+0300 TestOpenEars[5111:2385157] The word esch was not found in the dictionary of the acoustic model /var/containers/Bundle/Application/EF8E1618-8403-456C-8666-01B9C11D392E/TestOpenEars.app/AcousticModelGerman.bundle. Now using the fallback method to look it up. If this is happening more frequently than you would expect, likely causes can be that you are entering words in another language from the one you are recognizing, or that there are symbols (including numbers) that need to be spelled out or cleaned up, or you are using your own acoustic model and there is an issue with either its phonetic dictionary or it lacks a g2p file. Please get in touch at the forums for assistance with the last two possible issues.
2018-04-24 15:26:59.566934+0300 TestOpenEars[5111:2385157] the graphemes &quot;@ ss&quot; were created for the word esch using the fallback method.
2018-04-24 15:26:59.571940+0300 TestOpenEars[5111:2385157] The word frey was not found in the dictionary of the acoustic model /var/containers/Bundle/Application/EF8E1618-8403-456C-8666-01B9C11D392E/TestOpenEars.app/AcousticModelGerman.bundle. Now using the fallback method to look it up. If this is happening more frequently than you would expect, likely causes can be that you are entering words in another language from the one you are recognizing, or that there are symbols (including numbers) that need to be spelled out or cleaned up, or you are using your own acoustic model and there is an issue with either its phonetic dictionary or it lacks a g2p file. Please get in touch at the forums for assistance with the last two possible issues.
2018-04-24 15:26:59.572382+0300 TestOpenEars[5111:2385157] the graphemes &quot;f r @ ii&quot; were created for the word frey using the fallback method.
2018-04-24 15:26:59.577309+0300 TestOpenEars[5111:2385157] The word no was not found in the dictionary of the acoustic model /var/containers/Bundle/Application/EF8E1618-8403-456C-8666-01B9C11D392E/TestOpenEars.app/AcousticModelGerman.bundle. Now using the fallback method to look it up. If this is happening more frequently than you would expect, likely causes can be that you are entering words in another language from the one you are recognizing, or that there are symbols (including numbers) that need to be spelled out or cleaned up, or you are using your own acoustic model and there is an issue with either its phonetic dictionary or it lacks a g2p file. Please get in touch at the forums for assistance with the last two possible issues.
2018-04-24 15:26:59.577520+0300 TestOpenEars[5111:2385157] the graphemes &quot;n oo&quot; were created for the word no using the fallback method.
2018-04-24 15:26:59.577594+0300 TestOpenEars[5111:2385157] I&#039;m done running performDictionaryLookup and it took 0.077345 seconds
2018-04-24 15:26:59.620226+0300 TestOpenEars[5111:2385157] Attempting to start listening session from startListeningWithLanguageModelAtPath:
2018-04-24 15:26:59.624967+0300 TestOpenEars[5111:2385157] User gave mic permission for this app.
2018-04-24 15:26:59.625738+0300 TestOpenEars[5111:2385157] setSecondsOfSilence wasn&#039;t set, using default of 0.700000.
2018-04-24 15:26:59.626794+0300 TestOpenEars[5111:2385361] Starting listening.
2018-04-24 15:26:59.627043+0300 TestOpenEars[5111:2385361] About to set up audio session
2018-04-24 15:26:59.912222+0300 TestOpenEars[5111:2385373] Audio route has changed for the following reason:
2018-04-24 15:26:59.924468+0300 TestOpenEars[5111:2385361] Creating audio session with default settings.
2018-04-24 15:26:59.924526+0300 TestOpenEars[5111:2385361] Done setting audio session category.
2018-04-24 15:26:59.934688+0300 TestOpenEars[5111:2385361] Done setting preferred sample rate to 16000.000000 – now the real sample rate is 48000.000000
2018-04-24 15:26:59.935107+0300 TestOpenEars[5111:2385361] number of channels is already the preferred number of 1 so not setting it.
2018-04-24 15:26:59.935530+0300 TestOpenEars[5111:2385373] There was a category change. The new category is AVAudioSessionCategoryPlayAndRecord
2018-04-24 15:26:59.938452+0300 TestOpenEars[5111:2385361] Done setting session&#039;s preferred I/O buffer duration to 0.128000 – now the actual buffer duration is 0.085333
2018-04-24 15:26:59.938717+0300 TestOpenEars[5111:2385361] Done setting up audio session
2018-04-24 15:26:59.939075+0300 TestOpenEars[5111:2385361] About to set up audio IO unit in a session with a sample rate of 48000.000000, a channel number of 1 and a buffer duration of 0.085333.
2018-04-24 15:26:59.939645+0300 TestOpenEars[5111:2385373] This is not a case in which OpenEars notifies of a route change. At the close of this method, the new audio route will be &lt;Input route or routes: &quot;MicrophoneBuiltIn&quot;. Output route or routes: &quot;Speaker&quot;&gt;. The previous route before changing to this route was &quot;&lt;AVAudioSessionRouteDescription: 0x1c421ade0, 
inputs = (null); 
outputs = (
    &quot;&lt;AVAudioSessionPortDescription: 0x1c421ada0, type = Speaker; name = Speaker; UID = Speaker; selectedDataSource = (null)&gt;&quot;
)&gt;&quot;.
2018-04-24 15:27:00.043139+0300 TestOpenEars[5111:2385373] Audio route has changed for the following reason:
2018-04-24 15:27:00.044041+0300 TestOpenEars[5111:2385373] There was a category change. The new category is AVAudioSessionCategoryPlayAndRecord
2018-04-24 15:27:00.048596+0300 TestOpenEars[5111:2385373] This is not a case in which OpenEars notifies of a route change. At the close of this method, the new audio route will be &lt;Input route or routes: &quot;MicrophoneBuiltIn&quot;. Output route or routes: &quot;Speaker&quot;&gt;. The previous route before changing to this route was &quot;&lt;AVAudioSessionRouteDescription: 0x1c421ade0, 
inputs = (
    &quot;&lt;AVAudioSessionPortDescription: 0x1c421ad80, type = MicrophoneBuiltIn; name = iPhone Microphone; UID = Built-In Microphone; selectedDataSource = Bottom&gt;&quot;
); 
outputs = (
    &quot;&lt;AVAudioSessionPortDescription: 0x1c421aee0, type = Receiver; name = Receiver; UID = Built-In Receiver; selectedDataSource = (null)&gt;&quot;
)&gt;&quot;.
2018-04-24 15:27:00.083178+0300 TestOpenEars[5111:2385361] Done setting up audio unit
2018-04-24 15:27:00.083242+0300 TestOpenEars[5111:2385361] About to start audio IO unit
2018-04-24 15:27:00.310893+0300 TestOpenEars[5111:2385361] Done starting audio unit
INFO: pocketsphinx.c(145): Parsed model-specific feature parameters from /var/containers/Bundle/Application/EF8E1618-8403-456C-8666-01B9C11D392E/TestOpenEars.app/AcousticModelGerman.bundle/feat.params
Current configuration:
[NAME]			[DEFLT]		[VALUE]
-agc			none		none
-agcthresh		2.0		2.000000e+00
-allphone				
-allphone_ci		no		no
-alpha			0.97		9.700000e-01
-ascale			20.0		2.000000e+01
-aw			1		1
-backtrace		no		no
-beam			1e-48		1.000000e-48
-bestpath		yes		yes
-bestpathlw		9.5		9.500000e+00
-ceplen			13		13
-cmn			current		current
-cmninit		8.0		30
-compallsen		no		no
-debug					0
-dict					/var/mobile/Containers/Data/Application/36B29079-C9F8-4804-BE51-0BDCE309BB18/Library/Caches/GermanModel.dic
-dictcase		no		no
-dither			no		no
-doublebw		no		no
-ds			1		1
-fdict					/var/containers/Bundle/Application/EF8E1618-8403-456C-8666-01B9C11D392E/TestOpenEars.app/AcousticModelGerman.bundle/noisedict
-feat			1s_c_d_dd	1s_c_d_dd
-featparams				/var/containers/Bundle/Application/EF8E1618-8403-456C-8666-01B9C11D392E/TestOpenEars.app/AcousticModelGerman.bundle/feat.params
-fillprob		1e-8		1.000000e-08
-frate			100		100
-fsg					
-fsgusealtpron		yes		yes
-fsgusefiller		yes		yes
-fwdflat		yes		yes
-fwdflatbeam		1e-64		1.000000e-64
-fwdflatefwid		4		4
-fwdflatlw		8.5		8.500000e+00
-fwdflatsfwin		25		25
-fwdflatwbeam		7e-29		7.000000e-29
-fwdtree		yes		yes
-hmm					/var/containers/Bundle/Application/EF8E1618-8403-456C-8666-01B9C11D392E/TestOpenEars.app/AcousticModelGerman.bundle
-input_endian		little		little
-jsgf					/var/mobile/Containers/Data/Application/36B29079-C9F8-4804-BE51-0BDCE309BB18/Library/Caches/GermanModel.gram
-keyphrase				
-kws					
-kws_delay		10		10
-kws_plp		1e-1		1.000000e-01
-kws_threshold		1		1.000000e+00
-latsize		5000		5000
-lda					
-ldadim			0		0
-lifter			0		22
-lm					
-lmctl					
-lmname					
-logbase		1.0001		1.000100e+00
-logfn					
-logspec		no		no
-lowerf			133.33334	1.300000e+02
-lpbeam			1e-40		1.000000e-40
-lponlybeam		7e-29		7.000000e-29
-lw			6.5		1.000000e+00
-maxhmmpf		30000		30000
-maxwpf			-1		-1
-mdef					/var/containers/Bundle/Application/EF8E1618-8403-456C-8666-01B9C11D392E/TestOpenEars.app/AcousticModelGerman.bundle/mdef
-mean					/var/containers/Bundle/Application/EF8E1618-8403-456C-8666-01B9C11D392E/TestOpenEars.app/AcousticModelGerman.bundle/means
-mfclogdir				
-min_endfr		0		0
-mixw					/var/containers/Bundle/Application/EF8E1618-8403-456C-8666-01B9C11D392E/TestOpenEars.app/AcousticModelGerman.bundle/mixture_weights
-mixwfloor		0.0000001	1.000000e-07
-mllr					
-mmap			yes		yes
-ncep			13		13
-nfft			512		512
-nfilt			40		25
-nwpen			1.0		1.000000e+00
-pbeam			1e-48		1.000000e-48
-pip			1.0		1.000000e+00
-pl_beam		1e-10		1.000000e-10
-pl_pbeam		1e-10		1.000000e-10
-pl_pip			1.0		1.000000e+00
-pl_weight		3.0		3.000000e+00
-pl_window		5		5
-rawlogdir				
-remove_dc		no		no
-remove_noise		yes		yes
-remove_silence		yes		yes
-round_filters		yes		yes
-samprate		16000		1.600000e+04
-seed			-1		-1
-sendump				
-senlogdir				
-senmgau				
-silprob		0.005		5.000000e-03
-smoothspec		no		no
-svspec					
-tmat					/var/containers/Bundle/Application/EF8E1618-8403-456C-8666-01B9C11D392E/TestOpenEars.app/AcousticModelGerman.bundle/transition_matrices
-tmatfloor		0.0001		1.000000e-04
-topn			4		4
-topn_beam		0		0
-toprule				
-transform		legacy		dct
-unit_area		yes		yes
-upperf			6855.4976	6.800000e+03
-uw			1.0		1.000000e+00
-vad_postspeech		50		69
-vad_prespeech		20		10
-vad_startspeech	10		10
-vad_threshold		2.0		3.200000e+00
-var					/var/containers/Bundle/Application/EF8E1618-8403-456C-8666-01B9C11D392E/TestOpenEars.app/AcousticModelGerman.bundle/variances
-varfloor		0.0001		1.000000e-04
-varnorm		no		no
-verbose		no		no
-warp_params				
-warp_type		inverse_linear	inverse_linear
-wbeam			7e-29		7.000000e-29
-wip			0.65		6.500000e-01
-wlen			0.025625	2.562500e-02

INFO: feat.c(715): Initializing feature stream to type: &#039;1s_c_d_dd&#039;, ceplen=13, CMN=&#039;current&#039;, VARNORM=&#039;no&#039;, AGC=&#039;none&#039;
INFO: cmn.c(143): mean[0]= 12.00, mean[1..12]= 0.0
INFO: mdef.c(518): Reading model definition: /var/containers/Bundle/Application/EF8E1618-8403-456C-8666-01B9C11D392E/TestOpenEars.app/AcousticModelGerman.bundle/mdef
INFO: bin_mdef.c(181): Allocating 53834 * 8 bytes (420 KiB) for CD tree
INFO: tmat.c(206): Reading HMM transition probability matrices: /var/containers/Bundle/Application/EF8E1618-8403-456C-8666-01B9C11D392E/TestOpenEars.app/AcousticModelGerman.bundle/transition_matrices
INFO: acmod.c(117): Attempting to use PTM computation module
INFO: ms_gauden.c(198): Reading mixture gaussian parameter: /var/containers/Bundle/Application/EF8E1618-8403-456C-8666-01B9C11D392E/TestOpenEars.app/AcousticModelGerman.bundle/means
INFO: ms_gauden.c(292): 2129 codebook, 1 feature, size: 
INFO: ms_gauden.c(294):  32x39
INFO: ms_gauden.c(198): Reading mixture gaussian parameter: /var/containers/Bundle/Application/EF8E1618-8403-456C-8666-01B9C11D392E/TestOpenEars.app/AcousticModelGerman.bundle/variances
INFO: ms_gauden.c(292): 2129 codebook, 1 feature, size: 
INFO: ms_gauden.c(294):  32x39
INFO: ms_gauden.c(354): 7100 variance values floored
INFO: ptm_mgau.c(801): Number of codebooks exceeds 256: 2129
INFO: acmod.c(119): Attempting to use semi-continuous computation module
INFO: ms_gauden.c(198): Reading mixture gaussian parameter: /var/containers/Bundle/Application/EF8E1618-8403-456C-8666-01B9C11D392E/TestOpenEars.app/AcousticModelGerman.bundle/means
INFO: ms_gauden.c(292): 2129 codebook, 1 feature, size: 
INFO: ms_gauden.c(294):  32x39
INFO: ms_gauden.c(198): Reading mixture gaussian parameter: /var/containers/Bundle/Application/EF8E1618-8403-456C-8666-01B9C11D392E/TestOpenEars.app/AcousticModelGerman.bundle/variances
INFO: ms_gauden.c(292): 2129 codebook, 1 feature, size: 
INFO: ms_gauden.c(294):  32x39
INFO: ms_gauden.c(354): 7100 variance values floored
INFO: acmod.c(121): Falling back to general multi-stream GMM computation
INFO: ms_gauden.c(198): Reading mixture gaussian parameter: /var/containers/Bundle/Application/EF8E1618-8403-456C-8666-01B9C11D392E/TestOpenEars.app/AcousticModelGerman.bundle/means
INFO: ms_gauden.c(292): 2129 codebook, 1 feature, size: 
INFO: ms_gauden.c(294):  32x39
INFO: ms_gauden.c(198): Reading mixture gaussian parameter: /var/containers/Bundle/Application/EF8E1618-8403-456C-8666-01B9C11D392E/TestOpenEars.app/AcousticModelGerman.bundle/variances
INFO: ms_gauden.c(292): 2129 codebook, 1 feature, size: 
INFO: ms_gauden.c(294):  32x39
INFO: ms_gauden.c(354): 7100 variance values floored
INFO: ms_senone.c(149): Reading senone mixture weights: /var/containers/Bundle/Application/EF8E1618-8403-456C-8666-01B9C11D392E/TestOpenEars.app/AcousticModelGerman.bundle/mixture_weights
INFO: ms_senone.c(200): Truncating senone logs3(pdf) values by 10 bits
INFO: ms_senone.c(207): Not transposing mixture weights in memory
INFO: ms_senone.c(268): Read mixture weights for 2129 senones: 1 features x 32 codewords
INFO: ms_senone.c(320): Mapping senones to individual codebooks
INFO: ms_mgau.c(141): The value of topn: 4
INFO: phone_loop_search.c(114): State beam -225 Phone exit beam -225 Insertion penalty 0
INFO: dict.c(320): Allocating 4104 * 32 bytes (128 KiB) for word entries
INFO: dict.c(333): Reading main dictionary: /var/mobile/Containers/Data/Application/36B29079-C9F8-4804-BE51-0BDCE309BB18/Library/Caches/GermanModel.dic
INFO: dict.c(213): Allocated 0 KiB for strings, 0 KiB for phones
INFO: dict.c(336): 4 words read
INFO: dict.c(358): Reading filler dictionary: /var/containers/Bundle/Application/EF8E1618-8403-456C-8666-01B9C11D392E/TestOpenEars.app/AcousticModelGerman.bundle/noisedict
INFO: dict.c(213): Allocated 0 KiB for strings, 0 KiB for phones
INFO: dict.c(361): 4 words read
INFO: dict2pid.c(396): Building PID tables for dictionary
INFO: dict2pid.c(406): Allocating 43^3 * 2 bytes (155 KiB) for word-initial triphones
INFO: dict2pid.c(132): Allocated 44720 bytes (43 KiB) for word-final triphones
INFO: dict2pid.c(196): Allocated 44720 bytes (43 KiB) for single-phone word triphones
INFO: jsgf.c(691): Defined rule: &lt;GermanModel.g00000&gt;
INFO: jsgf.c(691): Defined rule: PUBLIC &lt;GermanModel.rule_0&gt;
INFO: fsg_model.c(215): Computing transitive closure for null transitions
INFO: fsg_model.c(277): 0 null transitions added
INFO: fsg_search.c(227): FSG(beam: -1080, pbeam: -1080, wbeam: -634; wip: -5, pip: 0)
INFO: fsg_model.c(428): Adding silence transitions for &lt;sil&gt; to FSG
INFO: fsg_model.c(448): Added 5 silence word transitions
INFO: fsg_model.c(428): Adding silence transitions for &lt;sil&gt; to FSG
INFO: fsg_model.c(448): Added 5 silence word transitions
INFO: fsg_search.c(173): Added 0 alternate word transitions
INFO: fsg_lextree.c(110): Allocated 440 bytes (0 KiB) for left and right context phones
INFO: fsg_lextree.c(256): 17 HMM nodes in lextree (11 leaves)
INFO: fsg_lextree.c(259): Allocated 2448 bytes (2 KiB) for all lextree nodes
INFO: fsg_lextree.c(262): Allocated 1584 bytes (1 KiB) for lextree leafnodes
2018-04-24 15:27:01.081355+0300 TestOpenEars[5111:2385361] There is no CMN plist so we are using the fresh CMN value 30.000000.
2018-04-24 15:27:01.081752+0300 TestOpenEars[5111:2385361] Listening.
2018-04-24 15:27:01.082081+0300 TestOpenEars[5111:2385361] Project has these words or phrases in its dictionary:
do
esch
frey
no
2018-04-24 15:27:01.082136+0300 TestOpenEars[5111:2385361] Recognition loop has started
2018-04-24 15:27:01.082386+0300 TestOpenEars[5111:2385157] Successfully started listening session from startListeningWithLanguageModelAtPath:
Local callback: Pocketsphinx is now listening.
Local callback: Pocketsphinx started.
2018-04-24 15:27:01.107309+0300 TestOpenEars[5111:2385365] Speech detected...
2018-04-24 15:27:01.190684+0300 TestOpenEars[5111:2385157] Status bar could not find cached time string image. Rendering in-process.
Local callback: Pocketsphinx has detected speech.
2018-04-24 15:27:02.115525+0300 TestOpenEars[5111:2385365] End of speech detected...
Local callback: Pocketsphinx has detected a second of silence, concluding an utterance.
INFO: cmn_prior.c(131): cmn_prior_update: from &lt; 30.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00 &gt;
INFO: cmn_prior.c(149): cmn_prior_update: to   &lt; 52.05  4.29 -6.30  6.55  2.33  7.62  1.16  3.38  0.15  2.67  4.63 -0.61  7.11 &gt;
INFO: fsg_search.c(843): 98 frames, 653 HMMs (6/fr), 2042 senones (20/fr), 256 history entries (2/fr)

ERROR: &quot;fsg_search.c&quot;, line 913: Final result does not match the grammar in frame 98
2018-04-24 15:27:02.117015+0300 TestOpenEars[5111:2385365] Pocketsphinx heard &quot;&quot; with a score of (0) and an utterance ID of 0.
2018-04-24 15:27:02.117123+0300 TestOpenEars[5111:2385365] Hypothesis was null so we aren&#039;t returning it. If you want null hypotheses to also be returned, set OEPocketsphinxController&#039;s property returnNullHypotheses to TRUE before starting OEPocketsphinxController.
2018-04-24 15:27:04.500792+0300 TestOpenEars[5111:2385365] Speech detected...
Local callback: Pocketsphinx has detected speech.
2018-04-24 15:27:06.311372+0300 TestOpenEars[5111:2385365] End of speech detected...
Local callback: Pocketsphinx has detected a second of silence, concluding an utterance.
INFO: cmn_prior.c(131): cmn_prior_update: from &lt; 52.05  4.29 -6.30  6.55  2.33  7.62  1.16  3.38  0.15  2.67  4.63 -0.61  7.11 &gt;
INFO: cmn_prior.c(149): cmn_prior_update: to   &lt; 58.15 13.64 -1.14 13.16 -1.76  4.38 -0.40 -0.17  2.94 -3.08  6.71 -0.77  0.66 &gt;
INFO: fsg_search.c(843): 182 frames, 1377 HMMs (7/fr), 3920 senones (21/fr), 578 history entries (3/fr)

ERROR: &quot;fsg_search.c&quot;, line 913: Final result does not match the grammar in frame 182
2018-04-24 15:27:06.312908+0300 TestOpenEars[5111:2385365] Pocketsphinx heard &quot;&quot; with a score of (0) and an utterance ID of 1.
2018-04-24 15:27:06.312985+0300 TestOpenEars[5111:2385365] Hypothesis was null so we aren&#039;t returning it. If you want null hypotheses to also be returned, set OEPocketsphinxController&#039;s property returnNullHypotheses to TRUE before starting OEPocketsphinxController.
2018-04-24 15:27:09.497641+0300 TestOpenEars[5111:2385365] Speech detected...
Local callback: Pocketsphinx has detected speech.
2018-04-24 15:27:10.950073+0300 TestOpenEars[5111:2385365] End of speech detected...
Local callback: Pocketsphinx has detected a second of silence, concluding an utterance.
INFO: cmn_prior.c(131): cmn_prior_update: from &lt; 58.15 13.64 -1.14 13.16 -1.76  4.38 -0.40 -0.17  2.94 -3.08  6.71 -0.77  0.66 &gt;
INFO: cmn_prior.c(149): cmn_prior_update: to   &lt; 59.76 10.97 -1.90 16.73 -0.71  2.84 -0.63 -0.64  2.90 -4.16  8.11 -1.47  1.15 &gt;
INFO: fsg_search.c(843): 152 frames, 1313 HMMs (8/fr), 3563 senones (23/fr), 481 history entries (3/fr)

2018-04-24 15:27:10.951331+0300 TestOpenEars[5111:2385365] Pocketsphinx heard &quot;esch do no frey&quot; with a score of (0) and an utterance ID of 2.
Local callback: The received hypothesis is esch do no frey with a score of 0 and an ID of 2
2018-04-24 15:27:14.027713+0300 TestOpenEars[5111:2385365] Speech detected...
Local callback: Pocketsphinx has detected speech.
2018-04-24 15:27:15.556479+0300 TestOpenEars[5111:2385365] End of speech detected...
Local callback: Pocketsphinx has detected a second of silence, concluding an utterance.
INFO: cmn_prior.c(131): cmn_prior_update: from &lt; 59.76 10.97 -1.90 16.73 -0.71  2.84 -0.63 -0.64  2.90 -4.16  8.11 -1.47  1.15 &gt;
INFO: cmn_prior.c(149): cmn_prior_update: to   &lt; 61.02 10.07 -1.94 18.70 -1.04  2.18 -0.03  0.14  2.00 -4.99  8.23 -1.17  0.73 &gt;
INFO: fsg_search.c(843): 149 frames, 1388 HMMs (9/fr), 3631 senones (24/fr), 529 history entries (3/fr)

2018-04-24 15:27:15.557777+0300 TestOpenEars[5111:2385365] Pocketsphinx heard &quot;esch do no frey&quot; with a score of (0) and an utterance ID of 3.
Local callback: The received hypothesis is esch do no frey with a score of 0 and an ID of 3
2018-04-24 15:27:18.889630+0300 TestOpenEars[5111:2385365] Speech detected...
Local callback: Pocketsphinx has detected speech.
2018-04-24 15:27:20.689538+0300 TestOpenEars[5111:2385365] End of speech detected...
Local callback: Pocketsphinx has detected a second of silence, concluding an utterance.
INFO: cmn_prior.c(131): cmn_prior_update: from &lt; 61.02 10.07 -1.94 18.70 -1.04  2.18 -0.03  0.14  2.00 -4.99  8.23 -1.17  0.73 &gt;
INFO: cmn_prior.c(149): cmn_prior_update: to   &lt; 61.56  8.80  0.48 17.99 -1.61  1.57  1.08  0.47  2.06 -4.60  8.51 -1.48  0.24 &gt;
INFO: fsg_search.c(843): 191 frames, 1669 HMMs (8/fr), 4600 senones (24/fr), 474 history entries (2/fr)

2018-04-24 15:27:20.690857+0300 TestOpenEars[5111:2385365] Pocketsphinx heard &quot;esch do no frey&quot; with a score of (0) and an utterance ID of 4.
Local callback: The received hypothesis is esch do no frey with a score of 0 and an ID of 4
INFO: cmn_prior.c(99): cmn_prior_update: from &lt; 61.56  8.80  0.48 17.99 -1.61  1.57  1.08  0.47  2.06 -4.60  8.51 -1.48  0.24 &gt;
INFO: cmn_prior.c(116): cmn_prior_update: to   &lt; 61.76  8.78  0.35 18.48 -1.57  1.41  0.91  0.39  2.02 -4.70  8.28 -1.45  0.26 &gt;
2018-04-24 15:27:22.731373+0300 TestOpenEars[5111:2385365] Speech detected...
Local callback: Pocketsphinx has detected speech.
2018-04-24 15:27:24.515545+0300 TestOpenEars[5111:2385365] End of speech detected...
Local callback: Pocketsphinx has detected a second of silence, concluding an utterance.
INFO: cmn_prior.c(131): cmn_prior_update: from &lt; 61.76  8.78  0.35 18.48 -1.57  1.41  0.91  0.39  2.02 -4.70  8.28 -1.45  0.26 &gt;
INFO: cmn_prior.c(149): cmn_prior_update: to   &lt; 61.14  6.47  2.57 17.69 -1.60  2.08  2.04  1.05  0.54 -4.29  9.29 -2.48 -0.17 &gt;
INFO: fsg_search.c(843): 196 frames, 1392 HMMs (7/fr), 3717 senones (18/fr), 497 history entries (2/fr)

2018-04-24 15:27:24.516252+0300 TestOpenEars[5111:2385365] Pocketsphinx heard &quot;esch do no frey&quot; with a score of (0) and an utterance ID of 5.
Local callback: The received hypothesis is esch do no frey with a score of 0 and an ID of 5
2018-04-24 15:27:26.128084+0300 TestOpenEars[5111:2385365] Speech detected...
Local callback: Pocketsphinx has detected speech.
INFO: cmn_prior.c(99): cmn_prior_update: from &lt; 61.14  6.47  2.57 17.69 -1.60  2.08  2.04  1.05  0.54 -4.29  9.29 -2.48 -0.17 &gt;
INFO: cmn_prior.c(116): cmn_prior_update: to   &lt; 62.24  4.73  2.29 18.02 -2.27  1.41  2.70  1.52  0.78 -4.73  9.26 -2.53  0.30 &gt;
2018-04-24 15:27:28.084682+0300 TestOpenEars[5111:2385365] End of speech detected...
Local callback: Pocketsphinx has detected a second of silence, concluding an utterance.
INFO: cmn_prior.c(131): cmn_prior_update: from &lt; 62.24  4.73  2.29 18.02 -2.27  1.41  2.70  1.52  0.78 -4.73  9.26 -2.53  0.30 &gt;
INFO: cmn_prior.c(149): cmn_prior_update: to   &lt; 59.68  4.42  2.95 16.81 -0.93  2.99  2.93  0.78 -0.09 -3.93  9.04 -2.78  0.26 &gt;
INFO: fsg_search.c(843): 196 frames, 1654 HMMs (8/fr), 4578 senones (23/fr), 563 history entries (2/fr)

2018-04-24 15:27:28.087721+0300 TestOpenEars[5111:2385365] Pocketsphinx heard &quot;esch do no frey&quot; with a score of (0) and an utterance ID of 6.
Local callback: The received hypothesis is esch do no frey with a score of 0 and an ID of 6
2018-04-24 15:27:29.222305+0300 TestOpenEars[5111:2385365] Speech detected...
Local callback: Pocketsphinx has detected speech.
2018-04-24 15:27:30.032028+0300 TestOpenEars[5111:2385365] End of speech detected...
Local callback: Pocketsphinx has detected a second of silence, concluding an utterance.
INFO: cmn_prior.c(131): cmn_prior_update: from &lt; 59.68  4.42  2.95 16.81 -0.93  2.99  2.93  0.78 -0.09 -3.93  9.04 -2.78  0.26 &gt;
INFO: cmn_prior.c(149): cmn_prior_update: to   &lt; 58.59  3.00  2.81 16.73  0.59  3.92  2.47  0.95  1.43 -2.86  8.13 -2.14  0.18 &gt;
INFO: fsg_search.c(843): 94 frames, 701 HMMs (7/fr), 1954 senones (20/fr), 268 history entries (2/fr)

ERROR: &quot;fsg_search.c&quot;, line 913: Final result does not match the grammar in frame 94
2018-04-24 15:27:30.033297+0300 TestOpenEars[5111:2385365] Pocketsphinx heard &quot;&quot; with a score of (0) and an utterance ID of 7.
2018-04-24 15:27:30.033598+0300 TestOpenEars[5111:2385365] Hypothesis was null so we aren&#039;t returning it. If you want null hypotheses to also be returned, set OEPocketsphinxController&#039;s property returnNullHypotheses to TRUE before starting OEPocketsphinxController.</code></pre>

		
	</div>
<!-- .bbp-reply-content -->
</div>
<!-- .reply -->

			
				
<div id="post-1032362" class="bbp-reply-header">
	<div class="bbp-meta">
		<span class="bbp-reply-post-date">April 24, 2018 at 2:27 pm</span>

		
			<span class="bbp-header">
				in reply to: 				<a class="bbp-topic-permalink" href="/forums/topic/recognize-short-command-in-nonenglish/">Recognize short Command in nonEnglish</a>
			</span>

		
		<a href="/forums/topic/recognize-short-command-in-nonenglish/#post-1032362" class="bbp-reply-permalink">#1032362</a>

		
		<span class="bbp-admin-links"></span>
		
	</div>
<!-- .bbp-meta -->
</div>
<!-- #post-1032362 -->

<div class="loop-item-20 user-id-2480 bbp-parent-forum-3654 bbp-parent-topic-1032298 bbp-reply-position-51 odd topic-author  post-1032362 reply type-reply status-publish hentry">
	<div class="bbp-reply-author">

		
		<a href="/forums/profile/ikk/" title="View iKK&#039;s profile" class="bbp-author-link"><span class="bbp-author-avatar"></span><span class="bbp-author-name">iKK</span></a><div class="bbp-author-role">Participant</div>
		
		
	</div>
<!-- .bbp-reply-author -->

	<div class="bbp-reply-content">

		
		<p>Ok, I have everything ready again (thanks to TimeMachine ;) &#8211; &#8230;since I had the OpenEar-only version deleted on git.</p>
<p>1) OpenEars only with German-accModel and Logging (= version as in your <a href="/forums/topic/recognize-short-command-in-nonenglish/#post-1032343">Link</a> &#8211; except moved the logging right after viewDidLoad)</p>
<p>2) OpenEars with Rejecto and German-accModel (with logging right after viewDidLoad)</p>
<p>3) OpenEars with RuleORama with German-accModel (with logging right after viewDidLoad but still with a bug that I don&#8217;t know on how to correct &#8211; see above log)</p>
<p>In the next forum-entry I place the requested Log from the OpenEars-only version that you asked for. If more logs are needed let me know, ok ?</p>

		
	</div>
<!-- .bbp-reply-content -->
</div>
<!-- .reply -->

			
				
<div id="post-1032360" class="bbp-reply-header">
	<div class="bbp-meta">
		<span class="bbp-reply-post-date">April 23, 2018 at 10:44 pm</span>

		
			<span class="bbp-header">
				in reply to: 				<a class="bbp-topic-permalink" href="/forums/topic/recognize-short-command-in-nonenglish/">Recognize short Command in nonEnglish</a>
			</span>

		
		<a href="/forums/topic/recognize-short-command-in-nonenglish/#post-1032360" class="bbp-reply-permalink">#1032360</a>

		
		<span class="bbp-admin-links"></span>
		
	</div>
<!-- .bbp-meta -->
</div>
<!-- #post-1032360 -->

<div class="loop-item-21 user-id-2480 bbp-parent-forum-3654 bbp-parent-topic-1032298 bbp-reply-position-49 even topic-author  post-1032360 reply type-reply status-publish hentry">
	<div class="bbp-reply-author">

		
		<a href="/forums/profile/ikk/" title="View iKK&#039;s profile" class="bbp-author-link"><span class="bbp-author-avatar"></span><span class="bbp-author-name">iKK</span></a><div class="bbp-author-role">Participant</div>
		
		
	</div>
<!-- .bbp-reply-author -->

	<div class="bbp-reply-content">

		
		<p>Sorry &#8211; need to answer you this tomorrow. I don&#8217;t think I do have this project anymore in this state as it was&#8230; Please let me check tomorrow, ok?</p>

		
	</div>
<!-- .bbp-reply-content -->
</div>
<!-- .reply -->

			
				
<div id="post-1032357" class="bbp-reply-header">
	<div class="bbp-meta">
		<span class="bbp-reply-post-date">April 23, 2018 at 10:13 pm</span>

		
			<span class="bbp-header">
				in reply to: 				<a class="bbp-topic-permalink" href="/forums/topic/recognize-short-command-in-nonenglish/">Recognize short Command in nonEnglish</a>
			</span>

		
		<a href="/forums/topic/recognize-short-command-in-nonenglish/#post-1032357" class="bbp-reply-permalink">#1032357</a>

		
		<span class="bbp-admin-links"></span>
		
	</div>
<!-- .bbp-meta -->
</div>
<!-- #post-1032357 -->

<div class="loop-item-22 user-id-2480 bbp-parent-forum-3654 bbp-parent-topic-1032298 bbp-reply-position-46 odd topic-author  post-1032357 reply type-reply status-publish hentry">
	<div class="bbp-reply-author">

		
		<a href="/forums/profile/ikk/" title="View iKK&#039;s profile" class="bbp-author-link"><span class="bbp-author-avatar"></span><span class="bbp-author-name">iKK</span></a><div class="bbp-author-role">Participant</div>
		
		
	</div>
<!-- .bbp-reply-author -->

	<div class="bbp-reply-content">

		
		<p>Log done by RuleORama:</p>
<pre><code>2018-04-23 23:10:25.782460+0300 TestOpenEars[4514:2260548] Starting OpenEars logging for OpenEars version 2.506 on 64-bit device (or build): iPhone running iOS version: 11.300000
2018-04-23 23:10:25.783510+0300 TestOpenEars[4514:2260548] Creating shared instance of OEPocketsphinxController
2018-04-23 23:10:25.804235+0300 TestOpenEars[4514:2260548] RuleORama version 2.502000
2018-04-23 23:10:25.821992+0300 TestOpenEars[4514:2260548] Error: Error Domain=com.politepix.openears Code=6000 &quot;Language model has no content.&quot; UserInfo={NSLocalizedDescription=Language model has no content.}
2018-04-23 23:10:25.822185+0300 TestOpenEars[4514:2260548] Error generating this grammar: Error Domain=com.politepix.openears Code=6000 &quot;Language model has no content.&quot; UserInfo={NSLocalizedDescription=Language model has no content.}
2018-04-23 23:10:25.822216+0300 TestOpenEars[4514:2260548] Generating fast grammar took 0.000543 seconds
2018-04-23 23:10:25.823830+0300 TestOpenEars[4514:2260548] It wasn&#039;t possible to create this grammar: {
    OneOfTheseWillBeSaidOnce =     (
        &quot;esch do no frey&quot;
    );
}
Error while creating initial language model: Optional(Error Domain=LanguageModelErrorDomain Code=10040 &quot;It wasn&#039;t possible to generate a grammar for this dictionary, please turn on OELogging for more information&quot; UserInfo={NSLocalizedDescription=It wasn&#039;t possible to generate a grammar for this dictionary, please turn on OELogging for more information})
2018-04-23 23:10:25.828302+0300 TestOpenEars[4514:2260548] Attempting to start listening session from startListeningWithLanguageModelAtPath:
2018-04-23 23:10:25.828354+0300 TestOpenEars[4514:2260548] Error: you have invoked the method:

startListeningWithLanguageModelAtPath:(NSString *)languageModelPath dictionaryAtPath:(NSString *)dictionaryPath acousticModelAtPath:(NSString *)acousticModelPath languageModelIsJSGF:(BOOL)languageModelIsJSGF

with a languageModelPath which is nil. If your call to OELanguageModelGenerator did not return an error when you generated this grammar, that means the correct path to your grammar that you should pass to this method&#039;s languageModelPath argument is as follows:

NSString *correctPathToMyLanguageModelFile = [myLanguageModelGenerator pathToSuccessfullyGeneratedGrammarWithRequestedName:@&quot;TheNameIChoseForMyVocabulary&quot;];

Feel free to copy and paste this code for your path to your grammar, but remember to replace the part that says &quot;TheNameIChoseForMyVocabulary&quot; with the name you actually chose for your grammar or you will get this error again (and replace myLanguageModelGenerator with the name of your OELanguageModelGenerator instance). Since this file is required, expect an exception or undocumented behavior shortly.
2018-04-23 23:11:00.068429+0300 TestOpenEars[4514:2260548] Status bar could not find cached time string image. Rendering in-process.
2018-04-23 23:12:00.002388+0300 TestOpenEars[4514:2260548] Status bar could not find cached time string image. Rendering in-process.
2018-04-23 23:13:00.003170+0300 TestOpenEars[4514:2260548] Status bar could not find cached time string image. Rendering in-process.</code></pre>

		
	</div>
<!-- .bbp-reply-content -->
</div>
<!-- .reply -->

			
				
<div id="post-1032356" class="bbp-reply-header">
	<div class="bbp-meta">
		<span class="bbp-reply-post-date">April 23, 2018 at 10:12 pm</span>

		
			<span class="bbp-header">
				in reply to: 				<a class="bbp-topic-permalink" href="/forums/topic/recognize-short-command-in-nonenglish/">Recognize short Command in nonEnglish</a>
			</span>

		
		<a href="/forums/topic/recognize-short-command-in-nonenglish/#post-1032356" class="bbp-reply-permalink">#1032356</a>

		
		<span class="bbp-admin-links"></span>
		
	</div>
<!-- .bbp-meta -->
</div>
<!-- #post-1032356 -->

<div class="loop-item-23 user-id-2480 bbp-parent-forum-3654 bbp-parent-topic-1032298 bbp-reply-position-45 even topic-author  post-1032356 reply type-reply status-publish hentry">
	<div class="bbp-reply-author">

		
		<a href="/forums/profile/ikk/" title="View iKK&#039;s profile" class="bbp-author-link"><span class="bbp-author-avatar"></span><span class="bbp-author-name">iKK</span></a><div class="bbp-author-role">Participant</div>
		
		
	</div>
<!-- .bbp-reply-author -->

	<div class="bbp-reply-content">

		
		<p>Log from 5 Rejecto trials :</p>
<pre><code>2018-04-23 23:05:12.918271+0300 TestOpenEars[4509:2258026] Starting OpenEars logging for OpenEars version 2.506 on 64-bit device (or build): iPhone running iOS version: 11.300000
2018-04-23 23:05:12.919509+0300 TestOpenEars[4509:2258026] Creating shared instance of OEPocketsphinxController
2018-04-23 23:05:12.941856+0300 TestOpenEars[4509:2258026] Rejecto version 2.500000
2018-04-23 23:05:12.943018+0300 TestOpenEars[4509:2258026] Since there is no cached version, loading the g2p model for the acoustic model called AcousticModelGerman
2018-04-23 23:05:13.041475+0300 TestOpenEars[4509:2258026] Since there is no cached version, loading the language model lookup list for the acoustic model called AcousticModelGerman
2018-04-23 23:05:13.049510+0300 TestOpenEars[4509:2258026] Returning a cached version of LanguageModelGeneratorLookupList.text
2018-04-23 23:05:13.049628+0300 TestOpenEars[4509:2258026] Returning a cached version of g2p
2018-04-23 23:05:13.054494+0300 TestOpenEars[4509:2258026] The word do was not found in the dictionary of the acoustic model /var/containers/Bundle/Application/43D01A3B-05FF-4662-87CD-082AE28DF8B2/TestOpenEars.app/AcousticModelGerman.bundle. Now using the fallback method to look it up. If this is happening more frequently than you would expect, likely causes can be that you are entering words in another language from the one you are recognizing, or that there are symbols (including numbers) that need to be spelled out or cleaned up, or you are using your own acoustic model and there is an issue with either its phonetic dictionary or it lacks a g2p file. Please get in touch at the forums for assistance with the last two possible issues.
2018-04-23 23:05:13.054778+0300 TestOpenEars[4509:2258026] the graphemes &quot;d oo&quot; were created for the word do using the fallback method.
2018-04-23 23:05:13.059873+0300 TestOpenEars[4509:2258026] The word esch was not found in the dictionary of the acoustic model /var/containers/Bundle/Application/43D01A3B-05FF-4662-87CD-082AE28DF8B2/TestOpenEars.app/AcousticModelGerman.bundle. Now using the fallback method to look it up. If this is happening more frequently than you would expect, likely causes can be that you are entering words in another language from the one you are recognizing, or that there are symbols (including numbers) that need to be spelled out or cleaned up, or you are using your own acoustic model and there is an issue with either its phonetic dictionary or it lacks a g2p file. Please get in touch at the forums for assistance with the last two possible issues.
2018-04-23 23:05:13.060119+0300 TestOpenEars[4509:2258026] the graphemes &quot;@ ss&quot; were created for the word esch using the fallback method.
2018-04-23 23:05:13.065637+0300 TestOpenEars[4509:2258026] The word frey was not found in the dictionary of the acoustic model /var/containers/Bundle/Application/43D01A3B-05FF-4662-87CD-082AE28DF8B2/TestOpenEars.app/AcousticModelGerman.bundle. Now using the fallback method to look it up. If this is happening more frequently than you would expect, likely causes can be that you are entering words in another language from the one you are recognizing, or that there are symbols (including numbers) that need to be spelled out or cleaned up, or you are using your own acoustic model and there is an issue with either its phonetic dictionary or it lacks a g2p file. Please get in touch at the forums for assistance with the last two possible issues.
2018-04-23 23:05:13.066140+0300 TestOpenEars[4509:2258026] the graphemes &quot;f r @ ii&quot; were created for the word frey using the fallback method.
2018-04-23 23:05:13.071132+0300 TestOpenEars[4509:2258026] The word no was not found in the dictionary of the acoustic model /var/containers/Bundle/Application/43D01A3B-05FF-4662-87CD-082AE28DF8B2/TestOpenEars.app/AcousticModelGerman.bundle. Now using the fallback method to look it up. If this is happening more frequently than you would expect, likely causes can be that you are entering words in another language from the one you are recognizing, or that there are symbols (including numbers) that need to be spelled out or cleaned up, or you are using your own acoustic model and there is an issue with either its phonetic dictionary or it lacks a g2p file. Please get in touch at the forums for assistance with the last two possible issues.
2018-04-23 23:05:13.071372+0300 TestOpenEars[4509:2258026] the graphemes &quot;n oo&quot; were created for the word no using the fallback method.
2018-04-23 23:05:13.071437+0300 TestOpenEars[4509:2258026] I&#039;m done running performDictionaryLookup and it took 0.021849 seconds
2018-04-23 23:05:13.071773+0300 TestOpenEars[4509:2258026] I&#039;m done running performDictionaryLookup and it took 0.022536 seconds
2018-04-23 23:05:13.077796+0300 TestOpenEars[4509:2258026] A value has been given for weight, but it is identical to the default so we are ignoring it.
2018-04-23 23:05:13.077861+0300 TestOpenEars[4509:2258026] Starting dynamic language model generation

INFO: ngram_model_arpa_legacy.c(504): ngrams 1=26, 2=45, 3=24
INFO: ngram_model_arpa_legacy.c(136): Reading unigrams
INFO: ngram_model_arpa_legacy.c(543):       26 = #unigrams created
INFO: ngram_model_arpa_legacy.c(196): Reading bigrams
INFO: ngram_model_arpa_legacy.c(561):       45 = #bigrams created
INFO: ngram_model_arpa_legacy.c(562):        3 = #prob2 entries
INFO: ngram_model_arpa_legacy.c(570):        3 = #bo_wt2 entries
INFO: ngram_model_arpa_legacy.c(293): Reading trigrams
INFO: ngram_model_arpa_legacy.c(583):       24 = #trigrams created
INFO: ngram_model_arpa_legacy.c(584):        2 = #prob3 entries
INFO: ngram_model_dmp_legacy.c(521): Building DMP model...
INFO: ngram_model_dmp_legacy.c(551):       26 = #unigrams created
INFO: ngram_model_dmp_legacy.c(652):       45 = #bigrams created
INFO: ngram_model_dmp_legacy.c(653):        3 = #prob2 entries
INFO: ngram_model_dmp_legacy.c(660):        3 = #bo_wt2 entries
INFO: ngram_model_dmp_legacy.c(664):       24 = #trigrams created
INFO: ngram_model_dmp_legacy.c(665):        2 = #prob3 entries
2018-04-23 23:05:13.173883+0300 TestOpenEars[4509:2258026] Done creating language model with CMUCLMTK in 0.095971 seconds.
INFO: ngram_model_arpa_legacy.c(504): ngrams 1=26, 2=45, 3=24
INFO: ngram_model_arpa_legacy.c(136): Reading unigrams
INFO: ngram_model_arpa_legacy.c(543):       26 = #unigrams created
INFO: ngram_model_arpa_legacy.c(196): Reading bigrams
INFO: ngram_model_arpa_legacy.c(561):       45 = #bigrams created
INFO: ngram_model_arpa_legacy.c(562):        3 = #prob2 entries
INFO: ngram_model_arpa_legacy.c(570):        3 = #bo_wt2 entries
INFO: ngram_model_arpa_legacy.c(293): Reading trigrams
INFO: ngram_model_arpa_legacy.c(583):       24 = #trigrams created
INFO: ngram_model_arpa_legacy.c(584):        2 = #prob3 entries
INFO: ngram_model_dmp_legacy.c(521): Building DMP model...
INFO: ngram_model_dmp_legacy.c(551):       26 = #unigrams created
INFO: ngram_model_dmp_legacy.c(652):       45 = #bigrams created
INFO: ngram_model_dmp_legacy.c(653):        3 = #prob2 entries
INFO: ngram_model_dmp_legacy.c(660):        3 = #bo_wt2 entries
INFO: ngram_model_dmp_legacy.c(664):       24 = #trigrams created
INFO: ngram_model_dmp_legacy.c(665):        2 = #prob3 entries
2018-04-23 23:05:13.178718+0300 TestOpenEars[4509:2258026] I&#039;m done running dynamic language model generation and it took 0.235861 seconds
2018-04-23 23:05:13.180002+0300 TestOpenEars[4509:2258026] Attempting to start listening session from startListeningWithLanguageModelAtPath:
2018-04-23 23:05:13.184972+0300 TestOpenEars[4509:2258026] User gave mic permission for this app.
2018-04-23 23:05:13.185249+0300 TestOpenEars[4509:2258026] setSecondsOfSilence wasn&#039;t set, using default of 0.700000.
2018-04-23 23:05:13.186600+0300 TestOpenEars[4509:2258157] Starting listening.
2018-04-23 23:05:13.186840+0300 TestOpenEars[4509:2258157] About to set up audio session
2018-04-23 23:05:13.379133+0300 TestOpenEars[4509:2258157] Creating audio session with default settings.
2018-04-23 23:05:13.379218+0300 TestOpenEars[4509:2258157] Done setting audio session category.
2018-04-23 23:05:13.388928+0300 TestOpenEars[4509:2258157] Done setting preferred sample rate to 16000.000000 – now the real sample rate is 48000.000000
2018-04-23 23:05:13.390500+0300 TestOpenEars[4509:2258157] number of channels is already the preferred number of 1 so not setting it.
2018-04-23 23:05:13.395573+0300 TestOpenEars[4509:2258157] Done setting session&#039;s preferred I/O buffer duration to 0.128000 – now the actual buffer duration is 0.085333
2018-04-23 23:05:13.395785+0300 TestOpenEars[4509:2258157] Done setting up audio session
2018-04-23 23:05:13.402184+0300 TestOpenEars[4509:2258166] Audio route has changed for the following reason:
2018-04-23 23:05:13.404934+0300 TestOpenEars[4509:2258157] About to set up audio IO unit in a session with a sample rate of 48000.000000, a channel number of 1 and a buffer duration of 0.085333.
2018-04-23 23:05:13.405005+0300 TestOpenEars[4509:2258166] There was a category change. The new category is AVAudioSessionCategoryPlayAndRecord
2018-04-23 23:05:13.543573+0300 TestOpenEars[4509:2258166] This is not a case in which OpenEars notifies of a route change. At the close of this method, the new audio route will be &lt;Input route or routes: &quot;MicrophoneBuiltIn&quot;. Output route or routes: &quot;Speaker&quot;&gt;. The previous route before changing to this route was &quot;&lt;AVAudioSessionRouteDescription: 0x1c021a550, 
inputs = (null); 
outputs = (
    &quot;&lt;AVAudioSessionPortDescription: 0x1c021a390, type = Speaker; name = Speaker; UID = Speaker; selectedDataSource = (null)&gt;&quot;
)&gt;&quot;.
2018-04-23 23:05:13.546940+0300 TestOpenEars[4509:2258166] Audio route has changed for the following reason:
2018-04-23 23:05:13.547508+0300 TestOpenEars[4509:2258166] There was a category change. The new category is AVAudioSessionCategoryPlayAndRecord
2018-04-23 23:05:13.550799+0300 TestOpenEars[4509:2258166] This is not a case in which OpenEars notifies of a route change. At the close of this method, the new audio route will be &lt;Input route or routes: &quot;MicrophoneBuiltIn&quot;. Output route or routes: &quot;Speaker&quot;&gt;. The previous route before changing to this route was &quot;&lt;AVAudioSessionRouteDescription: 0x1c021a4c0, 
inputs = (
    &quot;&lt;AVAudioSessionPortDescription: 0x1c021a3a0, type = MicrophoneBuiltIn; name = iPhone Microphone; UID = Built-In Microphone; selectedDataSource = Bottom&gt;&quot;
); 
outputs = (
    &quot;&lt;AVAudioSessionPortDescription: 0x1c44061f0, type = Receiver; name = Receiver; UID = Built-In Receiver; selectedDataSource = (null)&gt;&quot;
)&gt;&quot;.
2018-04-23 23:05:13.569655+0300 TestOpenEars[4509:2258157] Done setting up audio unit
2018-04-23 23:05:13.570040+0300 TestOpenEars[4509:2258157] About to start audio IO unit
2018-04-23 23:05:13.790136+0300 TestOpenEars[4509:2258157] Done starting audio unit
INFO: pocketsphinx.c(145): Parsed model-specific feature parameters from /var/containers/Bundle/Application/43D01A3B-05FF-4662-87CD-082AE28DF8B2/TestOpenEars.app/AcousticModelGerman.bundle/feat.params
Current configuration:
[NAME]			[DEFLT]		[VALUE]
-agc			none		none
-agcthresh		2.0		2.000000e+00
-allphone				
-allphone_ci		no		no
-alpha			0.97		9.700000e-01
-ascale			20.0		2.000000e+01
-aw			1		1
-backtrace		no		no
-beam			1e-48		1.000000e-48
-bestpath		yes		yes
-bestpathlw		9.5		9.500000e+00
-ceplen			13		13
-cmn			current		current
-cmninit		8.0		30
-compallsen		no		no
-debug					0
-dict					/var/mobile/Containers/Data/Application/2235C424-8991-43FD-BD60-771ABE6FEF52/Library/Caches/GermanModel.dic
-dictcase		no		no
-dither			no		no
-doublebw		no		no
-ds			1		1
-fdict					/var/containers/Bundle/Application/43D01A3B-05FF-4662-87CD-082AE28DF8B2/TestOpenEars.app/AcousticModelGerman.bundle/noisedict
-feat			1s_c_d_dd	1s_c_d_dd
-featparams				/var/containers/Bundle/Application/43D01A3B-05FF-4662-87CD-082AE28DF8B2/TestOpenEars.app/AcousticModelGerman.bundle/feat.params
-fillprob		1e-8		1.000000e-08
-frate			100		100
-fsg					
-fsgusealtpron		yes		yes
-fsgusefiller		yes		yes
-fwdflat		yes		yes
-fwdflatbeam		1e-64		1.000000e-64
-fwdflatefwid		4		4
-fwdflatlw		8.5		8.500000e+00
-fwdflatsfwin		25		25
-fwdflatwbeam		7e-29		7.000000e-29
-fwdtree		yes		yes
-hmm					/var/containers/Bundle/Application/43D01A3B-05FF-4662-87CD-082AE28DF8B2/TestOpenEars.app/AcousticModelGerman.bundle
-input_endian		little		little
-jsgf					/var/mobile/Containers/Data/Application/2235C424-8991-43FD-BD60-771ABE6FEF52/Library/Caches/GermanModel.gram
-keyphrase				
-kws					
-kws_delay		10		10
-kws_plp		1e-1		1.000000e-01
-kws_threshold		1		1.000000e+00
-latsize		5000		5000
-lda					
-ldadim			0		0
-lifter			0		22
-lm					
-lmctl					
-lmname					
-logbase		1.0001		1.000100e+00
-logfn					
-logspec		no		no
-lowerf			133.33334	1.300000e+02
-lpbeam			1e-40		1.000000e-40
-lponlybeam		7e-29		7.000000e-29
-lw			6.5		1.000000e+00
-maxhmmpf		30000		30000
-maxwpf			-1		-1
-mdef					/var/containers/Bundle/Application/43D01A3B-05FF-4662-87CD-082AE28DF8B2/TestOpenEars.app/AcousticModelGerman.bundle/mdef
-mean					/var/containers/Bundle/Application/43D01A3B-05FF-4662-87CD-082AE28DF8B2/TestOpenEars.app/AcousticModelGerman.bundle/means
-mfclogdir				
-min_endfr		0		0
-mixw					/var/containers/Bundle/Application/43D01A3B-05FF-4662-87CD-082AE28DF8B2/TestOpenEars.app/AcousticModelGerman.bundle/mixture_weights
-mixwfloor		0.0000001	1.000000e-07
-mllr					
-mmap			yes		yes
-ncep			13		13
-nfft			512		512
-nfilt			40		25
-nwpen			1.0		1.000000e+00
-pbeam			1e-48		1.000000e-48
-pip			1.0		1.000000e+00
-pl_beam		1e-10		1.000000e-10
-pl_pbeam		1e-10		1.000000e-10
-pl_pip			1.0		1.000000e+00
-pl_weight		3.0		3.000000e+00
-pl_window		5		5
-rawlogdir				
-remove_dc		no		no
-remove_noise		yes		yes
-remove_silence		yes		yes
-round_filters		yes		yes
-samprate		16000		1.600000e+04
-seed			-1		-1
-sendump				
-senlogdir				
-senmgau				
-silprob		0.005		5.000000e-03
-smoothspec		no		no
-svspec					
-tmat					/var/containers/Bundle/Application/43D01A3B-05FF-4662-87CD-082AE28DF8B2/TestOpenEars.app/AcousticModelGerman.bundle/transition_matrices
-tmatfloor		0.0001		1.000000e-04
-topn			4		4
-topn_beam		0		0
-toprule				
-transform		legacy		dct
-unit_area		yes		yes
-upperf			6855.4976	6.800000e+03
-uw			1.0		1.000000e+00
-vad_postspeech		50		69
-vad_prespeech		20		10
-vad_startspeech	10		10
-vad_threshold		2.0		3.200000e+00
-var					/var/containers/Bundle/Application/43D01A3B-05FF-4662-87CD-082AE28DF8B2/TestOpenEars.app/AcousticModelGerman.bundle/variances
-varfloor		0.0001		1.000000e-04
-varnorm		no		no
-verbose		no		no
-warp_params				
-warp_type		inverse_linear	inverse_linear
-wbeam			7e-29		7.000000e-29
-wip			0.65		6.500000e-01
-wlen			0.025625	2.562500e-02

INFO: feat.c(715): Initializing feature stream to type: &#039;1s_c_d_dd&#039;, ceplen=13, CMN=&#039;current&#039;, VARNORM=&#039;no&#039;, AGC=&#039;none&#039;
INFO: cmn.c(143): mean[0]= 12.00, mean[1..12]= 0.0
INFO: mdef.c(518): Reading model definition: /var/containers/Bundle/Application/43D01A3B-05FF-4662-87CD-082AE28DF8B2/TestOpenEars.app/AcousticModelGerman.bundle/mdef
INFO: bin_mdef.c(181): Allocating 53834 * 8 bytes (420 KiB) for CD tree
INFO: tmat.c(206): Reading HMM transition probability matrices: /var/containers/Bundle/Application/43D01A3B-05FF-4662-87CD-082AE28DF8B2/TestOpenEars.app/AcousticModelGerman.bundle/transition_matrices
INFO: acmod.c(117): Attempting to use PTM computation module
INFO: ms_gauden.c(198): Reading mixture gaussian parameter: /var/containers/Bundle/Application/43D01A3B-05FF-4662-87CD-082AE28DF8B2/TestOpenEars.app/AcousticModelGerman.bundle/means
INFO: ms_gauden.c(292): 2129 codebook, 1 feature, size: 
INFO: ms_gauden.c(294):  32x39
INFO: ms_gauden.c(198): Reading mixture gaussian parameter: /var/containers/Bundle/Application/43D01A3B-05FF-4662-87CD-082AE28DF8B2/TestOpenEars.app/AcousticModelGerman.bundle/variances
INFO: ms_gauden.c(292): 2129 codebook, 1 feature, size: 
INFO: ms_gauden.c(294):  32x39
INFO: ms_gauden.c(354): 7100 variance values floored
INFO: ptm_mgau.c(801): Number of codebooks exceeds 256: 2129
INFO: acmod.c(119): Attempting to use semi-continuous computation module
INFO: ms_gauden.c(198): Reading mixture gaussian parameter: /var/containers/Bundle/Application/43D01A3B-05FF-4662-87CD-082AE28DF8B2/TestOpenEars.app/AcousticModelGerman.bundle/means
INFO: ms_gauden.c(292): 2129 codebook, 1 feature, size: 
INFO: ms_gauden.c(294):  32x39
INFO: ms_gauden.c(198): Reading mixture gaussian parameter: /var/containers/Bundle/Application/43D01A3B-05FF-4662-87CD-082AE28DF8B2/TestOpenEars.app/AcousticModelGerman.bundle/variances
INFO: ms_gauden.c(292): 2129 codebook, 1 feature, size: 
INFO: ms_gauden.c(294):  32x39
INFO: ms_gauden.c(354): 7100 variance values floored
INFO: acmod.c(121): Falling back to general multi-stream GMM computation
INFO: ms_gauden.c(198): Reading mixture gaussian parameter: /var/containers/Bundle/Application/43D01A3B-05FF-4662-87CD-082AE28DF8B2/TestOpenEars.app/AcousticModelGerman.bundle/means
INFO: ms_gauden.c(292): 2129 codebook, 1 feature, size: 
INFO: ms_gauden.c(294):  32x39
INFO: ms_gauden.c(198): Reading mixture gaussian parameter: /var/containers/Bundle/Application/43D01A3B-05FF-4662-87CD-082AE28DF8B2/TestOpenEars.app/AcousticModelGerman.bundle/variances
INFO: ms_gauden.c(292): 2129 codebook, 1 feature, size: 
INFO: ms_gauden.c(294):  32x39
INFO: ms_gauden.c(354): 7100 variance values floored
INFO: ms_senone.c(149): Reading senone mixture weights: /var/containers/Bundle/Application/43D01A3B-05FF-4662-87CD-082AE28DF8B2/TestOpenEars.app/AcousticModelGerman.bundle/mixture_weights
INFO: ms_senone.c(200): Truncating senone logs3(pdf) values by 10 bits
INFO: ms_senone.c(207): Not transposing mixture weights in memory
INFO: ms_senone.c(268): Read mixture weights for 2129 senones: 1 features x 32 codewords
INFO: ms_senone.c(320): Mapping senones to individual codebooks
INFO: ms_mgau.c(141): The value of topn: 4
INFO: phone_loop_search.c(114): State beam -225 Phone exit beam -225 Insertion penalty 0
INFO: dict.c(320): Allocating 4124 * 32 bytes (128 KiB) for word entries
INFO: dict.c(333): Reading main dictionary: /var/mobile/Containers/Data/Application/2235C424-8991-43FD-BD60-771ABE6FEF52/Library/Caches/GermanModel.dic
INFO: dict.c(213): Allocated 0 KiB for strings, 0 KiB for phones
INFO: dict.c(336): 24 words read
INFO: dict.c(358): Reading filler dictionary: /var/containers/Bundle/Application/43D01A3B-05FF-4662-87CD-082AE28DF8B2/TestOpenEars.app/AcousticModelGerman.bundle/noisedict
INFO: dict.c(213): Allocated 0 KiB for strings, 0 KiB for phones
INFO: dict.c(361): 4 words read
INFO: dict2pid.c(396): Building PID tables for dictionary
INFO: dict2pid.c(406): Allocating 43^3 * 2 bytes (155 KiB) for word-initial triphones
INFO: dict2pid.c(132): Allocated 44720 bytes (43 KiB) for word-final triphones
INFO: dict2pid.c(196): Allocated 44720 bytes (43 KiB) for single-phone word triphones
INFO: jsgf.c(691): Defined rule: &lt;GermanModel.g00000&gt;
INFO: jsgf.c(691): Defined rule: PUBLIC &lt;GermanModel.rule_0&gt;
INFO: fsg_model.c(215): Computing transitive closure for null transitions
INFO: fsg_model.c(277): 0 null transitions added
INFO: fsg_search.c(227): FSG(beam: -1080, pbeam: -1080, wbeam: -634; wip: -5, pip: 0)
INFO: fsg_model.c(428): Adding silence transitions for &lt;sil&gt; to FSG
INFO: fsg_model.c(448): Added 5 silence word transitions
INFO: fsg_model.c(428): Adding silence transitions for &lt;sil&gt; to FSG
INFO: fsg_model.c(448): Added 5 silence word transitions
INFO: fsg_search.c(173): Added 0 alternate word transitions
INFO: fsg_lextree.c(110): Allocated 440 bytes (0 KiB) for left and right context phones
INFO: fsg_lextree.c(256): 17 HMM nodes in lextree (11 leaves)
INFO: fsg_lextree.c(259): Allocated 2448 bytes (2 KiB) for all lextree nodes
INFO: fsg_lextree.c(262): Allocated 1584 bytes (1 KiB) for lextree leafnodes
2018-04-23 23:05:14.614291+0300 TestOpenEars[4509:2258157] There is no CMN plist so we are using the fresh CMN value 30.000000.
2018-04-23 23:05:14.614826+0300 TestOpenEars[4509:2258157] Listening.
2018-04-23 23:05:14.615526+0300 TestOpenEars[4509:2258157] Project has these words or phrases in its dictionary:
___REJ_yy
___REJ_y:
___REJ_uu
___REJ_ui:
___REJ_ui
___REJ_u:
___REJ_oy
___REJ_oo
___REJ_o:
___REJ_ii
___REJ_i:
___REJ_ei
___REJ_ee:
___REJ_ee
___REJ_e:
___REJ_au
___REJ_ai
___REJ_aa:
___REJ_a
___REJ_@
do
esch
frey
no
2018-04-23 23:05:14.616365+0300 TestOpenEars[4509:2258157] Recognition loop has started
2018-04-23 23:05:14.616672+0300 TestOpenEars[4509:2258026] Successfully started listening session from startListeningWithLanguageModelAtPath:
Local callback: Pocketsphinx is now listening.
Local callback: Pocketsphinx started.
2018-04-23 23:05:15.009217+0300 TestOpenEars[4509:2258263] Speech detected...
Local callback: Pocketsphinx has detected speech.
2018-04-23 23:05:15.799115+0300 TestOpenEars[4509:2258263] End of speech detected...
INFO: cmn_prior.c(131): cmn_prior_update: from &lt; 30.00 Local callback: Pocketsphinx has detected a second of silence, concluding an utterance.
 0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00 &gt;
INFO: cmn_prior.c(149): cmn_prior_update: to   &lt; 44.41 30.50  8.46 18.30  6.58  0.68  6.31  2.90  2.41 -1.35  6.45  2.09 -2.91 &gt;
INFO: fsg_search.c(843): 91 frames, 1007 HMMs (11/fr), 2357 senones (25/fr), 460 history entries (5/fr)

ERROR: &quot;fsg_search.c&quot;, line 913: Final result does not match the grammar in frame 91
2018-04-23 23:05:15.800405+0300 TestOpenEars[4509:2258263] Pocketsphinx heard &quot; &quot; with a score of (0) and an utterance ID of 0.
2018-04-23 23:05:15.800484+0300 TestOpenEars[4509:2258263] Hypothesis was null so we aren&#039;t returning it. If you want null hypotheses to also be returned, set OEPocketsphinxController&#039;s property returnNullHypotheses to TRUE before starting OEPocketsphinxController.
2018-04-23 23:05:18.838269+0300 TestOpenEars[4509:2258158] Speech detected...
Local callback: Pocketsphinx has detected speech.
2018-04-23 23:05:20.650945+0300 TestOpenEars[4509:2258158] End of speech detected...
Local callback: Pocketsphinx has detected a second of silence, concluding an utterance.
INFO: cmn_prior.c(131): cmn_prior_update: from &lt; 44.41 30.50  8.46 18.30  6.58  0.68  6.31  2.90  2.41 -1.35  6.45  2.09 -2.91 &gt;
INFO: cmn_prior.c(149): cmn_prior_update: to   &lt; 53.26 20.96  4.55 17.38  0.21 -1.67  4.79 -0.35 -0.18 -4.38  6.48 -1.25 -0.39 &gt;
INFO: fsg_search.c(843): 181 frames, 2069 HMMs (11/fr), 4811 senones (26/fr), 686 history entries (3/fr)

2018-04-23 23:05:20.651764+0300 TestOpenEars[4509:2258158] Pocketsphinx heard &quot;esch do no frey&quot; with a score of (0) and an utterance ID of 1.
Local callback: The received hypothesis is esch do no frey with a score of 0 and an ID of 1
2018-04-23 23:05:23.066355+0300 TestOpenEars[4509:2258158] Speech detected...
Local callback: Pocketsphinx has detected speech.
2018-04-23 23:05:24.596305+0300 TestOpenEars[4509:2258158] End of speech detected...
Local callback: Pocketsphinx has detected a second of silence, concluding an utterance.
INFO: cmn_prior.c(131): cmn_prior_update: from &lt; 53.26 20.96  4.55 17.38  0.21 -1.67  4.79 -0.35 -0.18 -4.38  6.48 -1.25 -0.39 &gt;
INFO: cmn_prior.c(149): cmn_prior_update: to   &lt; 54.65 18.41  2.70 19.09 -0.71 -1.76  5.51 -0.36 -1.55 -4.42  6.28 -2.13  0.55 &gt;
INFO: fsg_search.c(843): 162 frames, 1278 HMMs (7/fr), 3174 senones (19/fr), 459 history entries (2/fr)

2018-04-23 23:05:24.597442+0300 TestOpenEars[4509:2258158] Pocketsphinx heard &quot;esch do no frey&quot; with a score of (0) and an utterance ID of 2.
Local callback: The received hypothesis is esch do no frey with a score of 0 and an ID of 2
2018-04-23 23:05:27.788021+0300 TestOpenEars[4509:2258158] Speech detected...
Local callback: Pocketsphinx has detected speech.
2018-04-23 23:05:29.850067+0300 TestOpenEars[4509:2258158] End of speech detected...
Local callback: Pocketsphinx has detected a second of silence, concluding an utterance.
INFO: cmn_prior.c(131): cmn_prior_update: from &lt; 54.65 18.41  2.70 19.09 -0.71 -1.76  5.51 -0.36 -1.55 -4.42  6.28 -2.13  0.55 &gt;
INFO: cmn_prior.c(149): cmn_prior_update: to   &lt; 54.51 15.96  2.96 17.45 -1.80 -3.57  5.57  0.03 -0.98 -3.84  6.16 -2.31  0.42 &gt;
INFO: fsg_search.c(843): 213 frames, 2056 HMMs (9/fr), 5431 senones (25/fr), 682 history entries (3/fr)

2018-04-23 23:05:29.851350+0300 TestOpenEars[4509:2258158] Pocketsphinx heard &quot;esch do no frey&quot; with a score of (0) and an utterance ID of 3.
Local callback: The received hypothesis is esch do no frey with a score of 0 and an ID of 3
2018-04-23 23:05:31.887961+0300 TestOpenEars[4509:2258158] Speech detected...
Local callback: Pocketsphinx has detected speech.
INFO: cmn_prior.c(99): cmn_prior_update: from &lt; 54.51 15.96  2.96 17.45 -1.80 -3.57  5.57  0.03 -0.98 -3.84  6.16 -2.31  0.42 &gt;
INFO: cmn_prior.c(116): cmn_prior_update: to   &lt; 55.54 13.48  2.27 17.55 -2.54 -4.29  5.28 -0.03 -1.65 -3.59  6.26 -2.36  0.88 &gt;
2018-04-23 23:05:34.105732+0300 TestOpenEars[4509:2258158] End of speech detected...
Local callback: Pocketsphinx has detected a second of silence, concluding an utterance.
INFO: cmn_prior.c(131): cmn_prior_update: from &lt; 55.54 13.48  2.27 17.55 -2.54 -4.29  5.28 -0.03 -1.65 -3.59  6.26 -2.36  0.88 &gt;
INFO: cmn_prior.c(149): cmn_prior_update: to   &lt; 52.94 14.17  2.28 16.13 -1.96 -3.92  5.22 -0.20 -1.13 -3.16  6.55 -1.67  0.61 &gt;
INFO: fsg_search.c(843): 224 frames, 1865 HMMs (8/fr), 5165 senones (23/fr), 563 history entries (2/fr)

2018-04-23 23:05:34.107134+0300 TestOpenEars[4509:2258158] Pocketsphinx heard &quot;esch do no frey&quot; with a score of (0) and an utterance ID of 4.
Local callback: The received hypothesis is esch do no frey with a score of 0 and an ID of 4
2018-04-23 23:05:35.979058+0300 TestOpenEars[4509:2258158] Speech detected...
Local callback: Pocketsphinx has detected speech.
2018-04-23 23:05:37.790857+0300 TestOpenEars[4509:2258158] End of speech detected...
Local callback: Pocketsphinx has detected a second of silence, concluding an utterance.
INFO: cmn_prior.c(131): cmn_prior_update: from &lt; 52.94 14.17  2.28 16.13 -1.96 -3.92  5.22 -0.20 -1.13 -3.16  6.55 -1.67  0.61 &gt;
INFO: cmn_prior.c(149): cmn_prior_update: to   &lt; 53.41 11.98  2.53 14.97 -2.38 -4.02  5.18  0.31 -1.08 -2.87  5.96 -1.54  0.32 &gt;
INFO: fsg_search.c(843): 186 frames, 1338 HMMs (7/fr), 3723 senones (20/fr), 409 history entries (2/fr)

2018-04-23 23:05:37.792028+0300 TestOpenEars[4509:2258158] Pocketsphinx heard &quot;esch do no frey&quot; with a score of (0) and an utterance ID of 5.
Local callback: The received hypothesis is esch do no frey with a score of 0 and an ID of 5</code></pre>

		
	</div>
<!-- .bbp-reply-content -->
</div>
<!-- .reply -->

			
				
<div id="post-1032355" class="bbp-reply-header">
	<div class="bbp-meta">
		<span class="bbp-reply-post-date">April 23, 2018 at 10:12 pm</span>

		
			<span class="bbp-header">
				in reply to: 				<a class="bbp-topic-permalink" href="/forums/topic/recognize-short-command-in-nonenglish/">Recognize short Command in nonEnglish</a>
			</span>

		
		<a href="/forums/topic/recognize-short-command-in-nonenglish/#post-1032355" class="bbp-reply-permalink">#1032355</a>

		
		<span class="bbp-admin-links"></span>
		
	</div>
<!-- .bbp-meta -->
</div>
<!-- #post-1032355 -->

<div class="loop-item-24 user-id-2480 bbp-parent-forum-3654 bbp-parent-topic-1032298 bbp-reply-position-44 odd topic-author  post-1032355 reply type-reply status-publish hentry">
	<div class="bbp-reply-author">

		
		<a href="/forums/profile/ikk/" title="View iKK&#039;s profile" class="bbp-author-link"><span class="bbp-author-avatar"></span><span class="bbp-author-name">iKK</span></a><div class="bbp-author-role">Participant</div>
		
		
	</div>
<!-- .bbp-reply-author -->

	<div class="bbp-reply-content">

		
		<p>I am sorry about my tone during RuleORama-demo-trials today &#8211; I felt a bit stressed out since things did not fit immediately :/ I do appreciate your help !</p>
<p>As requested, I did move the log-code accordingly (i..e after viewDidLoad).</p>
<p>Please see the following two forum-entries for the two Logs</p>
<p>(1) : Done by Rejecto<br>
&#8211;&gt; There are 5 times I spoke, the two first times are spoken correctly (i.e. our  words-array) &#8211; the thrid, fourth and fitht time is spoken incorrectly (but unfortunately still recognized by Rejecto)</p>
<p>(2) : Done by RuleORama<br>
&#8211;&gt; Still, there is a bug in code as can be read in the log&#8230;</p>

		
	</div>
<!-- .bbp-reply-content -->
</div>
<!-- .reply -->

			
				
<div id="post-1032352" class="bbp-reply-header">
	<div class="bbp-meta">
		<span class="bbp-reply-post-date">April 23, 2018 at 1:14 pm</span>

		
			<span class="bbp-header">
				in reply to: 				<a class="bbp-topic-permalink" href="/forums/topic/recognize-short-command-in-nonenglish/">Recognize short Command in nonEnglish</a>
			</span>

		
		<a href="/forums/topic/recognize-short-command-in-nonenglish/#post-1032352" class="bbp-reply-permalink">#1032352</a>

		
		<span class="bbp-admin-links"></span>
		
	</div>
<!-- .bbp-meta -->
</div>
<!-- #post-1032352 -->

<div class="loop-item-25 user-id-2480 bbp-parent-forum-3654 bbp-parent-topic-1032298 bbp-reply-position-42 even topic-author  post-1032352 reply type-reply status-publish hentry">
	<div class="bbp-reply-author">

		
		<a href="/forums/profile/ikk/" title="View iKK&#039;s profile" class="bbp-author-link"><span class="bbp-author-avatar"></span><span class="bbp-author-name">iKK</span></a><div class="bbp-author-role">Participant</div>
		
		
	</div>
<!-- .bbp-reply-author -->

	<div class="bbp-reply-content">

		
		<p>My RuleORama-VC looks like this:</p>
<p>Additionally, I<br>
&#8211; inserted the RuleORama-Framework<br>
&#8211; set Other Linker Flags to -ObjC<br>
&#8211; set the Bridging-Header Path correctly</p>
<p>Here is the Code:</p>
<pre><code>import UIKit

class ViewController: UIViewController, OEEventsObserverDelegate {
    
    var openEarsEventsObserver = OEEventsObserver()

    override func viewDidLoad() {
        super.viewDidLoad()
        // Do any additional setup after loading the view, typically from a nib.
        
        self.openEarsEventsObserver.delegate = self
        
        let lmGenerator = OELanguageModelGenerator()
        let accusticModelName = &quot;AcousticModelGerman&quot;
        let fileName = &quot;GermanModel&quot;
        
        let words = [&quot;esch do no frey&quot;]
        
        // let err: Error! = lmGenerator.generateLanguageModel(from: words, withFilesNamed: name, forAcousticModelAtPath: OEAcousticModel.path(toModel: accusticModelName))
        
        // let err: Error! = lmGenerator.generateGrammar(from: [OneOfTheseWillBeSaidOnce : words], withFilesNamed: fileName, forAcousticModelAtPath: OEAcousticModel.path(toModel: accusticModelName))
        
        let err: Error! = lmGenerator.generateFastGrammar(from: [OneOfTheseWillBeSaidOnce : words], withFilesNamed: fileName, forAcousticModelAtPath: OEAcousticModel.path(toModel: accusticModelName))
        
        var lmPath = &quot;&quot;
        var dictPath = &quot;&quot;
        
        if(err != nil) {
            print(&quot;Error while creating initial language model: \(err)&quot;)
        } else {
            lmPath = lmGenerator.pathToSuccessfullyGeneratedLanguageModel(withRequestedName: fileName)
            dictPath = lmGenerator.pathToSuccessfullyGeneratedDictionary(withRequestedName: fileName)
            lmPath = lmGenerator.pathToSuccessfullyGeneratedRuleORamaRuleset(withRequestedName: fileName)
        }
        
        // ************* Necessary for logging **************************
        OELogging.startOpenEarsLogging() //Uncomment to receive full OpenEars logging in case of any unexpected results.
        OEPocketsphinxController.sharedInstance().verbosePocketSphinx = true
        // ************* Necessary for logging **************************
        
        do {
            try OEPocketsphinxController.sharedInstance().setActive(true) // Setting the shared OEPocketsphinxController active is necessary before any of its properties are accessed.
        } catch {
            print(&quot;Error: it wasn&#039;t possible to set the shared instance to active: \&quot;\(error)\&quot;&quot;)
        }
        
        OEPocketsphinxController.sharedInstance().vadThreshold = 3.2;
    OEPocketsphinxController.sharedInstance().startListeningWithLanguageModel(atPath: lmPath, dictionaryAtPath: dictPath, acousticModelAtPath: OEAcousticModel.path(toModel: accusticModelName), languageModelIsJSGF: true)
    }

    override func didReceiveMemoryWarning() {
        super.didReceiveMemoryWarning()
        // Dispose of any resources that can be recreated.
    }
    
    func pocketsphinxDidReceiveHypothesis(_ hypothesis: String!, recognitionScore: String!, utteranceID: String!) { // Something was heard
        print(&quot;Local callback: The received hypothesis is \(hypothesis!) with a score of \(recognitionScore!) and an ID of \(utteranceID!)&quot;)
    }
    
    // An optional delegate method of OEEventsObserver which informs that the Pocketsphinx recognition loop has entered its actual loop.
    // This might be useful in debugging a conflict between another sound class and Pocketsphinx.
    func pocketsphinxRecognitionLoopDidStart() {
        print(&quot;Local callback: Pocketsphinx started.&quot;) // Log it.
    }
    
    // An optional delegate method of OEEventsObserver which informs that Pocketsphinx is now listening for speech.
    func pocketsphinxDidStartListening() {
        print(&quot;Local callback: Pocketsphinx is now listening.&quot;) // Log it.
    }
    
    // An optional delegate method of OEEventsObserver which informs that Pocketsphinx detected speech and is starting to process it.
    func pocketsphinxDidDetectSpeech() {
        print(&quot;Local callback: Pocketsphinx has detected speech.&quot;) // Log it.
    }
    
    // An optional delegate method of OEEventsObserver which informs that Pocketsphinx detected a second of silence, indicating the end of an utterance.
    func pocketsphinxDidDetectFinishedSpeech() {
        print(&quot;Local callback: Pocketsphinx has detected a second of silence, concluding an utterance.&quot;) // Log it.
    }
    
    // An optional delegate method of OEEventsObserver which informs that Pocketsphinx has exited its recognition loop, most
    // likely in response to the OEPocketsphinxController being told to stop listening via the stopListening method.
    func pocketsphinxDidStopListening() {
        print(&quot;Local callback: Pocketsphinx has stopped listening.&quot;) // Log it.
    }
    
    // An optional delegate method of OEEventsObserver which informs that Pocketsphinx is still in its listening loop but it is not
    // Going to react to speech until listening is resumed.  This can happen as a result of Flite speech being
    // in progress on an audio route that doesn&#039;t support simultaneous Flite speech and Pocketsphinx recognition,
    // or as a result of the OEPocketsphinxController being told to suspend recognition via the suspendRecognition method.
    func pocketsphinxDidSuspendRecognition() {
        print(&quot;Local callback: Pocketsphinx has suspended recognition.&quot;) // Log it.
    }
    
    // An optional delegate method of OEEventsObserver which informs that Pocketsphinx is still in its listening loop and after recognition
    // having been suspended it is now resuming.  This can happen as a result of Flite speech completing
    // on an audio route that doesn&#039;t support simultaneous Flite speech and Pocketsphinx recognition,
    // or as a result of the OEPocketsphinxController being told to resume recognition via the resumeRecognition method.
    func pocketsphinxDidResumeRecognition() {
        print(&quot;Local callback: Pocketsphinx has resumed recognition.&quot;) // Log it.
    }
    
    // An optional delegate method which informs that Pocketsphinx switched over to a new language model at the given URL in the course of
    // recognition. This does not imply that it is a valid file or that recognition will be successful using the file.
    func pocketsphinxDidChangeLanguageModel(toFile newLanguageModelPathAsString: String!, andDictionary newDictionaryPathAsString: String!) {
        
        print(&quot;Local callback: Pocketsphinx is now using the following language model: \n\(newLanguageModelPathAsString!) and the following dictionary: \(newDictionaryPathAsString!)&quot;)
    }
    
    // An optional delegate method of OEEventsObserver which informs that Flite is speaking, most likely to be useful if debugging a
    // complex interaction between sound classes. You don&#039;t have to do anything yourself in order to prevent Pocketsphinx from listening to Flite talk and trying to recognize the speech.
    func fliteDidStartSpeaking() {
        print(&quot;Local callback: Flite has started speaking&quot;) // Log it.
    }
    
    // An optional delegate method of OEEventsObserver which informs that Flite is finished speaking, most likely to be useful if debugging a
    // complex interaction between sound classes.
    func fliteDidFinishSpeaking() {
        print(&quot;Local callback: Flite has finished speaking&quot;) // Log it.
    }
    
    func pocketSphinxContinuousSetupDidFail(withReason reasonForFailure: String!) { // This can let you know that something went wrong with the recognition loop startup. Turn on [OELogging startOpenEarsLogging] to learn why.
        print(&quot;Local callback: Setting up the continuous recognition loop has failed for the reason \(reasonForFailure), please turn on OELogging.startOpenEarsLogging() to learn more.&quot;) // Log it.
    }
    
    func pocketSphinxContinuousTeardownDidFail(withReason reasonForFailure: String!) { // This can let you know that something went wrong with the recognition loop startup. Turn on OELogging.startOpenEarsLogging() to learn why.
        print(&quot;Local callback: Tearing down the continuous recognition loop has failed for the reason \(reasonForFailure)&quot;) // Log it.
    }
    
    /** Pocketsphinx couldn&#039;t start because it has no mic permissions (will only be returned on iOS7 or later).*/
    func pocketsphinxFailedNoMicPermissions() {
        print(&quot;Local callback: The user has never set mic permissions or denied permission to this app&#039;s mic, so listening will not start.&quot;)
    }
    
    /** The user prompt to get mic permissions, or a check of the mic permissions, has completed with a true or a false result  (will only be returned on iOS7 or later).*/
    
    func micPermissionCheckCompleted(withResult: Bool) {
        print(&quot;Local callback: mic check completed.&quot;)
    }
}</code></pre>

		
	</div>
<!-- .bbp-reply-content -->
</div>
<!-- .reply -->

			
				
<div id="post-1032351" class="bbp-reply-header">
	<div class="bbp-meta">
		<span class="bbp-reply-post-date">April 23, 2018 at 1:11 pm</span>

		
			<span class="bbp-header">
				in reply to: 				<a class="bbp-topic-permalink" href="/forums/topic/recognize-short-command-in-nonenglish/">Recognize short Command in nonEnglish</a>
			</span>

		
		<a href="/forums/topic/recognize-short-command-in-nonenglish/#post-1032351" class="bbp-reply-permalink">#1032351</a>

		
		<span class="bbp-admin-links"></span>
		
	</div>
<!-- .bbp-meta -->
</div>
<!-- #post-1032351 -->

<div class="loop-item-26 user-id-2480 bbp-parent-forum-3654 bbp-parent-topic-1032298 bbp-reply-position-41 odd topic-author  post-1032351 reply type-reply status-publish hentry">
	<div class="bbp-reply-author">

		
		<a href="/forums/profile/ikk/" title="View iKK&#039;s profile" class="bbp-author-link"><span class="bbp-author-avatar"></span><span class="bbp-author-name">iKK</span></a><div class="bbp-author-role">Participant</div>
		
		
	</div>
<!-- .bbp-reply-author -->

	<div class="bbp-reply-content">

		
		<p>With RuleORama, I end up with the following error (see log below). Can you please tell me what is still wrong ? And also, how does the words-array now need to look like. It seems that RuleORama wants a different one ???</p>
<p>Here is the RuleORama-log: (..still not sure if I translated all ObjC-Code from the manual correctly to Swift)&#8230;.</p>
<pre><code>2018-04-23 14:08:20.169350+0300 TestOpenEars[4109:2062039] Error: Error Domain=com.politepix.openears Code=6000 &quot;Language model has no content.&quot; UserInfo={NSLocalizedDescription=Language model has no content.}
2018-04-23 14:08:20.170097+0300 TestOpenEars[4109:2062039] It wasn&#039;t possible to create this grammar: {
    OneOfTheseWillBeSaidOnce =     (
        &quot;esch do no frey&quot;
    );
}
Error while creating initial language model: Optional(Error Domain=LanguageModelErrorDomain Code=10040 &quot;It wasn&#039;t possible to generate a grammar for this dictionary, please turn on OELogging for more information&quot; UserInfo={NSLocalizedDescription=It wasn&#039;t possible to generate a grammar for this dictionary, please turn on OELogging for more information})
2018-04-23 14:08:20.170989+0300 TestOpenEars[4109:2062039] Starting OpenEars logging for OpenEars version 2.506 on 64-bit device (or build): iPhone running iOS version: 11.300000
2018-04-23 14:08:20.171130+0300 TestOpenEars[4109:2062039] Creating shared instance of OEPocketsphinxController
2018-04-23 14:08:20.177706+0300 TestOpenEars[4109:2062039] Attempting to start listening session from startListeningWithLanguageModelAtPath:
2018-04-23 14:08:20.177741+0300 TestOpenEars[4109:2062039] Error: you have invoked the method:

startListeningWithLanguageModelAtPath:(NSString *)languageModelPath dictionaryAtPath:(NSString *)dictionaryPath acousticModelAtPath:(NSString *)acousticModelPath languageModelIsJSGF:(BOOL)languageModelIsJSGF

with a languageModelPath which is nil. If your call to OELanguageModelGenerator did not return an error when you generated this grammar, that means the correct path to your grammar that you should pass to this method&#039;s languageModelPath argument is as follows:

NSString *correctPathToMyLanguageModelFile = [myLanguageModelGenerator pathToSuccessfullyGeneratedGrammarWithRequestedName:@&quot;TheNameIChoseForMyVocabulary&quot;];

Feel free to copy and paste this code for your path to your grammar, but remember to replace the part that says &quot;TheNameIChoseForMyVocabulary&quot; with the name you actually chose for your grammar or you will get this error again (and replace myLanguageModelGenerator with the name of your OELanguageModelGenerator instance). Since this file is required, expect an exception or undocumented behavior shortly.</code></pre>

		
	</div>
<!-- .bbp-reply-content -->
</div>
<!-- .reply -->

			
				
<div id="post-1032350" class="bbp-reply-header">
	<div class="bbp-meta">
		<span class="bbp-reply-post-date">April 23, 2018 at 12:52 pm</span>

		
			<span class="bbp-header">
				in reply to: 				<a class="bbp-topic-permalink" href="/forums/topic/recognize-short-command-in-nonenglish/">Recognize short Command in nonEnglish</a>
			</span>

		
		<a href="/forums/topic/recognize-short-command-in-nonenglish/#post-1032350" class="bbp-reply-permalink">#1032350</a>

		
		<span class="bbp-admin-links"></span>
		
	</div>
<!-- .bbp-meta -->
</div>
<!-- #post-1032350 -->

<div class="loop-item-27 user-id-2480 bbp-parent-forum-3654 bbp-parent-topic-1032298 bbp-reply-position-40 even topic-author  post-1032350 reply type-reply status-publish hentry">
	<div class="bbp-reply-author">

		
		<a href="/forums/profile/ikk/" title="View iKK&#039;s profile" class="bbp-author-link"><span class="bbp-author-avatar"></span><span class="bbp-author-name">iKK</span></a><div class="bbp-author-role">Participant</div>
		
		
	</div>
<!-- .bbp-reply-author -->

	<div class="bbp-reply-content">

		
		<p>Halle,<br>
 can we please continue with Rejecto. I relaize the RuleORama-demo is again not useful after download &#8211; and I feel that I loose trememdeous amount of time just to set up these demo-projects. Also, your manual contains ObjC-Code under the Swift3 chapter &#8211; which is not something pleasant either. Can you please provide me with a working RuleORama-demo (Swift4) or we continue with Rejecto. Let me know, ok?</p>

		
	</div>
<!-- .bbp-reply-content -->
</div>
<!-- .reply -->

			
				
<div id="post-1032348" class="bbp-reply-header">
	<div class="bbp-meta">
		<span class="bbp-reply-post-date">April 23, 2018 at 11:44 am</span>

		
			<span class="bbp-header">
				in reply to: 				<a class="bbp-topic-permalink" href="/forums/topic/recognize-short-command-in-nonenglish/">Recognize short Command in nonEnglish</a>
			</span>

		
		<a href="/forums/topic/recognize-short-command-in-nonenglish/#post-1032348" class="bbp-reply-permalink">#1032348</a>

		
		<span class="bbp-admin-links"></span>
		
	</div>
<!-- .bbp-meta -->
</div>
<!-- #post-1032348 -->

<div class="loop-item-28 user-id-2480 bbp-parent-forum-3654 bbp-parent-topic-1032298 bbp-reply-position-39 odd topic-author  post-1032348 reply type-reply status-publish hentry">
	<div class="bbp-reply-author">

		
		<a href="/forums/profile/ikk/" title="View iKK&#039;s profile" class="bbp-author-link"><span class="bbp-author-avatar"></span><span class="bbp-author-name">iKK</span></a><div class="bbp-author-role">Participant</div>
		
		
	</div>
<!-- .bbp-reply-author -->

	<div class="bbp-reply-content">

		
		<p>In principle, we can continue with RuleORama. However, since costs are three times as much, I would of course prefer Rejecto somewhat.</p>
<p>I propose, we make tests with both and decide then on the better outcome, ok? As long as I can test using a free testing license for both of the technologies, we can go ahead comparing.</p>
<p>I downloaded RuleORama test-version. Give me a moment to set it up, ok. After that we have both technologies to play with.</p>

		
	</div>
<!-- .bbp-reply-content -->
</div>
<!-- .reply -->

			
				
<div id="post-1032343" class="bbp-reply-header">
	<div class="bbp-meta">
		<span class="bbp-reply-post-date">April 19, 2018 at 8:35 pm</span>

		
			<span class="bbp-header">
				in reply to: 				<a class="bbp-topic-permalink" href="/forums/topic/recognize-short-command-in-nonenglish/">Recognize short Command in nonEnglish</a>
			</span>

		
		<a href="/forums/topic/recognize-short-command-in-nonenglish/#post-1032343" class="bbp-reply-permalink">#1032343</a>

		
		<span class="bbp-admin-links"></span>
		
	</div>
<!-- .bbp-meta -->
</div>
<!-- #post-1032343 -->

<div class="loop-item-29 user-id-2480 bbp-parent-forum-3654 bbp-parent-topic-1032298 bbp-reply-position-37 even topic-author  post-1032343 reply type-reply status-publish hentry">
	<div class="bbp-reply-author">

		
		<a href="/forums/profile/ikk/" title="View iKK&#039;s profile" class="bbp-author-link"><span class="bbp-author-avatar"></span><span class="bbp-author-name">iKK</span></a><div class="bbp-author-role">Participant</div>
		
		
	</div>
<!-- .bbp-reply-author -->

	<div class="bbp-reply-content">

		
		<p>Third: ViewController.swift with all the relevant “generation of my language model”</p>
<pre><code>//
//  ViewController.swift
//  TestOpenEars
//
//  Created by Stephan Korner on 13.04.18.
//  Copyright © 2018 Ideen Kaffee Korner. All rights reserved.
//

import UIKit

class ViewController: UIViewController, OEEventsObserverDelegate {
    
    var openEarsEventsObserver = OEEventsObserver()

    override func viewDidLoad() {
        super.viewDidLoad()
        // Do any additional setup after loading the view, typically from a nib.
        
        self.openEarsEventsObserver.delegate = self
        
        let lmGenerator = OELanguageModelGenerator()
        let accusticModelName = &quot;AcousticModelGerman&quot;
        let fileName = &quot;GermanModel&quot;
        
        let words = [&quot;esch do no frey&quot;]
        
        // let err: Error! = lmGenerator.generateLanguageModel(from: words, withFilesNamed: name, forAcousticModelAtPath: OEAcousticModel.path(toModel: accusticModelName))
        
        let err: Error! = lmGenerator.generateGrammar(from: [OneOfTheseWillBeSaidOnce : words], withFilesNamed: fileName, forAcousticModelAtPath: OEAcousticModel.path(toModel: accusticModelName))
        
        var lmPath = &quot;&quot;
        var dictPath = &quot;&quot;
        
        if(err != nil) {
            print(&quot;Error while creating initial language model: \(err)&quot;)
        } else {
            lmPath = lmGenerator.pathToSuccessfullyGeneratedLanguageModel(withRequestedName: fileName)
            dictPath = lmGenerator.pathToSuccessfullyGeneratedDictionary(withRequestedName: fileName)
            lmPath = lmGenerator.pathToSuccessfullyGeneratedGrammar(withRequestedName: fileName)
        }
        
        // ************* Necessary for logging **************************
        OELogging.startOpenEarsLogging() //Uncomment to receive full OpenEars logging in case of any unexpected results.
        OEPocketsphinxController.sharedInstance().verbosePocketSphinx = true
        // ************* Necessary for logging **************************
        
        do {
            try OEPocketsphinxController.sharedInstance().setActive(true) // Setting the shared OEPocketsphinxController active is necessary before any of its properties are accessed.
        } catch {
            print(&quot;Error: it wasn&#039;t possible to set the shared instance to active: \&quot;\(error)\&quot;&quot;)
        }
        
        OEPocketsphinxController.sharedInstance().vadThreshold = 3.2;
    OEPocketsphinxController.sharedInstance().startListeningWithLanguageModel(atPath: lmPath, dictionaryAtPath: dictPath, acousticModelAtPath: OEAcousticModel.path(toModel: accusticModelName), languageModelIsJSGF: true)
    }

    override func didReceiveMemoryWarning() {
        super.didReceiveMemoryWarning()
        // Dispose of any resources that can be recreated.
    }
    
    func pocketsphinxDidReceiveHypothesis(_ hypothesis: String!, recognitionScore: String!, utteranceID: String!) { // Something was heard
        print(&quot;Local callback: The received hypothesis is \(hypothesis!) with a score of \(recognitionScore!) and an ID of \(utteranceID!)&quot;)
    }
    
    // An optional delegate method of OEEventsObserver which informs that the Pocketsphinx recognition loop has entered its actual loop.
    // This might be useful in debugging a conflict between another sound class and Pocketsphinx.
    func pocketsphinxRecognitionLoopDidStart() {
        print(&quot;Local callback: Pocketsphinx started.&quot;) // Log it.
    }
    
    // An optional delegate method of OEEventsObserver which informs that Pocketsphinx is now listening for speech.
    func pocketsphinxDidStartListening() {
        print(&quot;Local callback: Pocketsphinx is now listening.&quot;) // Log it.
    }
    
    // An optional delegate method of OEEventsObserver which informs that Pocketsphinx detected speech and is starting to process it.
    func pocketsphinxDidDetectSpeech() {
        print(&quot;Local callback: Pocketsphinx has detected speech.&quot;) // Log it.
    }
    
    // An optional delegate method of OEEventsObserver which informs that Pocketsphinx detected a second of silence, indicating the end of an utterance.
    func pocketsphinxDidDetectFinishedSpeech() {
        print(&quot;Local callback: Pocketsphinx has detected a second of silence, concluding an utterance.&quot;) // Log it.
    }
    
    // An optional delegate method of OEEventsObserver which informs that Pocketsphinx has exited its recognition loop, most
    // likely in response to the OEPocketsphinxController being told to stop listening via the stopListening method.
    func pocketsphinxDidStopListening() {
        print(&quot;Local callback: Pocketsphinx has stopped listening.&quot;) // Log it.
    }
    
    // An optional delegate method of OEEventsObserver which informs that Pocketsphinx is still in its listening loop but it is not
    // Going to react to speech until listening is resumed.  This can happen as a result of Flite speech being
    // in progress on an audio route that doesn&#039;t support simultaneous Flite speech and Pocketsphinx recognition,
    // or as a result of the OEPocketsphinxController being told to suspend recognition via the suspendRecognition method.
    func pocketsphinxDidSuspendRecognition() {
        print(&quot;Local callback: Pocketsphinx has suspended recognition.&quot;) // Log it.
    }
    
    // An optional delegate method of OEEventsObserver which informs that Pocketsphinx is still in its listening loop and after recognition
    // having been suspended it is now resuming.  This can happen as a result of Flite speech completing
    // on an audio route that doesn&#039;t support simultaneous Flite speech and Pocketsphinx recognition,
    // or as a result of the OEPocketsphinxController being told to resume recognition via the resumeRecognition method.
    func pocketsphinxDidResumeRecognition() {
        print(&quot;Local callback: Pocketsphinx has resumed recognition.&quot;) // Log it.
    }
    
    // An optional delegate method which informs that Pocketsphinx switched over to a new language model at the given URL in the course of
    // recognition. This does not imply that it is a valid file or that recognition will be successful using the file.
    func pocketsphinxDidChangeLanguageModel(toFile newLanguageModelPathAsString: String!, andDictionary newDictionaryPathAsString: String!) {
        
        print(&quot;Local callback: Pocketsphinx is now using the following language model: \n\(newLanguageModelPathAsString!) and the following dictionary: \(newDictionaryPathAsString!)&quot;)
    }
    
    // An optional delegate method of OEEventsObserver which informs that Flite is speaking, most likely to be useful if debugging a
    // complex interaction between sound classes. You don&#039;t have to do anything yourself in order to prevent Pocketsphinx from listening to Flite talk and trying to recognize the speech.
    func fliteDidStartSpeaking() {
        print(&quot;Local callback: Flite has started speaking&quot;) // Log it.
    }
    
    // An optional delegate method of OEEventsObserver which informs that Flite is finished speaking, most likely to be useful if debugging a
    // complex interaction between sound classes.
    func fliteDidFinishSpeaking() {
        print(&quot;Local callback: Flite has finished speaking&quot;) // Log it.
    }
    
    func pocketSphinxContinuousSetupDidFail(withReason reasonForFailure: String!) { // This can let you know that something went wrong with the recognition loop startup. Turn on [OELogging startOpenEarsLogging] to learn why.
        print(&quot;Local callback: Setting up the continuous recognition loop has failed for the reason \(reasonForFailure), please turn on OELogging.startOpenEarsLogging() to learn more.&quot;) // Log it.
    }
    
    func pocketSphinxContinuousTeardownDidFail(withReason reasonForFailure: String!) { // This can let you know that something went wrong with the recognition loop startup. Turn on OELogging.startOpenEarsLogging() to learn why.
        print(&quot;Local callback: Tearing down the continuous recognition loop has failed for the reason \(reasonForFailure)&quot;) // Log it.
    }
    
    /** Pocketsphinx couldn&#039;t start because it has no mic permissions (will only be returned on iOS7 or later).*/
    func pocketsphinxFailedNoMicPermissions() {
        print(&quot;Local callback: The user has never set mic permissions or denied permission to this app&#039;s mic, so listening will not start.&quot;)
    }
    
    /** The user prompt to get mic permissions, or a check of the mic permissions, has completed with a true or a false result  (will only be returned on iOS7 or later).*/
    
    func micPermissionCheckCompleted(withResult: Bool) {
        print(&quot;Local callback: mic check completed.&quot;)
    }
}</code></pre>

		
	</div>
<!-- .bbp-reply-content -->
</div>
<!-- .reply -->

			
				
<div id="post-1032342" class="bbp-reply-header">
	<div class="bbp-meta">
		<span class="bbp-reply-post-date">April 19, 2018 at 8:34 pm</span>

		
			<span class="bbp-header">
				in reply to: 				<a class="bbp-topic-permalink" href="/forums/topic/recognize-short-command-in-nonenglish/">Recognize short Command in nonEnglish</a>
			</span>

		
		<a href="/forums/topic/recognize-short-command-in-nonenglish/#post-1032342" class="bbp-reply-permalink">#1032342</a>

		
		<span class="bbp-admin-links"></span>
		
	</div>
<!-- .bbp-meta -->
</div>
<!-- #post-1032342 -->

<div class="loop-item-30 user-id-2480 bbp-parent-forum-3654 bbp-parent-topic-1032298 bbp-reply-position-36 odd topic-author  post-1032342 reply type-reply status-publish hentry">
	<div class="bbp-reply-author">

		
		<a href="/forums/profile/ikk/" title="View iKK&#039;s profile" class="bbp-author-link"><span class="bbp-author-avatar"></span><span class="bbp-author-name">iKK</span></a><div class="bbp-author-role">Participant</div>
		
		
	</div>
<!-- .bbp-reply-author -->

	<div class="bbp-reply-content">

		
		<p>Second LOG: from incorrectly spoken but unfortunately still recognised sentences</p>
<pre><code>2018-04-19 14:02:29.024746+0200 TestOpenEars[1288:617841] Starting OpenEars logging for OpenEars version 2.506 on 64-bit device (or build): iPhone running iOS version: 11.300000
2018-04-19 14:02:29.025006+0200 TestOpenEars[1288:617841] Creating shared instance of OEPocketsphinxController
2018-04-19 14:02:29.034738+0200 TestOpenEars[1288:617841] Attempting to start listening session from startListeningWithLanguageModelAtPath:
2018-04-19 14:02:29.037920+0200 TestOpenEars[1288:617841] User gave mic permission for this app.
2018-04-19 14:02:29.038176+0200 TestOpenEars[1288:617841] setSecondsOfSilence wasn&#039;t set, using default of 0.700000.
2018-04-19 14:02:29.039275+0200 TestOpenEars[1288:617894] Starting listening.
2018-04-19 14:02:29.039506+0200 TestOpenEars[1288:617894] About to set up audio session
2018-04-19 14:02:29.210501+0200 TestOpenEars[1288:617894] Creating audio session with default settings.
2018-04-19 14:02:29.212404+0200 TestOpenEars[1288:617894] Done setting audio session category.
2018-04-19 14:02:29.220219+0200 TestOpenEars[1288:617901] Audio route has changed for the following reason:
2018-04-19 14:02:29.225080+0200 TestOpenEars[1288:617894] Done setting preferred sample rate to 16000.000000 – now the real sample rate is 48000.000000
2018-04-19 14:02:29.225185+0200 TestOpenEars[1288:617901] There was a category change. The new category is AVAudioSessionCategoryPlayAndRecord
2018-04-19 14:02:29.226309+0200 TestOpenEars[1288:617894] number of channels is already the preferred number of 1 so not setting it.
2018-04-19 14:02:29.228887+0200 TestOpenEars[1288:617901] This is not a case in which OpenEars notifies of a route change. At the close of this method, the new audio route will be &lt;Input route or routes: &quot;MicrophoneBuiltIn&quot;. Output route or routes: &quot;Speaker&quot;&gt;. The previous route b2018-04-19 14:02:29.239190+0200 TestOpenEars[1288:617894] Done setting session&#039;s preferred I/O buffer duration to 0.128000 – now the actual buffer duration is 0.085333
2018-04-19 14:02:29.279574+0200 TestOpenEars[1288:617894] Done setting up audio session
efore changing to this route was &quot;&lt;AVAudioSessionRouteDescription: 0x1c041e180,
inputs = (null);
outputs = (
    &quot;&lt;AVAudioSessionPortDescription: 0x1c041e110, type = Speaker; name = Speaker; UID = Speaker; selectedDataSource = (null)&gt;&quot;
)&gt;&quot;.
2018-04-19 14:02:29.282389+0200 TestOpenEars[1288:617894] About to set up audio IO unit in a session with a sample rate of 48000.000000, a channel number of 1 and a buffer duration of 0.085333.
2018-04-19 14:02:29.309608+0200 TestOpenEars[1288:617901] Audio route has changed for the following reason:
2018-04-19 14:02:29.310813+0200 TestOpenEars[1288:617901] There was a category change. The new category is AVAudioSessionCategoryPlayAndRecord
2018-04-19 14:02:29.315959+0200 TestOpenEars[1288:617901] This is not a case in which OpenEars notifies of a route change. At the close of this method, the new audio route will be &lt;Input route or routes: &quot;MicrophoneBuiltIn&quot;. Output route or routes: &quot;Speaker&quot;&gt;. The previous route before changing to this route was &quot;&lt;AVAudioSessionRouteDescription: 0x1c4219460,
inputs = (
    &quot;&lt;AVAudioSessionPortDescription: 0x1c42193a0, type = MicrophoneBuiltIn; name = iPhone Microphone; UID = Built-In Microphone; selectedDataSource = Bottom&gt;&quot;
);
outputs = (
    &quot;&lt;AVAudioSessionPortDescription: 0x1c4219510, type = Receiver; name = Receiver; UID = Built-In Receiver; selectedDataSource = (null)&gt;&quot;
)&gt;&quot;.
2018-04-19 14:02:29.341243+0200 TestOpenEars[1288:617894] Done setting up audio unit
2018-04-19 14:02:29.341311+0200 TestOpenEars[1288:617894] About to start audio IO unit
2018-04-19 14:02:29.560570+0200 TestOpenEars[1288:617894] Done starting audio unit
INFO: pocketsphinx.c(145): Parsed model-specific feature parameters from /var/containers/Bundle/Application/CE15AFDC-1F3A-4E6F-88A6-60733F226865/TestOpenEars.app/AcousticModelGerman.bundle/feat.params
Current configuration:
[NAME]			[DEFLT]		[VALUE]
-agc			none		none
-agcthresh		2.0		2.000000e+00
-allphone
-allphone_ci		no		no
-alpha			0.97		9.700000e-01
-ascale			20.0		2.000000e+01
-aw			1		1
-backtrace		no		no
-beam			1e-48		1.000000e-48
-bestpath		yes		yes
-bestpathlw		9.5		9.500000e+00
-ceplen			13		13
-cmn			current		current
-cmninit		8.0		30
-compallsen		no		no
-debug					0
-dict					/var/mobile/Containers/Data/Application/95C6D225-194A-49A4-907C-BB5A0B8A698B/Library/Caches/GermanModel.dic
-dictcase		no		no
-dither			no		no
-doublebw		no		no
-ds			1		1
-fdict					/var/containers/Bundle/Application/CE15AFDC-1F3A-4E6F-88A6-60733F226865/TestOpenEars.app/AcousticModelGerman.bundle/noisedict
-feat			1s_c_d_dd	1s_c_d_dd
-featparams				/var/containers/Bundle/Application/CE15AFDC-1F3A-4E6F-88A6-60733F226865/TestOpenEars.app/AcousticModelGerman.bundle/feat.params
-fillprob		1e-8		1.000000e-08
-frate			100		100
-fsg
-fsgusealtpron		yes		yes
-fsgusefiller		yes		yes
-fwdflat		yes		yes
-fwdflatbeam		1e-64		1.000000e-64
-fwdflatefwid		4		4
-fwdflatlw		8.5		8.500000e+00
-fwdflatsfwin		25		25
-fwdflatwbeam		7e-29		7.000000e-29
-fwdtree		yes		yes
-hmm					/var/containers/Bundle/Application/CE15AFDC-1F3A-4E6F-88A6-60733F226865/TestOpenEars.app/AcousticModelGerman.bundle
-input_endian		little		little
-jsgf					/var/mobile/Containers/Data/Application/95C6D225-194A-49A4-907C-BB5A0B8A698B/Library/Caches/GermanModel.gram
-keyphrase
-kws
-kws_delay		10		10
-kws_plp		1e-1		1.000000e-01
-kws_threshold		1		1.000000e+00
-latsize		5000		5000
-lda
-ldadim			0		0
-lifter			0		22
-lm
-lmctl
-lmname
-logbase		1.0001		1.000100e+00
-logfn
-logspec		no		no
-lowerf			133.33334	1.300000e+02
-lpbeam			1e-40		1.000000e-40
-lponlybeam		7e-29		7.000000e-29
-lw			6.5		1.000000e+00
-maxhmmpf		30000		30000
-maxwpf			-1		-1
-mdef					/var/containers/Bundle/Application/CE15AFDC-1F3A-4E6F-88A6-60733F226865/TestOpenEars.app/AcousticModelGerman.bundle/mdef
-mean					/var/containers/Bundle/Application/CE15AFDC-1F3A-4E6F-88A6-60733F226865/TestOpenEars.app/AcousticModelGerman.bundle/means
-mfclogdir
-min_endfr		0		0
-mixw					/var/containers/Bundle/Application/CE15AFDC-1F3A-4E6F-88A6-60733F226865/TestOpenEars.app/AcousticModelGerman.bundle/mixture_weights
-mixwfloor		0.0000001	1.000000e-07
-mllr
-mmap			yes		yes
-ncep			13		13
-nfft			512		512
-nfilt			40		25
-nwpen			1.0		1.000000e+00
-pbeam			1e-48		1.000000e-48
-pip			1.0		1.000000e+00
-pl_beam		1e-10		1.000000e-10
-pl_pbeam		1e-10		1.000000e-10
-pl_pip			1.0		1.000000e+00
-pl_weight		3.0		3.000000e+00
-pl_window		5		5
-rawlogdir
-remove_dc		no		no
-remove_noise		yes		yes
-remove_silence		yes		yes
-round_filters		yes		yes
-samprate		16000		1.600000e+04
-seed			-1		-1
-sendump
-senlogdir
-senmgau
-silprob		0.005		5.000000e-03
-smoothspec		no		no
-svspec
-tmat					/var/containers/Bundle/Application/CE15AFDC-1F3A-4E6F-88A6-60733F226865/TestOpenEars.app/AcousticModelGerman.bundle/transition_matrices
-tmatfloor		0.0001		1.000000e-04
-topn			4		4
-topn_beam		0		0
-toprule
-transform		legacy		dct
-unit_area		yes		yes
-upperf			6855.4976	6.800000e+03
-uw			1.0		1.000000e+00
-vad_postspeech		50		69
-vad_prespeech		20		10
-vad_startspeech	10		10
-vad_threshold		2.0		3.200000e+00
-var					/var/containers/Bundle/Application/CE15AFDC-1F3A-4E6F-88A6-60733F226865/TestOpenEars.app/AcousticModelGerman.bundle/variances
-varfloor		0.0001		1.000000e-04
-varnorm		no		no
-verbose		no		no
-warp_params
-warp_type		inverse_linear	inverse_linear
-wbeam			7e-29		7.000000e-29
-wip			0.65		6.500000e-01
-wlen			0.025625	2.562500e-02

INFO: feat.c(715): Initializing feature stream to type: &#039;1s_c_d_dd&#039;, ceplen=13, CMN=&#039;current&#039;, VARNORM=&#039;no&#039;, AGC=&#039;none&#039;
INFO: cmn.c(143): mean[0]= 12.00, mean[1..12]= 0.0
INFO: mdef.c(518): Reading model definition: /var/containers/Bundle/Application/CE15AFDC-1F3A-4E6F-88A6-60733F226865/TestOpenEars.app/AcousticModelGerman.bundle/mdef
INFO: bin_mdef.c(181): Allocating 53834 * 8 bytes (420 KiB) for CD tree
INFO: tmat.c(206): Reading HMM transition probability matrices: /var/containers/Bundle/Application/CE15AFDC-1F3A-4E6F-88A6-60733F226865/TestOpenEars.app/AcousticModelGerman.bundle/transition_matrices
INFO: acmod.c(117): Attempting to use PTM computation module
INFO: ms_gauden.c(198): Reading mixture gaussian parameter: /var/containers/Bundle/Application/CE15AFDC-1F3A-4E6F-88A6-60733F226865/TestOpenEars.app/AcousticModelGerman.bundle/means
INFO: ms_gauden.c(292): 2129 codebook, 1 feature, size:
INFO: ms_gauden.c(294):  32x39
INFO: ms_gauden.c(198): Reading mixture gaussian parameter: /var/containers/Bundle/Application/CE15AFDC-1F3A-4E6F-88A6-60733F226865/TestOpenEars.app/AcousticModelGerman.bundle/variances
INFO: ms_gauden.c(292): 2129 codebook, 1 feature, size:
INFO: ms_gauden.c(294):  32x39
INFO: ms_gauden.c(354): 7100 variance values floored
INFO: ptm_mgau.c(801): Number of codebooks exceeds 256: 2129
INFO: acmod.c(119): Attempting to use semi-continuous computation module
INFO: ms_gauden.c(198): Reading mixture gaussian parameter: /var/containers/Bundle/Application/CE15AFDC-1F3A-4E6F-88A6-60733F226865/TestOpenEars.app/AcousticModelGerman.bundle/means
INFO: ms_gauden.c(292): 2129 codebook, 1 feature, size:
INFO: ms_gauden.c(294):  32x39
INFO: ms_gauden.c(198): Reading mixture gaussian parameter: /var/containers/Bundle/Application/CE15AFDC-1F3A-4E6F-88A6-60733F226865/TestOpenEars.app/AcousticModelGerman.bundle/variances
INFO: ms_gauden.c(292): 2129 codebook, 1 feature, size:
INFO: ms_gauden.c(294):  32x39
INFO: ms_gauden.c(354): 7100 variance values floored
INFO: acmod.c(121): Falling back to general multi-stream GMM computation
INFO: ms_gauden.c(198): Reading mixture gaussian parameter: /var/containers/Bundle/Application/CE15AFDC-1F3A-4E6F-88A6-60733F226865/TestOpenEars.app/AcousticModelGerman.bundle/means
INFO: ms_gauden.c(292): 2129 codebook, 1 feature, size:
INFO: ms_gauden.c(294):  32x39
INFO: ms_gauden.c(198): Reading mixture gaussian parameter: /var/containers/Bundle/Application/CE15AFDC-1F3A-4E6F-88A6-60733F226865/TestOpenEars.app/AcousticModelGerman.bundle/variances
INFO: ms_gauden.c(292): 2129 codebook, 1 feature, size:
INFO: ms_gauden.c(294):  32x39
INFO: ms_gauden.c(354): 7100 variance values floored
INFO: ms_senone.c(149): Reading senone mixture weights: /var/containers/Bundle/Application/CE15AFDC-1F3A-4E6F-88A6-60733F226865/TestOpenEars.app/AcousticModelGerman.bundle/mixture_weights
INFO: ms_senone.c(200): Truncating senone logs3(pdf) values by 10 bits
INFO: ms_senone.c(207): Not transposing mixture weights in memory
INFO: ms_senone.c(268): Read mixture weights for 2129 senones: 1 features x 32 codewords
INFO: ms_senone.c(320): Mapping senones to individual codebooks
INFO: ms_mgau.c(141): The value of topn: 4
INFO: phone_loop_search.c(114): State beam -225 Phone exit beam -225 Insertion penalty 0
INFO: dict.c(320): Allocating 4104 * 32 bytes (128 KiB) for word entries
INFO: dict.c(333): Reading main dictionary: /var/mobile/Containers/Data/Application/95C6D225-194A-49A4-907C-BB5A0B8A698B/Library/Caches/GermanModel.dic
INFO: dict.c(213): Allocated 0 KiB for strings, 0 KiB for phones
INFO: dict.c(336): 4 words read
INFO: dict.c(358): Reading filler dictionary: /var/containers/Bundle/Application/CE15AFDC-1F3A-4E6F-88A6-60733F226865/TestOpenEars.app/AcousticModelGerman.bundle/noisedict
INFO: dict.c(213): Allocated 0 KiB for strings, 0 KiB for phones
INFO: dict.c(361): 4 words read
INFO: dict2pid.c(396): Building PID tables for dictionary
INFO: dict2pid.c(406): Allocating 43^3 * 2 bytes (155 KiB) for word-initial triphones
INFO: dict2pid.c(132): Allocated 44720 bytes (43 KiB) for word-final triphones
INFO: dict2pid.c(196): Allocated 44720 bytes (43 KiB) for single-phone word triphones
INFO: jsgf.c(691): Defined rule: &lt;GermanModel.g00000&gt;
INFO: jsgf.c(691): Defined rule: PUBLIC &lt;GermanModel.rule_0&gt;
INFO: fsg_model.c(215): Computing transitive closure for null transitions
INFO: fsg_model.c(277): 0 null transitions added
INFO: fsg_search.c(227): FSG(beam: -1080, pbeam: -1080, wbeam: -634; wip: -5, pip: 0)
INFO: fsg_model.c(428): Adding silence transitions for &lt;sil&gt; to FSG
INFO: fsg_model.c(448): Added 5 silence word transitions
INFO: fsg_model.c(428): Adding silence transitions for &lt;sil&gt; to FSG
INFO: fsg_model.c(448): Added 5 silence word transitions
INFO: fsg_search.c(173): Added 0 alternate word transitions
INFO: fsg_lextree.c(110): Allocated 440 bytes (0 KiB) for left and right context phones
INFO: fsg_lextree.c(256): 17 HMM nodes in lextree (11 leaves)
INFO: fsg_lextree.c(259): Allocated 2448 bytes (2 KiB) for all lextree nodes
INFO: fsg_lextree.c(262): Allocated 1584 bytes (1 KiB) for lextree leafnodes
2018-04-19 14:02:30.301919+0200 TestOpenEars[1288:617894] There is no CMN plist so we are using the fresh CMN value 30.000000.
2018-04-19 14:02:30.302332+0200 TestOpenEars[1288:617894] Listening.
2018-04-19 14:02:30.302757+0200 TestOpenEars[1288:617894] Project has these words or phrases in its dictionary:
do
esch
frey
no
2018-04-19 14:02:30.302834+0200 TestOpenEars[1288:617894] Recognition loop has started
2018-04-19 14:02:30.303171+0200 TestOpenEars[1288:617841] Successfully started listening session from startListeningWithLanguageModelAtPath:
Local callback: Pocketsphinx is now listening.
Local callback: Pocketsphinx started.
2018-04-19 14:02:31.613456+0200 TestOpenEars[1288:617893] Speech detected...
Local callback: Pocketsphinx has detected speech.
2018-04-19 14:02:33.406395+0200 TestOpenEars[1288:617893] End of speech detected...
Local callback: Pocketsphinx has detected a second of silence, concluding an utterance.
INFO: cmn_prior.c(131): cmn_prior_update: from &lt; 30.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00 &gt;
INFO: cmn_prior.c(149): cmn_prior_update: to   &lt; 68.49 12.84 -7.48  5.65 -7.95  0.96  3.01  0.51 -0.81 -2.76  1.39  0.98  0.65 &gt;
INFO: fsg_search.c(843): 182 frames, 1688 HMMs (9/fr), 4466 senones (24/fr), 548 history entries (3/fr)

2018-04-19 14:02:33.407798+0200 TestOpenEars[1288:617893] Pocketsphinx heard &quot;esch do no frey&quot; with a score of (0) and an utterance ID of 0.
Local callback: The received hypothesis is esch do no frey with a score of 0 and an ID of 0
2018-04-19 14:02:34.460784+0200 TestOpenEars[1288:617893] Speech detected...
Local callback: Pocketsphinx has detected speech.
2018-04-19 14:02:37.551469+0200 TestOpenEars[1288:617893] End of speech detected...
Local callback: Pocketsphinx has detected a second of silence, concluding an utterance.
INFO: cmn_prior.c(131): cmn_prior_update: from &lt; 68.49 12.84 -7.48  5.65 -7.95  0.96  3.01  0.51 -0.81 -2.76  1.39  0.98  0.65 &gt;
INFO: cmn_prior.c(149): cmn_prior_update: to   &lt; 65.39 12.19 -6.64  5.08 -6.56  1.94  4.53  3.21  0.22 -2.76  0.47  1.69  0.13 &gt;
INFO: fsg_search.c(843): 313 frames, 2582 HMMs (8/fr), 7405 senones (23/fr), 1016 history entries (3/fr)

2018-04-19 14:02:37.552776+0200 TestOpenEars[1288:617893] Pocketsphinx heard &quot;esch do no frey&quot; with a score of (0) and an utterance ID of 1.
Local callback: The received hypothesis is esch do no frey with a score of 0 and an ID of 1
2018-04-19 14:02:39.212310+0200 TestOpenEars[1288:617893] Speech detected...
Local callback: Pocketsphinx has detected speech.
2018-04-19 14:02:41.103734+0200 TestOpenEars[1288:617893] End of speech detected...
Local callback: Pocketsphinx has detected a second of silence, concluding an utterance.
INFO: cmn_prior.c(131): cmn_prior_update: from &lt; 65.39 12.19 -6.64  5.08 -6.56  1.94  4.53  3.21  0.22 -2.76  0.47  1.69  0.13 &gt;
INFO: cmn_prior.c(149): cmn_prior_update: to   &lt; 66.10 12.58 -6.59  5.23 -7.36  1.07  4.44  3.00 -0.00 -2.35  0.52  1.84  0.19 &gt;
INFO: fsg_search.c(843): 194 frames, 1744 HMMs (8/fr), 4751 senones (24/fr), 651 history entries (3/fr)

2018-04-19 14:02:41.107087+0200 TestOpenEars[1288:617893] Pocketsphinx heard &quot;esch do no frey&quot; with a score of (0) and an utterance ID of 2.
Local callback: The received hypothesis is esch do no frey with a score of 0 and an ID of 2
2018-04-19 14:02:42.661713+0200 TestOpenEars[1288:617893] Speech detected...
Local callback: Pocketsphinx has detected speech.
INFO: cmn_prior.c(99): cmn_prior_update: from &lt; 66.10 12.58 -6.59  5.23 -7.36  1.07  4.44  3.00 -0.00 -2.35  0.52  1.84  0.19 &gt;
INFO: cmn_prior.c(116): cmn_prior_update: to   &lt; 65.78 10.39 -5.22  5.76 -7.50  0.51  5.25  3.14  0.81 -2.29  0.88  1.77  0.13 &gt;
2018-04-19 14:02:44.537660+0200 TestOpenEars[1288:617893] End of speech detected...
Local callback: Pocketsphinx has detected a second of silence, concluding an utterance.
INFO: cmn_prior.c(131): cmn_prior_update: from &lt; 65.78 10.39 -5.22  5.76 -7.50  0.51  5.25  3.14  0.81 -2.29  0.88  1.77  0.13 &gt;
INFO: cmn_prior.c(149): cmn_prior_update: to   &lt; 64.89 13.06 -6.23  4.89 -7.26  1.55  3.95  2.92  0.58 -1.80  0.81  1.76  0.35 &gt;
INFO: fsg_search.c(843): 192 frames, 1711 HMMs (8/fr), 4736 senones (24/fr), 714 history entries (3/fr)

2018-04-19 14:02:44.538437+0200 TestOpenEars[1288:617893] Pocketsphinx heard &quot;esch do no frey&quot; with a score of (0) and an utterance ID of 3.
Local callback: The received hypothesis is esch do no frey with a score of 0 and an ID of 3
2018-04-19 14:02:46.248629+0200 TestOpenEars[1288:617893] Speech detected...
Local callback: Pocketsphinx has detected speech.
INFO: cmn_prior.c(99): cmn_prior_update: from &lt; 64.89 13.06 -6.23  4.89 -7.26  1.55  3.95  2.92  0.58 -1.80  0.81  1.76  0.35 &gt;
INFO: cmn_prior.c(116): cmn_prior_update: to   &lt; 66.86 12.04 -7.14  5.36 -7.09  1.47  3.59  3.22  0.66 -1.95  0.66  1.82  0.27 &gt;
2018-04-19 14:02:48.643337+0200 TestOpenEars[1288:617893] End of speech detected...
Local callback: Pocketsphinx has detected a second of silence, concluding an utterance.
INFO: cmn_prior.c(131): cmn_prior_update: from &lt; 66.86 12.04 -7.14  5.36 -7.09  1.47  3.59  3.22  0.66 -1.95  0.66  1.82  0.27 &gt;
INFO: cmn_prior.c(149): cmn_prior_update: to   &lt; 65.41 13.10 -8.44  4.59 -6.98  2.08  2.77  3.03  0.47 -1.86  0.45  1.39 -0.09 &gt;
INFO: fsg_search.c(843): 248 frames, 2202 HMMs (8/fr), 6079 senones (24/fr), 843 history entries (3/fr)

2018-04-19 14:02:48.645033+0200 TestOpenEars[1288:617893] Pocketsphinx heard &quot;esch do no frey&quot; with a score of (0) and an utterance ID of 4.
Local callback: The received hypothesis is esch do no frey with a score of 0 and an ID of 4</code></pre>

		
	</div>
<!-- .bbp-reply-content -->
</div>
<!-- .reply -->

			
				
<div id="post-1032341" class="bbp-reply-header">
	<div class="bbp-meta">
		<span class="bbp-reply-post-date">April 19, 2018 at 8:33 pm</span>

		
			<span class="bbp-header">
				in reply to: 				<a class="bbp-topic-permalink" href="/forums/topic/recognize-short-command-in-nonenglish/">Recognize short Command in nonEnglish</a>
			</span>

		
		<a href="/forums/topic/recognize-short-command-in-nonenglish/#post-1032341" class="bbp-reply-permalink">#1032341</a>

		
		<span class="bbp-admin-links"></span>
		
	</div>
<!-- .bbp-meta -->
</div>
<!-- #post-1032341 -->

<div class="loop-item-31 user-id-2480 bbp-parent-forum-3654 bbp-parent-topic-1032298 bbp-reply-position-35 even topic-author  post-1032341 reply type-reply status-publish hentry">
	<div class="bbp-reply-author">

		
		<a href="/forums/profile/ikk/" title="View iKK&#039;s profile" class="bbp-author-link"><span class="bbp-author-avatar"></span><span class="bbp-author-name">iKK</span></a><div class="bbp-author-role">Participant</div>
		
		
	</div>
<!-- .bbp-reply-author -->

	<div class="bbp-reply-content">

		
		<p>The repo is closed for licensing purposes.</p>
<p>Here are the two LOGs and ViewController.swift File</p>
<p>(please refer to the two next posts since I want to separate the LOGs from each other&#8230;)</p>
<p>First LOG: &#8220;5 times correctly spoken sentence&#8221;</p>
<pre><code>2018-04-19 13:59:28.021225+0200 TestOpenEars[1285:616560] Starting OpenEars logging for OpenEars version 2.506 on 64-bit device (or build): iPhone running iOS version: 11.300000
2018-04-19 13:59:28.021943+0200 TestOpenEars[1285:616560] Creating shared instance of OEPocketsphinxController
2018-04-19 13:59:28.033404+0200 TestOpenEars[1285:616560] Attempting to start listening session from startListeningWithLanguageModelAtPath:
2018-04-19 13:59:28.040833+0200 TestOpenEars[1285:616560] User gave mic permission for this app.
2018-04-19 13:59:28.041866+0200 TestOpenEars[1285:616560] setSecondsOfSilence wasn&#039;t set, using default of 0.700000.
2018-04-19 13:59:28.042950+0200 TestOpenEars[1285:616676] Starting listening.
2018-04-19 13:59:28.043052+0200 TestOpenEars[1285:616676] About to set up audio session
2018-04-19 13:59:28.211559+0200 TestOpenEars[1285:616676] Creating audio session with default settings.
2018-04-19 13:59:28.211630+0200 TestOpenEars[1285:616676] Done setting audio session category.
2018-04-19 13:59:28.218468+0200 TestOpenEars[1285:616676] Done setting preferred sample rate to 16000.000000 – now the real sample rate is 48000.000000
2018-04-19 13:59:28.221402+0200 TestOpenEars[1285:616676] number of channels is already the preferred number of 1 so not setting it.
2018-04-19 13:59:28.226764+0200 TestOpenEars[1285:616676] Done setting session&#039;s preferred I/O buffer duration to 0.128000 – now the actual buffer duration is 0.085333
2018-04-19 13:59:28.226817+0200 TestOpenEars[1285:616676] Done setting up audio session
2018-04-19 13:59:28.227373+0200 TestOpenEars[1285:616685] Audio route has changed for the following reason:
2018-04-19 13:59:28.231358+0200 TestOpenEars[1285:616676] About to set up audio IO unit in a session with a sample rate of 48000.000000, a channel number of 1 and a buffer duration of 0.085333.
2018-04-19 13:59:28.231418+0200 TestOpenEars[1285:616685] There was a category change. The new category is AVAudioSessionCategoryPlayAndRecord
2018-04-19 13:59:28.337755+0200 TestOpenEars[1285:616685] This is not a case in which OpenEars notifies of a route change. At the close of this method, the new audio route will be &lt;Input route or routes: &quot;MicrophoneBuiltIn&quot;. Output route or routes: &quot;Speaker&quot;&gt;. The previous route before changing to this route was &quot;&lt;AVAudioSessionRouteDescription: 0x1c46028e0,
inputs = (null);
outputs = (
    &quot;&lt;AVAudioSessionPortDescription: 0x1c4602890, type = Speaker; name = Speaker; UID = Speaker; selectedDataSource = (null)&gt;&quot;
)&gt;&quot;.
2018-04-19 13:59:28.352755+0200 TestOpenEars[1285:616685] Audio route has changed for the following reason:
2018-04-19 13:59:28.354261+0200 TestOpenEars[1285:616685] There was a category change. The new category is AVAudioSessionCategoryPlayAndRecord
2018-04-19 13:59:28.359673+0200 TestOpenEars[1285:616676] Done setting up audio unit
2018-04-19 13:59:28.359731+0200 TestOpenEars[1285:616676] About to start audio IO unit
2018-04-19 13:59:28.365514+0200 TestOpenEars[1285:616685] This is not a case in which OpenEars notifies of a route change. At the close of this method, the new audio route will be &lt;Input route or routes: &quot;MicrophoneBuiltIn&quot;. Output route or routes: &quot;Speaker&quot;&gt;. The previous route before changing to this route was &quot;&lt;AVAudioSessionRouteDescription: 0x1c46028e0,
inputs = (
    &quot;&lt;AVAudioSessionPortDescription: 0x1c46028b0, type = MicrophoneBuiltIn; name = iPhone Microphone; UID = Built-In Microphone; selectedDataSource = Bottom&gt;&quot;
);
outputs = (
    &quot;&lt;AVAudioSessionPortDescription: 0x1c4602a30, type = Receiver; name = Receiver; UID = Built-In Receiver; selectedDataSource = (null)&gt;&quot;
)&gt;&quot;.
2018-04-19 13:59:28.589286+0200 TestOpenEars[1285:616676] Done starting audio unit
INFO: pocketsphinx.c(145): Parsed model-specific feature parameters from /var/containers/Bundle/Application/AF8A9931-95D6-4EED-93E3-6858584A31C9/TestOpenEars.app/AcousticModelGerman.bundle/feat.params
Current configuration:
[NAME]			[DEFLT]		[VALUE]
-agc			none		none
-agcthresh		2.0		2.000000e+00
-allphone
-allphone_ci		no		no
-alpha			0.97		9.700000e-01
-ascale			20.0		2.000000e+01
-aw			1		1
-backtrace		no		no
-beam			1e-48		1.000000e-48
-bestpath		yes		yes
-bestpathlw		9.5		9.500000e+00
-ceplen			13		13
-cmn			current		current
-cmninit		8.0		30
-compallsen		no		no
-debug					0
-dict					/var/mobile/Containers/Data/Application/3C7F2CAB-D0E4-4ABF-81DE-9DD3AF3B7BEC/Library/Caches/GermanModel.dic
-dictcase		no		no
-dither			no		no
-doublebw		no		no
-ds			1		1
-fdict					/var/containers/Bundle/Application/AF8A9931-95D6-4EED-93E3-6858584A31C9/TestOpenEars.app/AcousticModelGerman.bundle/noisedict
-feat			1s_c_d_dd	1s_c_d_dd
-featparams				/var/containers/Bundle/Application/AF8A9931-95D6-4EED-93E3-6858584A31C9/TestOpenEars.app/AcousticModelGerman.bundle/feat.params
-fillprob		1e-8		1.000000e-08
-frate			100		100
-fsg
-fsgusealtpron		yes		yes
-fsgusefiller		yes		yes
-fwdflat		yes		yes
-fwdflatbeam		1e-64		1.000000e-64
-fwdflatefwid		4		4
-fwdflatlw		8.5		8.500000e+00
-fwdflatsfwin		25		25
-fwdflatwbeam		7e-29		7.000000e-29
-fwdtree		yes		yes
-hmm					/var/containers/Bundle/Application/AF8A9931-95D6-4EED-93E3-6858584A31C9/TestOpenEars.app/AcousticModelGerman.bundle
-input_endian		little		little
-jsgf					/var/mobile/Containers/Data/Application/3C7F2CAB-D0E4-4ABF-81DE-9DD3AF3B7BEC/Library/Caches/GermanModel.gram
-keyphrase
-kws
-kws_delay		10		10
-kws_plp		1e-1		1.000000e-01
-kws_threshold		1		1.000000e+00
-latsize		5000		5000
-lda
-ldadim			0		0
-lifter			0		22
-lm
-lmctl
-lmname
-logbase		1.0001		1.000100e+00
-logfn
-logspec		no		no
-lowerf			133.33334	1.300000e+02
-lpbeam			1e-40		1.000000e-40
-lponlybeam		7e-29		7.000000e-29
-lw			6.5		1.000000e+00
-maxhmmpf		30000		30000
-maxwpf			-1		-1
-mdef					/var/containers/Bundle/Application/AF8A9931-95D6-4EED-93E3-6858584A31C9/TestOpenEars.app/AcousticModelGerman.bundle/mdef
-mean					/var/containers/Bundle/Application/AF8A9931-95D6-4EED-93E3-6858584A31C9/TestOpenEars.app/AcousticModelGerman.bundle/means
-mfclogdir
-min_endfr		0		0
-mixw					/var/containers/Bundle/Application/AF8A9931-95D6-4EED-93E3-6858584A31C9/TestOpenEars.app/AcousticModelGerman.bundle/mixture_weights
-mixwfloor		0.0000001	1.000000e-07
-mllr
-mmap			yes		yes
-ncep			13		13
-nfft			512		512
-nfilt			40		25
-nwpen			1.0		1.000000e+00
-pbeam			1e-48		1.000000e-48
-pip			1.0		1.000000e+00
-pl_beam		1e-10		1.000000e-10
-pl_pbeam		1e-10		1.000000e-10
-pl_pip			1.0		1.000000e+00
-pl_weight		3.0		3.000000e+00
-pl_window		5		5
-rawlogdir
-remove_dc		no		no
-remove_noise		yes		yes
-remove_silence		yes		yes
-round_filters		yes		yes
-samprate		16000		1.600000e+04
-seed			-1		-1
-sendump
-senlogdir
-senmgau
-silprob		0.005		5.000000e-03
-smoothspec		no		no
-svspec
-tmat					/var/containers/Bundle/Application/AF8A9931-95D6-4EED-93E3-6858584A31C9/TestOpenEars.app/AcousticModelGerman.bundle/transition_matrices
-tmatfloor		0.0001		1.000000e-04
-topn			4		4
-topn_beam		0		0
-toprule
-transform		legacy		dct
-unit_area		yes		yes
-upperf			6855.4976	6.800000e+03
-uw			1.0		1.000000e+00
-vad_postspeech		50		69
-vad_prespeech		20		10
-vad_startspeech	10		10
-vad_threshold		2.0		3.200000e+00
-var					/var/containers/Bundle/Application/AF8A9931-95D6-4EED-93E3-6858584A31C9/TestOpenEars.app/AcousticModelGerman.bundle/variances
-varfloor		0.0001		1.000000e-04
-varnorm		no		no
-verbose		no		no
-warp_params
-warp_type		inverse_linear	inverse_linear
-wbeam			7e-29		7.000000e-29
-wip			0.65		6.500000e-01
-wlen			0.025625	2.562500e-02

INFO: feat.c(715): Initializing feature stream to type: &#039;1s_c_d_dd&#039;, ceplen=13, CMN=&#039;current&#039;, VARNORM=&#039;no&#039;, AGC=&#039;none&#039;
INFO: cmn.c(143): mean[0]= 12.00, mean[1..12]= 0.0
INFO: mdef.c(518): Reading model definition: /var/containers/Bundle/Application/AF8A9931-95D6-4EED-93E3-6858584A31C9/TestOpenEars.app/AcousticModelGerman.bundle/mdef
INFO: bin_mdef.c(181): Allocating 53834 * 8 bytes (420 KiB) for CD tree
INFO: tmat.c(206): Reading HMM transition probability matrices: /var/containers/Bundle/Application/AF8A9931-95D6-4EED-93E3-6858584A31C9/TestOpenEars.app/AcousticModelGerman.bundle/transition_matrices
INFO: acmod.c(117): Attempting to use PTM computation module
INFO: ms_gauden.c(198): Reading mixture gaussian parameter: /var/containers/Bundle/Application/AF8A9931-95D6-4EED-93E3-6858584A31C9/TestOpenEars.app/AcousticModelGerman.bundle/means
INFO: ms_gauden.c(292): 2129 codebook, 1 feature, size:
INFO: ms_gauden.c(294):  32x39
INFO: ms_gauden.c(198): Reading mixture gaussian parameter: /var/containers/Bundle/Application/AF8A9931-95D6-4EED-93E3-6858584A31C9/TestOpenEars.app/AcousticModelGerman.bundle/variances
INFO: ms_gauden.c(292): 2129 codebook, 1 feature, size:
INFO: ms_gauden.c(294):  32x39
INFO: ms_gauden.c(354): 7100 variance values floored
INFO: ptm_mgau.c(801): Number of codebooks exceeds 256: 2129
INFO: acmod.c(119): Attempting to use semi-continuous computation module
INFO: ms_gauden.c(198): Reading mixture gaussian parameter: /var/containers/Bundle/Application/AF8A9931-95D6-4EED-93E3-6858584A31C9/TestOpenEars.app/AcousticModelGerman.bundle/means
INFO: ms_gauden.c(292): 2129 codebook, 1 feature, size:
INFO: ms_gauden.c(294):  32x39
INFO: ms_gauden.c(198): Reading mixture gaussian parameter: /var/containers/Bundle/Application/AF8A9931-95D6-4EED-93E3-6858584A31C9/TestOpenEars.app/AcousticModelGerman.bundle/variances
INFO: ms_gauden.c(292): 2129 codebook, 1 feature, size:
INFO: ms_gauden.c(294):  32x39
INFO: ms_gauden.c(354): 7100 variance values floored
INFO: acmod.c(121): Falling back to general multi-stream GMM computation
INFO: ms_gauden.c(198): Reading mixture gaussian parameter: /var/containers/Bundle/Application/AF8A9931-95D6-4EED-93E3-6858584A31C9/TestOpenEars.app/AcousticModelGerman.bundle/means
INFO: ms_gauden.c(292): 2129 codebook, 1 feature, size:
INFO: ms_gauden.c(294):  32x39
INFO: ms_gauden.c(198): Reading mixture gaussian parameter: /var/containers/Bundle/Application/AF8A9931-95D6-4EED-93E3-6858584A31C9/TestOpenEars.app/AcousticModelGerman.bundle/variances
INFO: ms_gauden.c(292): 2129 codebook, 1 feature, size:
INFO: ms_gauden.c(294):  32x39
INFO: ms_gauden.c(354): 7100 variance values floored
INFO: ms_senone.c(149): Reading senone mixture weights: /var/containers/Bundle/Application/AF8A9931-95D6-4EED-93E3-6858584A31C9/TestOpenEars.app/AcousticModelGerman.bundle/mixture_weights
INFO: ms_senone.c(200): Truncating senone logs3(pdf) values by 10 bits
INFO: ms_senone.c(207): Not transposing mixture weights in memory
INFO: ms_senone.c(268): Read mixture weights for 2129 senones: 1 features x 32 codewords
INFO: ms_senone.c(320): Mapping senones to individual codebooks
INFO: ms_mgau.c(141): The value of topn: 4
INFO: phone_loop_search.c(114): State beam -225 Phone exit beam -225 Insertion penalty 0
INFO: dict.c(320): Allocating 4104 * 32 bytes (128 KiB) for word entries
INFO: dict.c(333): Reading main dictionary: /var/mobile/Containers/Data/Application/3C7F2CAB-D0E4-4ABF-81DE-9DD3AF3B7BEC/Library/Caches/GermanModel.dic
INFO: dict.c(213): Allocated 0 KiB for strings, 0 KiB for phones
INFO: dict.c(336): 4 words read
INFO: dict.c(358): Reading filler dictionary: /var/containers/Bundle/Application/AF8A9931-95D6-4EED-93E3-6858584A31C9/TestOpenEars.app/AcousticModelGerman.bundle/noisedict
INFO: dict.c(213): Allocated 0 KiB for strings, 0 KiB for phones
INFO: dict.c(361): 4 words read
INFO: dict2pid.c(396): Building PID tables for dictionary
INFO: dict2pid.c(406): Allocating 43^3 * 2 bytes (155 KiB) for word-initial triphones
INFO: dict2pid.c(132): Allocated 44720 bytes (43 KiB) for word-final triphones
INFO: dict2pid.c(196): Allocated 44720 bytes (43 KiB) for single-phone word triphones
INFO: jsgf.c(691): Defined rule: &lt;GermanModel.g00000&gt;
INFO: jsgf.c(691): Defined rule: PUBLIC &lt;GermanModel.rule_0&gt;
INFO: fsg_model.c(215): Computing transitive closure for null transitions
INFO: fsg_model.c(277): 0 null transitions added
INFO: fsg_search.c(227): FSG(beam: -1080, pbeam: -1080, wbeam: -634; wip: -5, pip: 0)
INFO: fsg_model.c(428): Adding silence transitions for &lt;sil&gt; to FSG
INFO: fsg_model.c(448): Added 5 silence word transitions
INFO: fsg_model.c(428): Adding silence transitions for &lt;sil&gt; to FSG
INFO: fsg_model.c(448): Added 5 silence word transitions
INFO: fsg_search.c(173): Added 0 alternate word transitions
INFO: fsg_lextree.c(110): Allocated 440 bytes (0 KiB) for left and right context phones
INFO: fsg_lextree.c(256): 17 HMM nodes in lextree (11 leaves)
INFO: fsg_lextree.c(259): Allocated 2448 bytes (2 KiB) for all lextree nodes
INFO: fsg_lextree.c(262): Allocated 1584 bytes (1 KiB) for lextree leafnodes
2018-04-19 13:59:29.327456+0200 TestOpenEars[1285:616676] There is no CMN plist so we are using the fresh CMN value 30.000000.
2018-04-19 13:59:29.327909+0200 TestOpenEars[1285:616676] Listening.
2018-04-19 13:59:29.328299+0200 TestOpenEars[1285:616676] Project has these words or phrases in its dictionary:
do
esch
frey
no
2018-04-19 13:59:29.328539+0200 TestOpenEars[1285:616676] Recognition loop has started
2018-04-19 13:59:29.329632+0200 TestOpenEars[1285:616560] Successfully started listening session from startListeningWithLanguageModelAtPath:
Local callback: Pocketsphinx is now listening.
Local callback: Pocketsphinx started.
2018-04-19 13:59:29.644460+0200 TestOpenEars[1285:616678] Speech detected...
Local callback: Pocketsphinx has detected speech.
2018-04-19 13:59:30.533009+0200 TestOpenEars[1285:616678] End of speech detected...
Local callback: Pocketsphinx has detected a second of silence, concluding an utterance.
INFO: cmn_prior.c(131): cmn_prior_update: from &lt; 30.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00 &gt;
INFO: cmn_prior.c(149): cmn_prior_update: to   &lt; 53.23  5.46 -14.11  7.15  0.86  4.65 -7.53  3.98  4.45 -3.50  0.60  0.63 -0.93 &gt;
INFO: fsg_search.c(843): 93 frames, 677 HMMs (7/fr), 1990 senones (21/fr), 269 history entries (2/fr)

ERROR: &quot;fsg_search.c&quot;, line 913: Final result does not match the grammar in frame 93
2018-04-19 13:59:30.534037+0200 TestOpenEars[1285:616678] Pocketsphinx heard &quot;&quot; with a score of (0) and an utterance ID of 0.
2018-04-19 13:59:30.534077+0200 TestOpenEars[1285:616678] Hypothesis was null so we aren&#039;t returning it. If you want null hypotheses to also be returned, set OEPocketsphinxController&#039;s property returnNullHypotheses to TRUE before starting OEPocketsphinxController.
2018-04-19 13:59:30.769463+0200 TestOpenEars[1285:616678] Speech detected...
Local callback: Pocketsphinx has detected speech.
2018-04-19 13:59:32.152342+0200 TestOpenEars[1285:616678] End of speech detected...
Local callback: Pocketsphinx has detected a second of silence, concluding an utterance.
INFO: cmn_prior.c(131): cmn_prior_update: from &lt; 53.23  5.46 -14.11  7.15  0.86  4.65 -7.53  3.98  4.45 -3.50  0.60  0.63 -0.93 &gt;
INFO: cmn_prior.c(149): cmn_prior_update: to   &lt; 61.11 10.12 -7.20 12.76 -3.42  1.16 -3.88  0.29  4.21 -6.41  3.58 -1.38  0.87 &gt;
INFO: fsg_search.c(843): 143 frames, 1069 HMMs (7/fr), 2736 senones (19/fr), 413 history entries (2/fr)

2018-04-19 13:59:32.155979+0200 TestOpenEars[1285:616678] Pocketsphinx heard &quot;esch do no frey&quot; with a score of (0) and an utterance ID of 1.
Local callback: The received hypothesis is esch do no frey with a score of 0 and an ID of 1
2018-04-19 13:59:32.720826+0200 TestOpenEars[1285:616678] Speech detected...
Local callback: Pocketsphinx has detected speech.
2018-04-19 13:59:34.634173+0200 TestOpenEars[1285:616678] End of speech detected...
Local callback: Pocketsphinx has detected a second of silence, concluding an utterance.
INFO: cmn_prior.c(131): cmn_prior_update: from &lt; 61.11 10.12 -7.20 12.76 -3.42  1.16 -3.88  0.29  4.21 -6.41  3.58 -1.38  0.87 &gt;
INFO: cmn_prior.c(149): cmn_prior_update: to   &lt; 58.26 10.58 -4.64  9.03 -2.89  2.28 -0.84  1.48  3.76 -4.75  1.97 -1.18  0.44 &gt;
INFO: fsg_search.c(843): 197 frames, 2927 HMMs (14/fr), 6548 senones (33/fr), 1064 history entries (5/fr)

2018-04-19 13:59:34.636558+0200 TestOpenEars[1285:616678] Pocketsphinx heard &quot;esch do no frey&quot; with a score of (0) and an utterance ID of 2.
Local callback: The received hypothesis is esch do no frey with a score of 0 and an ID of 2
2018-04-19 13:59:41.285796+0200 TestOpenEars[1285:616678] Speech detected...
Local callback: Pocketsphinx has detected speech.
2018-04-19 13:59:42.569498+0200 TestOpenEars[1285:616678] End of speech detected...
Local callback: Pocketsphinx has detected a second of silence, concluding an utterance.
INFO: cmn_prior.c(131): cmn_prior_update: from &lt; 58.26 10.58 -4.64  9.03 -2.89  2.28 -0.84  1.48  3.76 -4.75  1.97 -1.18  0.44 &gt;
INFO: cmn_prior.c(149): cmn_prior_update: to   &lt; 60.54 10.98 -4.75 10.87 -5.02  1.78  1.04 -0.71  3.55 -4.35  2.33 -0.95  0.28 &gt;
INFO: fsg_search.c(843): 141 frames, 981 HMMs (6/fr), 2593 senones (18/fr), 318 history entries (2/fr)

2018-04-19 13:59:42.570751+0200 TestOpenEars[1285:616678] Pocketsphinx heard &quot;esch do no frey&quot; with a score of (0) and an utterance ID of 3.
Local callback: The received hypothesis is esch do no frey with a score of 0 and an ID of 3
2018-04-19 13:59:46.632433+0200 TestOpenEars[1285:616678] Speech detected...
Local callback: Pocketsphinx has detected speech.
2018-04-19 13:59:48.331594+0200 TestOpenEars[1285:616678] End of speech detected...
Local callback: Pocketsphinx has detected a second of silence, concluding an utterance.
INFO: cmn_prior.c(131): cmn_prior_update: from &lt; 60.54 10.98 -4.75 10.87 -5.02  1.78  1.04 -0.71  3.55 -4.35  2.33 -0.95  0.28 &gt;
INFO: cmn_prior.c(149): cmn_prior_update: to   &lt; 62.08 12.85 -4.75 10.76 -6.66  2.06  1.72 -2.32  4.27 -4.30  2.86 -1.06  0.58 &gt;
INFO: fsg_search.c(843): 170 frames, 1109 HMMs (6/fr), 2679 senones (15/fr), 358 history entries (2/fr)

2018-04-19 13:59:48.334816+0200 TestOpenEars[1285:616678] Pocketsphinx heard &quot;esch do no frey&quot; with a score of (0) and an utterance ID of 4.
Local callback: The received hypothesis is esch do no frey with a score of 0 and an ID of 4
2018-04-19 13:59:50.847118+0200 TestOpenEars[1285:616678] Speech detected...
Local callback: Pocketsphinx has detected speech.
INFO: cmn_prior.c(99): cmn_prior_update: from &lt; 62.08 12.85 -4.75 10.76 -6.66  2.06  1.72 -2.32  4.27 -4.30  2.86 -1.06  0.58 &gt;
INFO: cmn_prior.c(116): cmn_prior_update: to   &lt; 62.62 11.77 -4.58 11.62 -7.05  2.15  2.23 -2.68  4.03 -4.19  3.05 -1.03  0.51 &gt;
2018-04-19 13:59:53.396359+0200 TestOpenEars[1285:616678] End of speech detected...
Local callback: Pocketsphinx has detected a second of silence, concluding an utterance.
INFO: cmn_prior.c(131): cmn_prior_update: from &lt; 62.62 11.77 -4.58 11.62 -7.05  2.15  2.23 -2.68  4.03 -4.19  3.05 -1.03  0.51 &gt;
INFO: cmn_prior.c(149): cmn_prior_update: to   &lt; 60.50 12.69 -5.29 11.47 -6.15  3.94  2.48 -2.55  3.25 -4.41  2.90 -1.68  0.59 &gt;
INFO: fsg_search.c(843): 256 frames, 1194 HMMs (4/fr), 2965 senones (11/fr), 435 history entries (1/fr)

2018-04-19 13:59:53.397731+0200 TestOpenEars[1285:616678] Pocketsphinx heard &quot;esch do no frey&quot; with a score of (0) and an utterance ID of 5.
Local callback: The received hypothesis is esch do no frey with a score of 0 and an ID of 5
2018-04-19 13:59:53.582752+0200 TestOpenEars[1285:616678] Speech detected...
Local callback: Pocketsphinx has detected speech.
2018-04-19 13:59:54.333555+0200 TestOpenEars[1285:616678] End of speech detected...
Local callback: Pocketsphinx has detected a second of silence, concluding an utterance.
INFO: cmn_prior.c(131): cmn_prior_update: from &lt; 60.50 12.69 -5.29 11.47 -6.15  3.94  2.48 -2.55  3.25 -4.41  2.90 -1.68  0.59 &gt;
INFO: cmn_prior.c(149): cmn_prior_update: to   &lt; 59.83 10.88 -5.47 11.03 -6.10  4.88  2.89 -2.23  2.70 -4.01  2.37 -1.37  0.47 &gt;
INFO: fsg_search.c(843): 79 frames, 520 HMMs (6/fr), 1624 senones (20/fr), 221 history entries (2/fr)</code></pre>

		
	</div>
<!-- .bbp-reply-content -->
</div>
<!-- .reply -->

			
				
<div id="post-1032340" class="bbp-reply-header">
	<div class="bbp-meta">
		<span class="bbp-reply-post-date">April 19, 2018 at 2:14 pm</span>

		
			<span class="bbp-header">
				in reply to: 				<a class="bbp-topic-permalink" href="/forums/topic/recognize-short-command-in-nonenglish/">Recognize short Command in nonEnglish</a>
			</span>

		
		<a href="/forums/topic/recognize-short-command-in-nonenglish/#post-1032340" class="bbp-reply-permalink">#1032340</a>

		
		<span class="bbp-admin-links"></span>
		
	</div>
<!-- .bbp-meta -->
</div>
<!-- #post-1032340 -->

<div class="loop-item-32 user-id-2480 bbp-parent-forum-3654 bbp-parent-topic-1032298 bbp-reply-position-34 odd topic-author  post-1032340 reply type-reply status-publish hentry">
	<div class="bbp-reply-author">

		
		<a href="/forums/profile/ikk/" title="View iKK&#039;s profile" class="bbp-author-link"><span class="bbp-author-avatar"></span><span class="bbp-author-name">iKK</span></a><div class="bbp-author-role">Participant</div>
		
		
	</div>
<!-- .bbp-reply-author -->

	<div class="bbp-reply-content">

		
		<p>Here are the logs:<br>
<a href="https://github.com/korners/OpenEarsTest/tree/master/Testing_Logs" rel="nofollow">Logs</a></p>
<p>I did 2 Log-files: The first one contains logs of correctly spoken sentences. The second one contains logs from incorrectly spoken but unfortunately still recognised sentences.</p>
<p>Also, the link shows a third File which is the ViewController.swift-File containing hopefully all you need in terms of the required &#8220;generation of my language model&#8221;&#8230;</p>

		
	</div>
<!-- .bbp-reply-content -->
</div>
<!-- .reply -->

			
				
<div id="post-1032336" class="bbp-reply-header">
	<div class="bbp-meta">
		<span class="bbp-reply-post-date">April 19, 2018 at 1:09 pm</span>

		
			<span class="bbp-header">
				in reply to: 				<a class="bbp-topic-permalink" href="/forums/topic/recognize-short-command-in-nonenglish/">Recognize short Command in nonEnglish</a>
			</span>

		
		<a href="/forums/topic/recognize-short-command-in-nonenglish/#post-1032336" class="bbp-reply-permalink">#1032336</a>

		
		<span class="bbp-admin-links"></span>
		
	</div>
<!-- .bbp-meta -->
</div>
<!-- #post-1032336 -->

<div class="loop-item-33 user-id-2480 bbp-parent-forum-3654 bbp-parent-topic-1032298 bbp-reply-position-31 even topic-author  post-1032336 reply type-reply status-publish hentry">
	<div class="bbp-reply-author">

		
		<a href="/forums/profile/ikk/" title="View iKK&#039;s profile" class="bbp-author-link"><span class="bbp-author-avatar"></span><span class="bbp-author-name">iKK</span></a><div class="bbp-author-role">Participant</div>
		
		
	</div>
<!-- .bbp-reply-author -->

	<div class="bbp-reply-content">

		
		<p>Yes, it was confusing.</p>
<p>And also, I am not asking you for debugging. I am asking you on how to apply the view settings OpenEars offers to get the recognition-success-rate (and specificity!) to an order where it is acceptable for production.</p>
<p>So &#8211; is there anymore settings I can do in order to improve specificity for our one-sentece words-array ?</p>

		
	</div>
<!-- .bbp-reply-content -->
</div>
<!-- .reply -->

			
				
<div id="post-1032334" class="bbp-reply-header">
	<div class="bbp-meta">
		<span class="bbp-reply-post-date">April 19, 2018 at 12:33 pm</span>

		
			<span class="bbp-header">
				in reply to: 				<a class="bbp-topic-permalink" href="/forums/topic/recognize-short-command-in-nonenglish/">Recognize short Command in nonEnglish</a>
			</span>

		
		<a href="/forums/topic/recognize-short-command-in-nonenglish/#post-1032334" class="bbp-reply-permalink">#1032334</a>

		
		<span class="bbp-admin-links"></span>
		
	</div>
<!-- .bbp-meta -->
</div>
<!-- #post-1032334 -->

<div class="loop-item-34 user-id-2480 bbp-parent-forum-3654 bbp-parent-topic-1032298 bbp-reply-position-29 odd topic-author  post-1032334 reply type-reply status-publish hentry">
	<div class="bbp-reply-author">

		
		<a href="/forums/profile/ikk/" title="View iKK&#039;s profile" class="bbp-author-link"><span class="bbp-author-avatar"></span><span class="bbp-author-name">iKK</span></a><div class="bbp-author-role">Participant</div>
		
		
	</div>
<!-- .bbp-reply-author -->

	<div class="bbp-reply-content">

		
		<p>Here is the link to the the test-project you asked for (<em>an entirely new project with the tutorial only using the approach we’ve chosen here (a grammar using stock OpenEars and the German acoustic model)</em>): </p>
<p><a href="https://github.com/korners/OpenEarsTest" rel="nofollow">Test Project OpenEars with German-Acc.Model</a></p>
<p>Unfortunately, I observe still the very same issue as before with my other tests. (i.e. too many sentences are recognized that have nothing to do with the one provided in the words-array).</p>
<p>Can you please help any further here ??</p>

		
	</div>
<!-- .bbp-reply-content -->
</div>
<!-- .reply -->

			
				
<div id="post-1032332" class="bbp-reply-header">
	<div class="bbp-meta">
		<span class="bbp-reply-post-date">April 19, 2018 at 10:25 am</span>

		
			<span class="bbp-header">
				in reply to: 				<a class="bbp-topic-permalink" href="/forums/topic/recognize-short-command-in-nonenglish/">Recognize short Command in nonEnglish</a>
			</span>

		
		<a href="/forums/topic/recognize-short-command-in-nonenglish/#post-1032332" class="bbp-reply-permalink">#1032332</a>

		
		<span class="bbp-admin-links"></span>
		
	</div>
<!-- .bbp-meta -->
</div>
<!-- #post-1032332 -->

<div class="loop-item-35 user-id-2480 bbp-parent-forum-3654 bbp-parent-topic-1032298 bbp-reply-position-27 even topic-author  post-1032332 reply type-reply status-publish hentry">
	<div class="bbp-reply-author">

		
		<a href="/forums/profile/ikk/" title="View iKK&#039;s profile" class="bbp-author-link"><span class="bbp-author-avatar"></span><span class="bbp-author-name">iKK</span></a><div class="bbp-author-role">Participant</div>
		
		
	</div>
<!-- .bbp-reply-author -->

	<div class="bbp-reply-content">

		
		<p>H Halle,<br>
  I completed a test-example completely from scratch. Please refer to my email. Hope to hear from you soon.</p>

		
	</div>
<!-- .bbp-reply-content -->
</div>
<!-- .reply -->

			
				
<div id="post-1032322" class="bbp-reply-header">
	<div class="bbp-meta">
		<span class="bbp-reply-post-date">April 13, 2018 at 2:18 pm</span>

		
			<span class="bbp-header">
				in reply to: 				<a class="bbp-topic-permalink" href="/forums/topic/recognize-short-command-in-nonenglish/">Recognize short Command in nonEnglish</a>
			</span>

		
		<a href="/forums/topic/recognize-short-command-in-nonenglish/#post-1032322" class="bbp-reply-permalink">#1032322</a>

		
		<span class="bbp-admin-links"></span>
		
	</div>
<!-- .bbp-meta -->
</div>
<!-- #post-1032322 -->

<div class="loop-item-36 user-id-2480 bbp-parent-forum-3654 bbp-parent-topic-1032298 bbp-reply-position-25 odd topic-author  post-1032322 reply type-reply status-publish hentry">
	<div class="bbp-reply-author">

		
		<a href="/forums/profile/ikk/" title="View iKK&#039;s profile" class="bbp-author-link"><span class="bbp-author-avatar"></span><span class="bbp-author-name">iKK</span></a><div class="bbp-author-role">Participant</div>
		
		
	</div>
<!-- .bbp-reply-author -->

	<div class="bbp-reply-content">

		
		<p>Sorry &#8211; yes, of course. I have too many versions going on.</p>
<p>I do have it the way you just stated ! But same issue&#8230;</p>

		
	</div>
<!-- .bbp-reply-content -->
</div>
<!-- .reply -->

			
				
<div id="post-1032320" class="bbp-reply-header">
	<div class="bbp-meta">
		<span class="bbp-reply-post-date">April 13, 2018 at 2:15 pm</span>

		
			<span class="bbp-header">
				in reply to: 				<a class="bbp-topic-permalink" href="/forums/topic/recognize-short-command-in-nonenglish/">Recognize short Command in nonEnglish</a>
			</span>

		
		<a href="/forums/topic/recognize-short-command-in-nonenglish/#post-1032320" class="bbp-reply-permalink">#1032320</a>

		
		<span class="bbp-admin-links"></span>
		
	</div>
<!-- .bbp-meta -->
</div>
<!-- #post-1032320 -->

<div class="loop-item-37 user-id-2480 bbp-parent-forum-3654 bbp-parent-topic-1032298 bbp-reply-position-23 even topic-author  post-1032320 reply type-reply status-publish hentry">
	<div class="bbp-reply-author">

		
		<a href="/forums/profile/ikk/" title="View iKK&#039;s profile" class="bbp-author-link"><span class="bbp-author-avatar"></span><span class="bbp-author-name">iKK</span></a><div class="bbp-author-role">Participant</div>
		
		
	</div>
<!-- .bbp-reply-author -->

	<div class="bbp-reply-content">

		
		<p>sorry typo: it sais:</p>
<p>words = [“esch”, “da”, “no”, “fey”]</p>

		
	</div>
<!-- .bbp-reply-content -->
</div>
<!-- .reply -->

			
				
<div id="post-1032319" class="bbp-reply-header">
	<div class="bbp-meta">
		<span class="bbp-reply-post-date">April 13, 2018 at 2:14 pm</span>

		
			<span class="bbp-header">
				in reply to: 				<a class="bbp-topic-permalink" href="/forums/topic/recognize-short-command-in-nonenglish/">Recognize short Command in nonEnglish</a>
			</span>

		
		<a href="/forums/topic/recognize-short-command-in-nonenglish/#post-1032319" class="bbp-reply-permalink">#1032319</a>

		
		<span class="bbp-admin-links"></span>
		
	</div>
<!-- .bbp-meta -->
</div>
<!-- #post-1032319 -->

<div class="loop-item-38 user-id-2480 bbp-parent-forum-3654 bbp-parent-topic-1032298 bbp-reply-position-22 odd topic-author  post-1032319 reply type-reply status-publish hentry">
	<div class="bbp-reply-author">

		
		<a href="/forums/profile/ikk/" title="View iKK&#039;s profile" class="bbp-author-link"><span class="bbp-author-avatar"></span><span class="bbp-author-name">iKK</span></a><div class="bbp-author-role">Participant</div>
		
		
	</div>
<!-- .bbp-reply-author -->

	<div class="bbp-reply-content">

		
		<p>The words array sais</p>
<p>words = [&#8220;esch&#8221; &#8220;da&#8221; &#8220;no&#8221; &#8220;fey&#8221;]</p>

		
	</div>
<!-- .bbp-reply-content -->
</div>
<!-- .reply -->

			
				
<div id="post-1032317" class="bbp-reply-header">
	<div class="bbp-meta">
		<span class="bbp-reply-post-date">April 13, 2018 at 2:07 pm</span>

		
			<span class="bbp-header">
				in reply to: 				<a class="bbp-topic-permalink" href="/forums/topic/recognize-short-command-in-nonenglish/">Recognize short Command in nonEnglish</a>
			</span>

		
		<a href="/forums/topic/recognize-short-command-in-nonenglish/#post-1032317" class="bbp-reply-permalink">#1032317</a>

		
		<span class="bbp-admin-links"></span>
		
	</div>
<!-- .bbp-meta -->
</div>
<!-- #post-1032317 -->

<div class="loop-item-39 user-id-2480 bbp-parent-forum-3654 bbp-parent-topic-1032298 bbp-reply-position-20 even topic-author  post-1032317 reply type-reply status-publish hentry">
	<div class="bbp-reply-author">

		
		<a href="/forums/profile/ikk/" title="View iKK&#039;s profile" class="bbp-author-link"><span class="bbp-author-avatar"></span><span class="bbp-author-name">iKK</span></a><div class="bbp-author-role">Participant</div>
		
		
	</div>
<!-- .bbp-reply-author -->

	<div class="bbp-reply-content">

		
		<p>Sure:</p>
<p>func startListening()<br>
{<br>
    if OEPocketsphinxController.sharedInstance().isListening {<br>
        stopListening()<br>
    }</p>
<p>    var acousticModelName = &#8220;AcousticModelGerman&#8221;<br>
    var fileName = &#8220;GermanModel&#8221;</p>
<p>    OEPocketsphinxController.sharedInstance().vadThreshold = 3.6;</p>
<p>    var error: Error?</p>
<p>    error = lmGenerator.generateGrammar(from: [OneOfTheseWillBeSaidOnce : words], withFilesNamed: fileName, forAcousticModelAtPath: OEAcousticModel.path(toModel: acousticModelName))</p>
<p>    var lmPath = &#8220;&#8221;<br>
    var dictPath = &#8220;&#8221;</p>
<p>    if(error == nil) {</p>
<p>        lmPath = lmGenerator.pathToSuccessfullyGeneratedLanguageModel(withRequestedName: fileName)<br>
        dictPath = lmGenerator.pathToSuccessfullyGeneratedDictionary(withRequestedName: fileName)<br>
        lmPath = lmGenerator.pathToSuccessfullyGeneratedGrammar(withRequestedName: fileName)</p>
<p>    } else {<br>
        print(&#8220;Error: \(error!.localizedDescription)&#8221;)<br>
    }</p>
<p>    try? OEPocketsphinxController.sharedInstance().setActive(true)<br>
    OEPocketsphinxController.sharedInstance().startListeningWithLanguageModel(atPath: lmPath, dictionaryAtPath: dictPath, acousticModelAtPath: OEAcousticModel.path(toModel: acousticModelName), languageModelIsJSGF: true)<br>
}</p>

		
	</div>
<!-- .bbp-reply-content -->
</div>
<!-- .reply -->

			
				
<div id="post-1032315" class="bbp-reply-header">
	<div class="bbp-meta">
		<span class="bbp-reply-post-date">April 13, 2018 at 2:02 pm</span>

		
			<span class="bbp-header">
				in reply to: 				<a class="bbp-topic-permalink" href="/forums/topic/recognize-short-command-in-nonenglish/">Recognize short Command in nonEnglish</a>
			</span>

		
		<a href="/forums/topic/recognize-short-command-in-nonenglish/#post-1032315" class="bbp-reply-permalink">#1032315</a>

		
		<span class="bbp-admin-links"></span>
		
	</div>
<!-- .bbp-meta -->
</div>
<!-- #post-1032315 -->

<div class="loop-item-40 user-id-2480 bbp-parent-forum-3654 bbp-parent-topic-1032298 bbp-reply-position-18 odd topic-author  post-1032315 reply type-reply status-publish hentry">
	<div class="bbp-reply-author">

		
		<a href="/forums/profile/ikk/" title="View iKK&#039;s profile" class="bbp-author-link"><span class="bbp-author-avatar"></span><span class="bbp-author-name">iKK</span></a><div class="bbp-author-role">Participant</div>
		
		
	</div>
<!-- .bbp-reply-author -->

	<div class="bbp-reply-content">

		
		<p>Same issue: The sentence is recognized 100% &#8211; but many more sentences having a similar lenght. For example I speak the sentence with the last (of the four) words replace by another word &#8211; and the grammar method still recognizes the sentence, unfortunately!</p>

		
	</div>
<!-- .bbp-reply-content -->
</div>
<!-- .reply -->

			
				
<div id="post-1032312" class="bbp-reply-header">
	<div class="bbp-meta">
		<span class="bbp-reply-post-date">April 13, 2018 at 1:59 pm</span>

		
			<span class="bbp-header">
				in reply to: 				<a class="bbp-topic-permalink" href="/forums/topic/recognize-short-command-in-nonenglish/">Recognize short Command in nonEnglish</a>
			</span>

		
		<a href="/forums/topic/recognize-short-command-in-nonenglish/#post-1032312" class="bbp-reply-permalink">#1032312</a>

		
		<span class="bbp-admin-links"></span>
		
	</div>
<!-- .bbp-meta -->
</div>
<!-- #post-1032312 -->

<div class="loop-item-41 user-id-2480 bbp-parent-forum-3654 bbp-parent-topic-1032298 bbp-reply-position-15 even topic-author  post-1032312 reply type-reply status-publish hentry">
	<div class="bbp-reply-author">

		
		<a href="/forums/profile/ikk/" title="View iKK&#039;s profile" class="bbp-author-link"><span class="bbp-author-avatar"></span><span class="bbp-author-name">iKK</span></a><div class="bbp-author-role">Participant</div>
		
		
	</div>
<!-- .bbp-reply-author -->

	<div class="bbp-reply-content">

		
		<p>And also, what is the vadThreshold value for German ?</p>

		
	</div>
<!-- .bbp-reply-content -->
</div>
<!-- .reply -->

			
				
<div id="post-1032311" class="bbp-reply-header">
	<div class="bbp-meta">
		<span class="bbp-reply-post-date">April 13, 2018 at 1:58 pm</span>

		
			<span class="bbp-header">
				in reply to: 				<a class="bbp-topic-permalink" href="/forums/topic/recognize-short-command-in-nonenglish/">Recognize short Command in nonEnglish</a>
			</span>

		
		<a href="/forums/topic/recognize-short-command-in-nonenglish/#post-1032311" class="bbp-reply-permalink">#1032311</a>

		
		<span class="bbp-admin-links"></span>
		
	</div>
<!-- .bbp-meta -->
</div>
<!-- #post-1032311 -->

<div class="loop-item-42 user-id-2480 bbp-parent-forum-3654 bbp-parent-topic-1032298 bbp-reply-position-14 odd topic-author  post-1032311 reply type-reply status-publish hentry">
	<div class="bbp-reply-author">

		
		<a href="/forums/profile/ikk/" title="View iKK&#039;s profile" class="bbp-author-link"><span class="bbp-author-avatar"></span><span class="bbp-author-name">iKK</span></a><div class="bbp-author-role">Participant</div>
		
		
	</div>
<!-- .bbp-reply-author -->

	<div class="bbp-reply-content">

		
		<p>Is it one word as a single element in the array &#8211; or rather 4 words as a single string-array element ??</p>

		
	</div>
<!-- .bbp-reply-content -->
</div>
<!-- .reply -->

			
				
<div id="post-1032309" class="bbp-reply-header">
	<div class="bbp-meta">
		<span class="bbp-reply-post-date">April 13, 2018 at 1:53 pm</span>

		
			<span class="bbp-header">
				in reply to: 				<a class="bbp-topic-permalink" href="/forums/topic/recognize-short-command-in-nonenglish/">Recognize short Command in nonEnglish</a>
			</span>

		
		<a href="/forums/topic/recognize-short-command-in-nonenglish/#post-1032309" class="bbp-reply-permalink">#1032309</a>

		
		<span class="bbp-admin-links"></span>
		
	</div>
<!-- .bbp-meta -->
</div>
<!-- #post-1032309 -->

<div class="loop-item-43 user-id-2480 bbp-parent-forum-3654 bbp-parent-topic-1032298 bbp-reply-position-12 even topic-author  post-1032309 reply type-reply status-publish hentry">
	<div class="bbp-reply-author">

		
		<a href="/forums/profile/ikk/" title="View iKK&#039;s profile" class="bbp-author-link"><span class="bbp-author-avatar"></span><span class="bbp-author-name">iKK</span></a><div class="bbp-author-role">Participant</div>
		
		
	</div>
<!-- .bbp-reply-author -->

	<div class="bbp-reply-content">

		
		<p>Yes !</p>

		
	</div>
<!-- .bbp-reply-content -->
</div>
<!-- .reply -->

			
				
<div id="post-1032307" class="bbp-reply-header">
	<div class="bbp-meta">
		<span class="bbp-reply-post-date">April 13, 2018 at 1:49 pm</span>

		
			<span class="bbp-header">
				in reply to: 				<a class="bbp-topic-permalink" href="/forums/topic/recognize-short-command-in-nonenglish/">Recognize short Command in nonEnglish</a>
			</span>

		
		<a href="/forums/topic/recognize-short-command-in-nonenglish/#post-1032307" class="bbp-reply-permalink">#1032307</a>

		
		<span class="bbp-admin-links"></span>
		
	</div>
<!-- .bbp-meta -->
</div>
<!-- #post-1032307 -->

<div class="loop-item-44 user-id-2480 bbp-parent-forum-3654 bbp-parent-topic-1032298 bbp-reply-position-10 odd topic-author  post-1032307 reply type-reply status-publish hentry">
	<div class="bbp-reply-author">

		
		<a href="/forums/profile/ikk/" title="View iKK&#039;s profile" class="bbp-author-link"><span class="bbp-author-avatar"></span><span class="bbp-author-name">iKK</span></a><div class="bbp-author-role">Participant</div>
		
		
	</div>
<!-- .bbp-reply-author -->

	<div class="bbp-reply-content">

		
		<p>It is not as an articulated language like German.</p>

		
	</div>
<!-- .bbp-reply-content -->
</div>
<!-- .reply -->

			
				
<div id="post-1032306" class="bbp-reply-header">
	<div class="bbp-meta">
		<span class="bbp-reply-post-date">April 13, 2018 at 1:49 pm</span>

		
			<span class="bbp-header">
				in reply to: 				<a class="bbp-topic-permalink" href="/forums/topic/recognize-short-command-in-nonenglish/">Recognize short Command in nonEnglish</a>
			</span>

		
		<a href="/forums/topic/recognize-short-command-in-nonenglish/#post-1032306" class="bbp-reply-permalink">#1032306</a>

		
		<span class="bbp-admin-links"></span>
		
	</div>
<!-- .bbp-meta -->
</div>
<!-- #post-1032306 -->

<div class="loop-item-45 user-id-2480 bbp-parent-forum-3654 bbp-parent-topic-1032298 bbp-reply-position-9 even topic-author  post-1032306 reply type-reply status-publish hentry">
	<div class="bbp-reply-author">

		
		<a href="/forums/profile/ikk/" title="View iKK&#039;s profile" class="bbp-author-link"><span class="bbp-author-avatar"></span><span class="bbp-author-name">iKK</span></a><div class="bbp-author-role">Participant</div>
		
		
	</div>
<!-- .bbp-reply-author -->

	<div class="bbp-reply-content">

		
		<p>It is just spoken without break inbetween the words and also some letters are ommitted at the beginning of each single word (which is possible in Swiss german)</p>

		
	</div>
<!-- .bbp-reply-content -->
</div>
<!-- .reply -->

			
				
<div id="post-1032305" class="bbp-reply-header">
	<div class="bbp-meta">
		<span class="bbp-reply-post-date">April 13, 2018 at 1:46 pm</span>

		
			<span class="bbp-header">
				in reply to: 				<a class="bbp-topic-permalink" href="/forums/topic/recognize-short-command-in-nonenglish/">Recognize short Command in nonEnglish</a>
			</span>

		
		<a href="/forums/topic/recognize-short-command-in-nonenglish/#post-1032305" class="bbp-reply-permalink">#1032305</a>

		
		<span class="bbp-admin-links"></span>
		
	</div>
<!-- .bbp-meta -->
</div>
<!-- #post-1032305 -->

<div class="loop-item-46 user-id-2480 bbp-parent-forum-3654 bbp-parent-topic-1032298 bbp-reply-position-8 odd topic-author  post-1032305 reply type-reply status-publish hentry">
	<div class="bbp-reply-author">

		
		<a href="/forums/profile/ikk/" title="View iKK&#039;s profile" class="bbp-author-link"><span class="bbp-author-avatar"></span><span class="bbp-author-name">iKK</span></a><div class="bbp-author-role">Participant</div>
		
		
	</div>
<!-- .bbp-reply-author -->

	<div class="bbp-reply-content">

		
		<p>ok &#8211; it is hard to explain :) But let&#8217;s imagine the german sentence &#8220;Wir sind Wir&#8221; and then it is spoken &#8220;MiaSanMia&#8221; :)</p>

		
	</div>
<!-- .bbp-reply-content -->
</div>
<!-- .reply -->

			
				
<div id="post-1032303" class="bbp-reply-header">
	<div class="bbp-meta">
		<span class="bbp-reply-post-date">April 13, 2018 at 1:38 pm</span>

		
			<span class="bbp-header">
				in reply to: 				<a class="bbp-topic-permalink" href="/forums/topic/recognize-short-command-in-nonenglish/">Recognize short Command in nonEnglish</a>
			</span>

		
		<a href="/forums/topic/recognize-short-command-in-nonenglish/#post-1032303" class="bbp-reply-permalink">#1032303</a>

		
		<span class="bbp-admin-links"></span>
		
	</div>
<!-- .bbp-meta -->
</div>
<!-- #post-1032303 -->

<div class="loop-item-47 user-id-2480 bbp-parent-forum-3654 bbp-parent-topic-1032298 bbp-reply-position-6 even topic-author  post-1032303 reply type-reply status-publish hentry">
	<div class="bbp-reply-author">

		
		<a href="/forums/profile/ikk/" title="View iKK&#039;s profile" class="bbp-author-link"><span class="bbp-author-avatar"></span><span class="bbp-author-name">iKK</span></a><div class="bbp-author-role">Participant</div>
		
		
	</div>
<!-- .bbp-reply-author -->

	<div class="bbp-reply-content">

		
		<p>The thing is that the Swiss-german short sentence only consists of 4 words. And in 99% of the time they are spoken in such a fast manner that is sounds like ONE long word. There is some background-noise (imagine a train-station-kind-of background-noise).</p>
<p>What do you suggest for this use-case ? (grammar vs. Rejecto) ? You are the expert :)</p>

		
	</div>
<!-- .bbp-reply-content -->
</div>
<!-- .reply -->

			
				
<div id="post-1032301" class="bbp-reply-header">
	<div class="bbp-meta">
		<span class="bbp-reply-post-date">April 13, 2018 at 1:30 pm</span>

		
			<span class="bbp-header">
				in reply to: 				<a class="bbp-topic-permalink" href="/forums/topic/recognize-short-command-in-nonenglish/">Recognize short Command in nonEnglish</a>
			</span>

		
		<a href="/forums/topic/recognize-short-command-in-nonenglish/#post-1032301" class="bbp-reply-permalink">#1032301</a>

		
		<span class="bbp-admin-links"></span>
		
	</div>
<!-- .bbp-meta -->
</div>
<!-- #post-1032301 -->

<div class="loop-item-48 user-id-2480 bbp-parent-forum-3654 bbp-parent-topic-1032298 bbp-reply-position-4 odd topic-author  post-1032301 reply type-reply status-publish hentry">
	<div class="bbp-reply-author">

		
		<a href="/forums/profile/ikk/" title="View iKK&#039;s profile" class="bbp-author-link"><span class="bbp-author-avatar"></span><span class="bbp-author-name">iKK</span></a><div class="bbp-author-role">Participant</div>
		
		
	</div>
<!-- .bbp-reply-author -->

	<div class="bbp-reply-content">

		
		<p>About the decision &#8211; it is hard since both its documentation advertize what is needed in my case :</p>
<p>&#8211;&gt; generateGrammar sais: “This will recognize exact phrases instead of probabilistically recognizing word combinations in any sequence.”</p>
<p>&#8211;&gt; Rejecto&#8217;s doc sais: “Rejecto makes sure that your speech app does not attempt to recognize words which are not part of your vocabulary. This lets your app stick to listening for just the words it knows, and that makes your users happy.”</p>
<p>Therefore both seem to be necessary somehow &#8211; what choice do you suggest. Or can you even use both at the same time ??</p>

		
	</div>
<!-- .bbp-reply-content -->
</div>
<!-- .reply -->

			
				
<div id="post-1032300" class="bbp-reply-header">
	<div class="bbp-meta">
		<span class="bbp-reply-post-date">April 13, 2018 at 1:27 pm</span>

		
			<span class="bbp-header">
				in reply to: 				<a class="bbp-topic-permalink" href="/forums/topic/recognize-short-command-in-nonenglish/">Recognize short Command in nonEnglish</a>
			</span>

		
		<a href="/forums/topic/recognize-short-command-in-nonenglish/#post-1032300" class="bbp-reply-permalink">#1032300</a>

		
		<span class="bbp-admin-links"></span>
		
	</div>
<!-- .bbp-meta -->
</div>
<!-- #post-1032300 -->

<div class="loop-item-49 user-id-2480 bbp-parent-forum-3654 bbp-parent-topic-1032298 bbp-reply-position-3 even topic-author  post-1032300 reply type-reply status-publish hentry">
	<div class="bbp-reply-author">

		
		<a href="/forums/profile/ikk/" title="View iKK&#039;s profile" class="bbp-author-link"><span class="bbp-author-avatar"></span><span class="bbp-author-name">iKK</span></a><div class="bbp-author-role">Participant</div>
		
		
	</div>
<!-- .bbp-reply-author -->

	<div class="bbp-reply-content">

		
		<p>I was using only one Accoustic-model at the time (but happen to try English and Spanish so far). And no &#8211; there is no reason (anymore) to not also try with the German-Accoustic model &#8211; in fact I just did 5 Minutes ago. (we did have other products evaluated in EnglishOrSpanish and therefore the choice of EnglishOrSpanish so far&#8230;)</p>
<p>About grammar vs. Rejecto: You tell me what suits better for this kind of problem ??? (i.e. recognising a Swiss-german short sentence with highest specificity)</p>

		
	</div>
<!-- .bbp-reply-content -->
</div>
<!-- .reply -->

			
		
	</li>
<!-- .bbp-body -->

	<li class="bbp-footer">
		<div class="bbp-reply-author">Author</div>
		<div class="bbp-reply-content">Posts</div>
<!-- .bbp-reply-content -->
	</li>
<!-- .bbp-footer -->
</ul>
<!-- #topic-0-replies -->


			
<div class="bbp-pagination">
	<div class="bbp-pagination-count">Viewing 50 posts - 1 through 50 (of 50 total)</div>
	<div class="bbp-pagination-links"></div>
</div>


		
	</div>
</div>
<!-- #bbp-user-replies-created -->

								</div>
	</div>

	
</div>

					               	</section><!-- /.entry -->

				                
            </article><!-- /.post -->
            
              
        
		</section><!-- /#main -->
		
		
        	
<aside id="sidebar" class="col-right">

	
	   
	
	 
	
</aside><!-- /#sidebar -->

    </div>
<!-- /#content -->
		
		<footer id="footer" class="col-full">
	
			<div id="copyright" class="col-left">
							<p>Politepix &copy; 2024. All Rights Reserved.</p>
						</div>
	
			<div id="credit" class="col-right">
	        <div style="text-align:right;line-height:1.3em">OpenEars® is a registered trademark of Politepix<br>AllHours® is a registered trademark of Politepix<br>The Politepix site uses cookies in order to understand how the website is used by visitors and in order to enable some required functionality. You can learn all about which cookies we use on the <a href="/about/">About</a> page, as well as everything about our privacy policy.<br>
<a href="https://twitter.com/Politepix" rel="me">TWITTER</a> | <a href="/contact" id="impressumlink">CONTACT POLITEPIX</a><a href="/about" id="impressumlink"> | IMPRESSUM | ABOUT | LEGAL | IMPRINT</a>
</div>			</div>
	<a rel="me" href="https://mastodon.social/@Halle">M</a>
		</footer><!-- /#footer  -->

</div>
<!-- /#wrapper -->

<!-- Consent Management powered by Complianz | GDPR/CCPA Cookie Consent https://wordpress.org/plugins/complianz-gdpr -->
<div id="cmplz-cookiebanner-container">
<div class="cmplz-cookiebanner cmplz-hidden banner-1 bottom-right-view-preferences optin cmplz-bottom-right cmplz-categories-type-view-preferences" aria-modal="true" data-nosnippet="true" role="dialog" aria-live="polite" aria-labelledby="cmplz-header-1-optin" aria-describedby="cmplz-message-1-optin">
	<div class="cmplz-header">
		<div class="cmplz-logo"></div>
		<div class="cmplz-title" id="cmplz-header-1-optin">Manage Cookie Consent</div>
		<div class="cmplz-close" tabindex="0" role="button" aria-label="Close dialog">
			<svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="times" class="svg-inline--fa fa-times fa-w-11" role="img" xmlns="http://www.w3.org/2000/svg" viewbox="0 0 352 512"><path fill="currentColor" d="M242.72 256l100.07-100.07c12.28-12.28 12.28-32.19 0-44.48l-22.24-22.24c-12.28-12.28-32.19-12.28-44.48 0L176 189.28 75.93 89.21c-12.28-12.28-32.19-12.28-44.48 0L9.21 111.45c-12.28 12.28-12.28 32.19 0 44.48L109.28 256 9.21 356.07c-12.28 12.28-12.28 32.19 0 44.48l22.24 22.24c12.28 12.28 32.2 12.28 44.48 0L176 322.72l100.07 100.07c12.28 12.28 32.2 12.28 44.48 0l22.24-22.24c12.28-12.28 12.28-32.19 0-44.48L242.72 256z"></path></svg>
		</div>
	</div>

	<div class="cmplz-divider cmplz-divider-header"></div>
	<div class="cmplz-body">
		<div class="cmplz-message" id="cmplz-message-1-optin">To provide the best experiences, we use technologies like cookies to store and/or access device information. Consenting to these technologies will allow us to process data such as browsing behavior or unique IDs on this site. Not consenting or withdrawing consent, may adversely affect certain features and functions.</div>
		<!-- categories start -->
		<div class="cmplz-categories">
			<details class="cmplz-category cmplz-functional">
				<summary>
						<span class="cmplz-category-header">
							<span class="cmplz-category-title">Functional</span>
							<span class="cmplz-always-active">
								<span class="cmplz-banner-checkbox">
									<input type="checkbox" id="cmplz-functional-optin" data-category="cmplz_functional" class="cmplz-consent-checkbox cmplz-functional" size="40" value="1">
									<label class="cmplz-label" for="cmplz-functional-optin" tabindex="0"><span class="screen-reader-text">Functional</span></label>
								</span>
								Always active							</span>
							<span class="cmplz-icon cmplz-open">
								<svg xmlns="http://www.w3.org/2000/svg" viewbox="0 0 448 512" height="18"><path d="M224 416c-8.188 0-16.38-3.125-22.62-9.375l-192-192c-12.5-12.5-12.5-32.75 0-45.25s32.75-12.5 45.25 0L224 338.8l169.4-169.4c12.5-12.5 32.75-12.5 45.25 0s12.5 32.75 0 45.25l-192 192C240.4 412.9 232.2 416 224 416z"></path></svg>
							</span>
						</span>
				</summary>
				<div class="cmplz-description">
					<span class="cmplz-description-functional">The technical storage or access is strictly necessary for the legitimate purpose of enabling the use of a specific service explicitly requested by the subscriber or user, or for the sole purpose of carrying out the transmission of a communication over an electronic communications network.</span>
				</div>
			</details>

			<details class="cmplz-category cmplz-preferences">
				<summary>
						<span class="cmplz-category-header">
							<span class="cmplz-category-title">Preferences</span>
							<span class="cmplz-banner-checkbox">
								<input type="checkbox" id="cmplz-preferences-optin" data-category="cmplz_preferences" class="cmplz-consent-checkbox cmplz-preferences" size="40" value="1">
								<label class="cmplz-label" for="cmplz-preferences-optin" tabindex="0"><span class="screen-reader-text">Preferences</span></label>
							</span>
							<span class="cmplz-icon cmplz-open">
								<svg xmlns="http://www.w3.org/2000/svg" viewbox="0 0 448 512" height="18"><path d="M224 416c-8.188 0-16.38-3.125-22.62-9.375l-192-192c-12.5-12.5-12.5-32.75 0-45.25s32.75-12.5 45.25 0L224 338.8l169.4-169.4c12.5-12.5 32.75-12.5 45.25 0s12.5 32.75 0 45.25l-192 192C240.4 412.9 232.2 416 224 416z"></path></svg>
							</span>
						</span>
				</summary>
				<div class="cmplz-description">
					<span class="cmplz-description-preferences">The technical storage or access is necessary for the legitimate purpose of storing preferences that are not requested by the subscriber or user.</span>
				</div>
			</details>

			<details class="cmplz-category cmplz-statistics">
				<summary>
						<span class="cmplz-category-header">
							<span class="cmplz-category-title">Statistics</span>
							<span class="cmplz-banner-checkbox">
								<input type="checkbox" id="cmplz-statistics-optin" data-category="cmplz_statistics" class="cmplz-consent-checkbox cmplz-statistics" size="40" value="1">
								<label class="cmplz-label" for="cmplz-statistics-optin" tabindex="0"><span class="screen-reader-text">Statistics</span></label>
							</span>
							<span class="cmplz-icon cmplz-open">
								<svg xmlns="http://www.w3.org/2000/svg" viewbox="0 0 448 512" height="18"><path d="M224 416c-8.188 0-16.38-3.125-22.62-9.375l-192-192c-12.5-12.5-12.5-32.75 0-45.25s32.75-12.5 45.25 0L224 338.8l169.4-169.4c12.5-12.5 32.75-12.5 45.25 0s12.5 32.75 0 45.25l-192 192C240.4 412.9 232.2 416 224 416z"></path></svg>
							</span>
						</span>
				</summary>
				<div class="cmplz-description">
					<span class="cmplz-description-statistics">The technical storage or access that is used exclusively for statistical purposes.</span>
					<span class="cmplz-description-statistics-anonymous">The technical storage or access that is used exclusively for anonymous statistical purposes. Without a subpoena, voluntary compliance on the part of your Internet Service Provider, or additional records from a third party, information stored or retrieved for this purpose alone cannot usually be used to identify you.</span>
				</div>
			</details>
			<details class="cmplz-category cmplz-marketing">
				<summary>
						<span class="cmplz-category-header">
							<span class="cmplz-category-title">Marketing</span>
							<span class="cmplz-banner-checkbox">
								<input type="checkbox" id="cmplz-marketing-optin" data-category="cmplz_marketing" class="cmplz-consent-checkbox cmplz-marketing" size="40" value="1">
								<label class="cmplz-label" for="cmplz-marketing-optin" tabindex="0"><span class="screen-reader-text">Marketing</span></label>
							</span>
							<span class="cmplz-icon cmplz-open">
								<svg xmlns="http://www.w3.org/2000/svg" viewbox="0 0 448 512" height="18"><path d="M224 416c-8.188 0-16.38-3.125-22.62-9.375l-192-192c-12.5-12.5-12.5-32.75 0-45.25s32.75-12.5 45.25 0L224 338.8l169.4-169.4c12.5-12.5 32.75-12.5 45.25 0s12.5 32.75 0 45.25l-192 192C240.4 412.9 232.2 416 224 416z"></path></svg>
							</span>
						</span>
				</summary>
				<div class="cmplz-description">
					<span class="cmplz-description-marketing">The technical storage or access is required to create user profiles to send advertising, or to track the user on a website or across several websites for similar marketing purposes.</span>
				</div>
			</details>
		</div>
<!-- categories end -->
			</div>

	<div class="cmplz-links cmplz-information">
		<a class="cmplz-link cmplz-manage-options cookie-statement" href="#" data-relative_url="#cmplz-manage-consent-container">Manage options</a>
		<a class="cmplz-link cmplz-manage-third-parties cookie-statement" href="#" data-relative_url="#cmplz-cookies-overview">Manage services</a>
		<a class="cmplz-link cmplz-manage-vendors tcf cookie-statement" href="#" data-relative_url="#cmplz-tcf-wrapper">Manage {vendor_count} vendors</a>
		<a class="cmplz-link cmplz-external cmplz-read-more-purposes tcf" target="_blank" rel="noopener noreferrer nofollow" href="https://cookiedatabase.org/tcf/purposes/">Read more about these purposes</a>
			</div>

	<div class="cmplz-divider cmplz-footer"></div>

	<div class="cmplz-buttons">
		<button class="cmplz-btn cmplz-accept">Accept</button>
		<button class="cmplz-btn cmplz-deny">Deny</button>
		<button class="cmplz-btn cmplz-view-preferences">View preferences</button>
		<button class="cmplz-btn cmplz-save-preferences">Save preferences</button>
		<a class="cmplz-btn cmplz-manage-options tcf cookie-statement" href="#" data-relative_url="#cmplz-manage-consent-container">View preferences</a>
			</div>

	<div class="cmplz-links cmplz-documents">
		<a class="cmplz-link cookie-statement" href="#" data-relative_url="">{title}</a>
		<a class="cmplz-link privacy-statement" href="#" data-relative_url="">{title}</a>
		<a class="cmplz-link impressum" href="#" data-relative_url="">{title}</a>
			</div>

</div>
</div>
					<div id="cmplz-manage-consent" data-nosnippet="true">
<button class="cmplz-btn cmplz-hidden cmplz-manage-consent manage-consent-1">Manage consent</button>

</div>
<!--[if lt IE 9]>
<script src="https://www.politepix.com/wp-content//themes/pixelpress/includes/js/respond-IE.js"></script>
<![endif]-->
			<script>jQuery(document).ready(function(){
					jQuery('.images a').attr('rel', 'prettyPhoto[product-gallery]');
				});</script>
			<script type="text/javascript">(function () {
			var c = document.body.className;
			c = c.replace(/woocommerce-no-js/, 'woocommerce-js');
			document.body.className = c;
		})();</script>
	<link rel="stylesheet" id="wc-blocks-style-css" href="https://c0.wp.com/p/woocommerce/8.8.2/assets/client/blocks/wc-blocks.css" type="text/css" media="all">
<script type="text/javascript" src="https://c0.wp.com/p/woocommerce/8.8.2/assets/js/accounting/accounting.min.js" id="accounting-js"></script>
<script type="text/javascript" src="https://c0.wp.com/c/6.5.2/wp-includes/js/jquery/ui/core.min.js" id="jquery-ui-core-js"></script>
<script type="text/javascript" src="https://c0.wp.com/c/6.5.2/wp-includes/js/jquery/ui/datepicker.min.js" id="jquery-ui-datepicker-js"></script>
<script type="text/javascript" id="jquery-ui-datepicker-js-after">
/* <![CDATA[ */
jQuery(function(jQuery){jQuery.datepicker.setDefaults({"closeText":"Close","currentText":"Today","monthNames":["January","February","March","April","May","June","July","August","September","October","November","December"],"monthNamesShort":["Jan","Feb","Mar","Apr","May","Jun","Jul","Aug","Sep","Oct","Nov","Dec"],"nextText":"Next","prevText":"Previous","dayNames":["Sunday","Monday","Tuesday","Wednesday","Thursday","Friday","Saturday"],"dayNamesShort":["Sun","Mon","Tue","Wed","Thu","Fri","Sat"],"dayNamesMin":["S","M","T","W","T","F","S"],"dateFormat":"MM d, yy","firstDay":1,"isRTL":false});});
/* ]]> */
</script>
<script type="text/javascript" id="woocommerce-addons-js-extra">
/* <![CDATA[ */
var woocommerce_addons_params = {"price_display_suffix":"","tax_enabled":"1","price_include_tax":"","display_include_tax":"","ajax_url":"\/wp-admin\/admin-ajax.php","i18n_validation_required_select":"Please choose an option.","i18n_validation_required_input":"Please enter some text in this field.","i18n_validation_required_number":"Please enter a number in this field.","i18n_validation_required_file":"Please upload a file.","i18n_validation_letters_only":"Please enter letters only.","i18n_validation_numbers_only":"Please enter numbers only.","i18n_validation_letters_and_numbers_only":"Please enter letters and numbers only.","i18n_validation_email_only":"Please enter a valid email address.","i18n_validation_min_characters":"Please enter at least %c characters.","i18n_validation_max_characters":"Please enter up to %c characters.","i18n_validation_min_number":"Please enter %c or more.","i18n_validation_max_number":"Please enter %c or less.","i18n_sub_total":"Subtotal","i18n_remaining":"<span><\/span> characters remaining","currency_format_num_decimals":"2","currency_format_symbol":"€","currency_format_decimal_sep":".","currency_format_thousand_sep":",","trim_trailing_zeros":"","is_bookings":"","trim_user_input_characters":"1000","quantity_symbol":"x ","datepicker_class":"wc_pao_datepicker","datepicker_date_format":"MM d, yy","gmt_offset":"-2","date_input_timezone_reference":"default","currency_format":"%s%v"};
/* ]]> */
</script>
<script type="text/javascript" src="https://www.politepix.com/wp-content/plugins/woocommerce-product-addons/assets/js/frontend/addons.min.js?ver=6.8.2" id="woocommerce-addons-js" defer data-wp-strategy="defer"></script>
<script type="text/javascript" src="https://www.politepix.com/wp-content/plugins/jetpack/jetpack_vendor/automattic/jetpack-image-cdn/dist/image-cdn.js?minify=false&amp;ver=132249e245926ae3e188" id="jetpack-photon-js"></script>
<script type="text/javascript" src="https://www.politepix.com/wp-content/plugins/bbpress/templates/default/js/editor.min.js?ver=2.6.9" id="bbpress-editor-js"></script>
<script type="text/javascript" src="https://c0.wp.com/p/woocommerce/8.8.2/assets/js/sourcebuster/sourcebuster.min.js" id="sourcebuster-js-js"></script>
<script type="text/javascript" id="wc-order-attribution-js-extra">
/* <![CDATA[ */
var wc_order_attribution = {"params":{"lifetime":1.0e-5,"session":30,"ajaxurl":"\/wp-admin\/admin-ajax.php","prefix":"wc_order_attribution_","allowTracking":true},"fields":{"source_type":"current.typ","referrer":"current_add.rf","utm_campaign":"current.cmp","utm_source":"current.src","utm_medium":"current.mdm","utm_content":"current.cnt","utm_id":"current.id","utm_term":"current.trm","session_entry":"current_add.ep","session_start_time":"current_add.fd","session_pages":"session.pgs","session_count":"udata.vst","user_agent":"udata.uag"}};
/* ]]> */
</script>
<script type="text/javascript" src="https://c0.wp.com/p/woocommerce/8.8.2/assets/js/frontend/order-attribution.min.js" id="wc-order-attribution-js"></script>
<script data-service="jetpack-statistics" data-category="statistics" type="text/plain" data-cmplz-src="https://stats.wp.com/e-202417.js" id="jetpack-stats-js" data-wp-strategy="defer"></script>
<script type="text/javascript" id="jetpack-stats-js-after">
/* <![CDATA[ */
_stq = window._stq || [];
_stq.push([ "view", JSON.parse("{\"v\":\"ext\",\"blog\":\"206848719\",\"post\":\"0\",\"tz\":\"2\",\"srv\":\"www.politepix.com\",\"j\":\"1:13.3.1\"}") ]);
_stq.push([ "clickTrackerInit", "206848719", "0" ]);
/* ]]> */
</script>
<script type="text/javascript" id="cmplz-cookiebanner-js-extra">
/* <![CDATA[ */
var complianz = {"prefix":"cmplz_","user_banner_id":"1","set_cookies":[],"block_ajax_content":"","banner_version":"18","version":"7.0.4","store_consent":"","do_not_track_enabled":"1","consenttype":"optin","region":"eu","geoip":"","dismiss_timeout":"","disable_cookiebanner":"","soft_cookiewall":"","dismiss_on_scroll":"","cookie_expiry":"365","url":"\/wp-json\/complianz\/v1\/","locale":"lang=en&locale=en_US","set_cookies_on_root":"","cookie_domain":"","current_policy_id":"16","cookie_path":"\/","categories":{"statistics":"statistics","marketing":"marketing"},"tcf_active":"","placeholdertext":"Click to accept {category} cookies and enable this content","css_file":"\/wp-content\/uploads\/complianz\/css\/banner-{banner_id}-{type}.css?v=18","page_links":{"eu":{"cookie-statement":{"title":"About &#038; Impressum &#038; Privacy Policy","url":"\/about\/"},"privacy-statement":{"title":"About &#038; Impressum &#038; Privacy Policy","url":"\/about\/"},"impressum":{"title":"About &#038; Impressum &#038; Privacy Policy","url":"\/about\/"}},"us":{"impressum":{"title":"About &#038; Impressum &#038; Privacy Policy","url":"\/about\/"}},"uk":{"impressum":{"title":"About &#038; Impressum &#038; Privacy Policy","url":"\/about\/"}},"ca":{"impressum":{"title":"About &#038; Impressum &#038; Privacy Policy","url":"\/about\/"}},"au":{"impressum":{"title":"About &#038; Impressum &#038; Privacy Policy","url":"\/about\/"}},"za":{"impressum":{"title":"About &#038; Impressum &#038; Privacy Policy","url":"\/about\/"}},"br":{"impressum":{"title":"About &#038; Impressum &#038; Privacy Policy","url":"\/about\/"}}},"tm_categories":"","forceEnableStats":"","preview":"","clean_cookies":"","aria_label":"Click to accept {category} cookies and enable this content"};
/* ]]> */
</script>
<script defer type="text/javascript" src="https://www.politepix.com/wp-content/plugins/complianz-gdpr/cookiebanner/js/complianz.min.js?ver=1710283454" id="cmplz-cookiebanner-js"></script>
</body>
</html>