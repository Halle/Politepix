<?xml version="1.0" encoding="UTF-8"?>
	<rss version="2.0"
		xmlns:content="http://purl.org/rss/1.0/modules/content/"
		xmlns:wfw="http://wellformedweb.org/CommentAPI/"
		xmlns:dc="http://purl.org/dc/elements/1.1/"
		xmlns:atom="http://www.w3.org/2005/Atom"

			>

	<channel>

		<title>how to use openears framework to &quot;parrot&quot; back to you what you said &#8211; Politepix</title>
		<atom:link href="/forums/topic/how-to-use-openears-framework-to-parrot-back-to-you-what-you-said/feed/" rel="self" type="application/rss+xml" />
		<link>/forums/topic/how-to-use-openears-framework-to-parrot-back-to-you-what-you-said/feed/</link>
		<description></description>
		<lastBuildDate>Tue, 23 Apr 2024 14:59:37 +0000</lastBuildDate>
		<generator>https://bbpress.org/?v=2.6.9</generator>
		<language>en-US</language>

		
														
					
				<item>
					<guid>/forums/topic/how-to-use-openears-framework-to-parrot-back-to-you-what-you-said/#post-1017568</guid>
					<title><![CDATA[how to use openears framework to &quot;parrot&quot; back to you what you said]]></title>
					<link>/forums/topic/how-to-use-openears-framework-to-parrot-back-to-you-what-you-said/#post-1017568</link>
					<pubDate>Fri, 28 Jun 2013 18:10:53 +0000</pubDate>
					<dc:creator>doogie001</dc:creator>

					<description>
						<![CDATA[
						<p>I have been developing with the openears framework and I need to be able to &#8220;parrot back&#8221; or re-itereate what the user said when openears was listening. </p>
<p>Looking through the code, I am not sure how to accomplish this. Any help is much appreciated. </p>
<p>Thank You</p>
						]]>
					</description>

					
					
				</item>

			
				<item>
					<guid>/forums/topic/how-to-use-openears-framework-to-parrot-back-to-you-what-you-said/#post-1017570</guid>
					<title><![CDATA[Reply To: how to use openears framework to &quot;parrot&quot; back to you what you said]]></title>
					<link>/forums/topic/how-to-use-openears-framework-to-parrot-back-to-you-what-you-said/#post-1017570</link>
					<pubDate>Fri, 28 Jun 2013 18:22:00 +0000</pubDate>
					<dc:creator>Halle Winkler</dc:creator>

					<description>
						<![CDATA[
						<p>Hi doogie,</p>
<p>Which part of the process are you having trouble with?</p>
						]]>
					</description>

					
					
				</item>

			
				<item>
					<guid>/forums/topic/how-to-use-openears-framework-to-parrot-back-to-you-what-you-said/#post-1017571</guid>
					<title><![CDATA[Reply To: how to use openears framework to &quot;parrot&quot; back to you what you said]]></title>
					<link>/forums/topic/how-to-use-openears-framework-to-parrot-back-to-you-what-you-said/#post-1017571</link>
					<pubDate>Fri, 28 Jun 2013 18:56:10 +0000</pubDate>
					<dc:creator>doogie001</dc:creator>

					<description>
						<![CDATA[
						<p>After the user speaks and openears processes, I want to be able to get at what the user has said. This will be like siri in the repect that it writes out or speaks exactly what the user said before it continues to process the users request. It seems though that looking at the code and several logs produced that it only will understand what you have placed in the Language model generator. </p>
<p>So unless I have the &#8220;phrase&#8221; or words that the user will speak, I don&#8217;t think I can get at all that the user has said. This may be the &#8220;nature of the beast&#8221; for offline speech recognition but I just want to make sure this is the case.  </p>
<p>For example: I want to say &#8220;This is a test can you understand what I am saying&#8221;. But my Language model generator is initialized with the words @&#8221;cat&#8221;, @&#8221;mouse&#8221;. @&#8221;dog&#8221;, I don&#8217;t think I&#8217;ll be able to get at what the user intially said. Is this a correct assesment or am I missing someting here. </p>
<p>In my testing I was looking at the coentents of words from the method &#8211; (void) rapidEarsDidDetectFinishedSpeechAsWordArray:(NSArray *)words andScoreArray:(NSArray *)scores {<br />
}<br />
Thanks for your help</p>
						]]>
					</description>

					
					
				</item>

			
				<item>
					<guid>/forums/topic/how-to-use-openears-framework-to-parrot-back-to-you-what-you-said/#post-1017572</guid>
					<title><![CDATA[Reply To: how to use openears framework to &quot;parrot&quot; back to you what you said]]></title>
					<link>/forums/topic/how-to-use-openears-framework-to-parrot-back-to-you-what-you-said/#post-1017572</link>
					<pubDate>Fri, 28 Jun 2013 19:14:00 +0000</pubDate>
					<dc:creator>Halle Winkler</dc:creator>

					<description>
						<![CDATA[
						<p>Hi doogie,</p>
<p>That&#8217;s correct, it&#8217;s always necessary to create a language model or grammar containing the words that can be recognized. The interesting thing about it is that this isn&#8217;t actually a property of offline recognition &#8212; even Google Voice Search and Siri have to use pre-defined language models and grammar. </p>
<p>The difference is just that they are being run on enormous server farms and then the models are shared across many user sessions simultaneously, so it is possible for their language and acoustic models to be so large and exist in so much memory that they can create the illusion of detecting &#8220;anything&#8221;, even though at some point in time a (very big) language model like the output of LanguageModelGenerator was made. Since we&#8217;re just running on a phone, which is like a sliver of the available memory and cpu power of just a single server, we have to be very frugal and efficient with what is possible to recognize so it has to be constrained vocabularies which are in some way specific to the task at hand. </p>
<p>Luckily you can swap between vocabularies very quickly with OpenEars, or even generate them dynamically using LanguageModelGenerator based on the needs of the moment, so the usual approach for offline recognition is to have vocabularies which change based on the mode of the app.</p>
						]]>
					</description>

					
					
				</item>

			
				<item>
					<guid>/forums/topic/how-to-use-openears-framework-to-parrot-back-to-you-what-you-said/#post-1017573</guid>
					<title><![CDATA[Reply To: how to use openears framework to &quot;parrot&quot; back to you what you said]]></title>
					<link>/forums/topic/how-to-use-openears-framework-to-parrot-back-to-you-what-you-said/#post-1017573</link>
					<pubDate>Fri, 28 Jun 2013 19:20:58 +0000</pubDate>
					<dc:creator>doogie001</dc:creator>

					<description>
						<![CDATA[
						<p>Thank you for your quick and detailed reply. </p>
						]]>
					</description>

					
					
				</item>

			
				<item>
					<guid>/forums/topic/how-to-use-openears-framework-to-parrot-back-to-you-what-you-said/#post-1017574</guid>
					<title><![CDATA[Reply To: how to use openears framework to &quot;parrot&quot; back to you what you said]]></title>
					<link>/forums/topic/how-to-use-openears-framework-to-parrot-back-to-you-what-you-said/#post-1017574</link>
					<pubDate>Fri, 28 Jun 2013 19:41:30 +0000</pubDate>
					<dc:creator>Halle Winkler</dc:creator>

					<description>
						<![CDATA[
						<p>No problem! Feel free to follow up if you have questions about the specifics of setting up vocabularies or switching between them.</p>
						]]>
					</description>

					
					
				</item>

			
				<item>
					<guid>/forums/topic/how-to-use-openears-framework-to-parrot-back-to-you-what-you-said/#post-1017651</guid>
					<title><![CDATA[Reply To: how to use openears framework to &quot;parrot&quot; back to you what you said]]></title>
					<link>/forums/topic/how-to-use-openears-framework-to-parrot-back-to-you-what-you-said/#post-1017651</link>
					<pubDate>Fri, 12 Jul 2013 12:25:16 +0000</pubDate>
					<dc:creator>Ruby</dc:creator>

					<description>
						<![CDATA[
						<p>Hi i am using openears framework.i have downloaded the openears link there i came to know how to use openear framework.my problem is when i am in same viewcontroller it is recognise my voice and giving response but when i change my view i mean i go to previous view and again came back to same view then the application is crashing and reason for crash is  please turn on [OpenEarsLogging startOpenEarsLogging] plese say me the solution for this </p>
<p>Thank you</p>
						]]>
					</description>

					
					
				</item>

			
				<item>
					<guid>/forums/topic/how-to-use-openears-framework-to-parrot-back-to-you-what-you-said/#post-1017652</guid>
					<title><![CDATA[Reply To: how to use openears framework to &quot;parrot&quot; back to you what you said]]></title>
					<link>/forums/topic/how-to-use-openears-framework-to-parrot-back-to-you-what-you-said/#post-1017652</link>
					<pubDate>Fri, 12 Jul 2013 12:32:16 +0000</pubDate>
					<dc:creator>Halle Winkler</dc:creator>

					<description>
						<![CDATA[
						<p>Welcome Ruby,</p>
<p>Can you read the instructions in this post and show me the logging output that you get as a result?</p>
<p><a href="/forums/topic/install-issues-and-their-solutions/">/forums/topic/install-issues-and-their-solutions/</a></p>
						]]>
					</description>

					
					
				</item>

					
		
	</channel>
	</rss>

